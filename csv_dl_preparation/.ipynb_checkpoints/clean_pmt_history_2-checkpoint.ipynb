{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Justin Hsi\n",
    "## Part 2 of cleaning lending club payment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dupe_dates(group):\n",
    "    return pd.to_datetime(group[group.duplicated('date')]['date'].values)\n",
    "\n",
    "def merge_dupe_dates(group):\n",
    "    df_chunks = []\n",
    "    \n",
    "    dupe_dates = find_dupe_dates(group)\n",
    "    df_chunks.append(group[~group['date'].isin(dupe_dates)])\n",
    "    \n",
    "    for date in dupe_dates:\n",
    "        problem_rows = group[group['date'] == date]\n",
    "        ori_index = problem_rows.index\n",
    "        keep_row = problem_rows.iloc[-1].to_dict()\n",
    "        keep_row['outs_princp_beg'] = problem_rows.ix[ori_index[0],column_iloc_map['outs_princp_beg']]\n",
    "        \n",
    "        summed = problem_rows.sum()\n",
    "        keep_row['princp_paid'] = summed['princp_paid']\n",
    "        keep_row['int_paid'] = summed['int_paid']\n",
    "        keep_row['fee_paid'] = summed['fee_paid']\n",
    "        keep_row['amt_due'] = summed['amt_due']\n",
    "        keep_row['amt_paid'] = summed['amt_paid']\n",
    "        keep_row['charged_off_amt'] = summed['charged_off_amt']\n",
    "        keep_row['recovs'] = summed['recovs']\n",
    "        keep_row['recov_fees'] = summed['recov_fees']\n",
    "            \n",
    "        df_chunks.append(pd.DataFrame(pd.Series(keep_row),columns=[ori_index[-1]]).T)\n",
    "            \n",
    "    return pd.concat(df_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'lendingclub'\n",
    "\n",
    "store =  pd.HDFStore(\n",
    "    '/Users/justinhsi/justin_tinkering/data_science/lendingclub/{0}_store.h5'.\n",
    "    format(platform),\n",
    "    append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are loans that have multiple row entries per month (as in multiple pmts in same month) and there are also loans that don't have any entry for a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmt_hist_ids = store['pmt_hist_ids'].astype(int)\n",
    "max_id = pmt_hist_ids.max()\n",
    "chunksize = 800\n",
    "n_chunks = len(pmt_hist_ids)//chunksize + 1\n",
    "\n",
    "# fix loans with double month entries _________________________________________\n",
    "# left_bound = 0\n",
    "# right_bound = pmt_hist_ids[chunksize]\n",
    "already_good_dfs = []\n",
    "fixed_dfs = []\n",
    "k = 0\n",
    "for n in tqdm_notebook(np.arange(n_chunks)):\n",
    "    if n == 0:\n",
    "        left_bound = 0\n",
    "    else:\n",
    "        left_bound = pmt_hist_ids[n*chunksize]\n",
    "    if n == (n_chunks - 1):\n",
    "        right_bound = max_id\n",
    "    else:\n",
    "        right_bound = pmt_hist_ids[(n+1)*chunksize]\n",
    "    \n",
    "    chunk = pd.read_hdf(\n",
    "        store,\n",
    "        'pmt_hist_intermediary_1',\n",
    "        where='(loan_id_num > left_bound) & (loan_id_num <= right_bound)')\n",
    "    loans_with_two_entries_in_same_month = chunk[chunk.duplicated(\n",
    "    ['loan_id', 'date'])]\n",
    "    dup_date_ids = loans_with_two_entries_in_same_month['loan_id'].unique()\n",
    "    if k == 0:\n",
    "        column_iloc_map = {\n",
    "            col_name: chunk.iloc[-1].index.get_loc(col_name)\n",
    "            for col_name in chunk.columns.values\n",
    "        }\n",
    "        k += 1\n",
    "\n",
    "    id_grouped = chunk.groupby('loan_id')\n",
    "    already_good = chunk[~chunk['loan_id'].isin(dup_date_ids)]\n",
    "    for ids, group in id_grouped:\n",
    "        if ids in dup_date_ids:\n",
    "            fixed_dfs.append(merge_dupe_dates(group))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    already_good_dfs.append(already_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store before next cleaning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create min_itemsize_dict for allocating size when storing ___________________\n",
    "min_itemsize_dict = {}\n",
    "for col in already_good.columns:\n",
    "    if already_good[col].dtype == np.object:\n",
    "        print(col, already_good[col].str.len().max())\n",
    "        if col in ['State', 'VINTAGE', 'grade']:\n",
    "            pass\n",
    "        else:\n",
    "            min_itemsize_dict[col] = 15\n",
    "\n",
    "col_dtype_map = already_good_dfs[0].dtypes.to_dict()\n",
    "all_fixed_dfs = pd.concat(fixed_dfs)\n",
    "for col, dtype in col_dtype_map.iteritems():\n",
    "    all_fixed_dfs[col] = all_fixed_dfs[col].astype(dtype)\n",
    "     \n",
    "k = 0\n",
    "for chunk in tqdm_notebook([all_fixed_dfs] + already_good_dfs):\n",
    "    if k == 0:\n",
    "        store.append(\n",
    "            'pmt_hist_intermediary_2',\n",
    "            chunk,\n",
    "            data_columns=True,\n",
    "            index=True,\n",
    "            append=False,\n",
    "            min_itemsize=min_itemsize_dict)\n",
    "        k += 1\n",
    "    else:\n",
    "        store.append(\n",
    "            'pmt_hist_intermediary_2',\n",
    "            chunk,\n",
    "            data_columns=True,\n",
    "            index=True,\n",
    "            append=True)           \n",
    "        \n",
    "store.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
