{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import math\n",
    "from pandas.io import sql\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "# Set engine\n",
    "engine = create_engine('sqlite:////Users/justinhsi/LRData/lc_database.db')\n",
    "batch_size = 200000\n",
    "\n",
    "pmt_hist_cols = [\n",
    "    'acc_int', 'charged_off_recovs_collection_fees',\n",
    "    'gross_charged_off_recovs', 'id', 'm_on_books', 'pmt_amt_received',\n",
    "    'gross_pmt_to_int', 'gross_pmt_to_princp', 'outs_princp_end',\n",
    "    'outs_princp_beg', 'date'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_to_picks(ids, dataframe):\n",
    "    return dataframe[dataframe['id'].isin(ids)]\n",
    "\n",
    "\n",
    "def create_original_amounts_funded(dataframe):\n",
    "    # Find out how much is being originated in each month and store that in a dict\n",
    "    just_first = dataframe.sort_values(['platform', 'id', 'date'])\n",
    "    just_first.drop_duplicates(subset=['id', 'platform'], inplace=True)\n",
    "    #assert just_first.shape[0] == (len(pmt_history['id'].unique()))# + len(pmt_history_P['id'].unique()))\n",
    "    origination_date_grouped = just_first.groupby('issue_d')\n",
    "    original_origination_amounts_dict = {}\n",
    "    for issue_d, group in origination_date_grouped:\n",
    "        original_origination_amounts_dict[issue_d] = group['funded'].sum()\n",
    "    return original_origination_amounts_dict\n",
    "\n",
    "def select_some_loans_h5():\n",
    "    datapath_store = '/Users/justinhsi/LRData/lendingclub/old/lendingclub_store.h5'\n",
    "    return pd.read_hdf(datapath_store, 'clean_pmt_history', where='LOAN_ID=ids_list', chunksize = 200000)\n",
    "\n",
    "def select_some_loans():\n",
    "    engine = create_engine(\n",
    "        'sqlite:////Users/justinhsi/LRData/lc_database.db')\n",
    "    selected_loans = pd.read_sql_query(\n",
    "        'SELECT * from jclean_pmt_history_month_merged',\n",
    "        engine,\n",
    "        parse_dates=['date'])\n",
    "    return selected_loans\n",
    "\n",
    "\n",
    "def speed_test(group):\n",
    "    to_concat = []\n",
    "    group['acc_int'] = make_acc_int(group)\n",
    "    group['status'] = make_status(group)\n",
    "    to_concat.append(group)\n",
    "    \n",
    "def lc_rename_cols(df):\n",
    "    return df.rename(columns = {'LOAN_ID': 'id',\n",
    "                              'PBAL_BEG_PERIOD': 'outs_princp_beg',\n",
    "                              'PRNCP_PAID': 'gross_pmt_to_princp',\n",
    "                              'INT_PAID': 'gross_pmt_to_int',\n",
    "                              'FEE_PAID': 'gross_pmt_to_late_fee',\n",
    "                              'DUE_AMT': 'm_amt_due',\n",
    "                              'RECEIVED_AMT': 'pmt_amt_received',\n",
    "                              'RECEIVED_D': 'pmt_date_received',\n",
    "                              'PERIOD_END_LSTAT': 'status',\n",
    "                              'MONTH': 'date',\n",
    "                              'PBAL_END_PERIOD': 'outs_princp_end',\n",
    "                              'MOB': 'm_on_books',\n",
    "                              'CO': 'charged_off',\n",
    "                              'COAMT': 'charged_off_amt',\n",
    "                              'InterestRate': 'rate',\n",
    "                              'IssuedDate': 'issue_d',\n",
    "                              'MONTHLYCONTRACTAMT': 'installment_funded',                              \n",
    "                              'dti': 'dti',\n",
    "                              'State': 'addr_state',\n",
    "                              'HomeOwnership': 'home_ownership',\n",
    "                              'MonthlyIncome': 'monthly_income',\n",
    "                              'EarliestCREDITLine': 'line_earliest',\n",
    "                              'OpenCREDITLines': 'lines_open',\n",
    "                              'TotalCREDITLines': 'lines_total',\n",
    "                              'RevolvingCREDITBalance': 'revol_bal',\n",
    "                              'RevolvingLineUtilization':'revol_util',\n",
    "                              'Inquiries6M': 'inquiries_6m',\n",
    "                              'DQ2yrs': 'delinq_24m',\n",
    "                              'MonthsSinceDQ': 'm_since_delinq',\n",
    "                              'PublicRec': 'records',\n",
    "                              'MonthsSinceLastRec': 'm_since_record',\n",
    "                              'EmploymentLength': 'emp_length',\n",
    "                              'currentpolicy': 'current_policy',\n",
    "                              'grade': 'grade',\n",
    "                              'term': 'term',\n",
    "                              'APPL_FICO_BAND': 'fico_apply',\n",
    "                              'Last_FICO_BAND': 'fico_last',\n",
    "                              'VINTAGE': 'yr_qtr',\n",
    "                              'PCO_RECOVERY': 'gross_charged_off_recovs',\n",
    "                              'PCO_COLLECTION_FEE': 'charged_off_recovs_collection_fees',\n",
    "                              'policy_code': 'policy_code',})\n",
    "\n",
    "def make_acc_int(group):\n",
    "    m_int_rate = group['rate'].values[0] / 12\n",
    "    acc_int = group['outs_princp_beg'] * m_int_rate\n",
    "    return acc_int\n",
    "\n",
    "\n",
    "def make_status(group):\n",
    "    pmts = group['pmt_amt_received'].values\n",
    "    outs_princp_end = group['outs_princp_end'].values\n",
    "    m_amt_due = group['m_amt_due'].values * .99\n",
    "    #     m_installment = group['installment_funded'].values[0]*.985\n",
    "    status = []\n",
    "    for i in np.arange(len(group)):\n",
    "        pmt = pmts[i]\n",
    "        amt_due = m_amt_due[i]\n",
    "        if pmt < amt_due:\n",
    "            if len(status) == 0:\n",
    "                status.append('late')\n",
    "            elif status[-1] == 'late':\n",
    "                status.append('late_60')\n",
    "            elif status[-1] == 'late_60':\n",
    "                status.append('late_90')\n",
    "            elif status[-1] == 'late_90':\n",
    "                status.append('late_120')\n",
    "            elif status[-1] == 'late_120':\n",
    "                status.append('late_max')\n",
    "            else:\n",
    "                status.append('late')\n",
    "        else:\n",
    "            if outs_princp_end[i] <= 0:\n",
    "                status.append('paid')\n",
    "            else:\n",
    "                status.append('current')\n",
    "    return status\n",
    "\n",
    "def make_service_fees(group):\n",
    "    before_13 = group[group['m_on_books'] <= 12]\n",
    "    rest = group[~group['date'].isin(before_13['date'].values)]\n",
    "    \n",
    "    b_13_service_fees = []\n",
    "    for index in before_13.index.values:\n",
    "        pmt = before_13.ix[index, 'pmt_amt_received']\n",
    "        m_amt_due = before_13.ix[index, 'm_amt_due']\n",
    "        b_13_service_fees.append(min(pmt*.01, m_amt_due*.01))\n",
    "    \n",
    "    rest_service_fees = list((rest['pmt_amt_received']).values*.01)\n",
    "    service_fees = np.array(b_13_service_fees + rest_service_fees)\n",
    "    assert(len(service_fees) == len(group)), print(group['id'].unique())\n",
    "    return service_fees\n",
    "\n",
    "def make_cummulative_service_fees(service_fee_list):\n",
    "    cum_service_fees = service_fee_list.cumsum()\n",
    "    return cum_service_fees\n",
    "\n",
    "def add_cols_lc(df):\n",
    "    id_grouped = df.groupby('id')\n",
    "    id_dict_subdict = {}\n",
    "    for ids, group in tqdm_notebook(id_grouped):\n",
    "        subdict = {}\n",
    "        subdict['status'] = make_status(group)\n",
    "        subdict['acc_int'] = make_acc_int(group)\n",
    "        subdict['service_fees'] = make_service_fees(group)\n",
    "#         subdict['cum_service_fees'] = make_cummulative_service_fees(subdict['service_fees'])\n",
    "        id_dict_subdict[ids] = subdict    \n",
    "    \n",
    "        \n",
    "    seen_ids = set()\n",
    "    status_list = []\n",
    "    acc_int_list = []\n",
    "    service_fees_list = []\n",
    "#     cum_service_fees_list = []\n",
    "    for ids in tqdm_notebook(df['id'].values):\n",
    "        if ids not in seen_ids:\n",
    "            seen_ids.update([ids])\n",
    "            status_list.extend(id_dict_subdict[ids]['status'])\n",
    "            acc_int_list.extend(id_dict_subdict[ids]['acc_int'])\n",
    "            service_fees_list.extend(id_dict_subdict[ids]['service_fees'])\n",
    "#             cum_service_fees_list.extend(id_dict_subdict[ids]['cum_service_fees'])\n",
    "#         else:\n",
    "#             pass\n",
    "    df['acc_int'] = acc_int_list\n",
    "    df['j_status'] = status_list\n",
    "    df['service_fees'] = service_fees_list\n",
    "#     df['cum_service_fees'] = cum_service_fees_list\n",
    "    \n",
    "    df['j_status'] = np.where(df['issue_d'] == df['date'], 'issued', df['j_status'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running as script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get in data\n",
    "store = pd.HDFStore('/Users/justinhsi/LRData/lendingclub/lendingclub_store.h5')\n",
    "loan_info = store['clean_loan_info']\n",
    "pmt_hist = store['clean_pmt_history']\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmt_history = lc_rename_cols(pmt_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix 600 loans with double entries in same date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loans= pmt_history\n",
    "loans_with_two_entries_in_same_month = all_loans[all_loans.duplicated(['id', 'date'])]\n",
    "dup_date_ids = loans_with_two_entries_in_same_month['id'].unique()\n",
    "column_iloc_map = {col_name:all_loans.iloc[-1].index.get_loc(col_name) for col_name in all_loans.columns.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group = all_loans[all_loans['id'].isin([dup_date_ids[0]])] #a test group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dupe_dates(group):\n",
    "    return pd.to_datetime(group[group.duplicated('date')]['date'].values)\n",
    "\n",
    "def merge_dupe_dates(group):\n",
    "    df_chunks = []\n",
    "    \n",
    "    dupe_dates = find_dupe_dates(group)\n",
    "    df_chunks.append(group[~group['date'].isin(dupe_dates)])\n",
    "    \n",
    "    for date in dupe_dates:\n",
    "        problem_rows = group[group['date'] == date]\n",
    "        ori_index = problem_rows.index\n",
    "        keep_row = problem_rows.iloc[-1].to_dict()\n",
    "        keep_row['outs_princp_beg'] = problem_rows.ix[ori_index[0],column_iloc_map['outs_princp_beg']]\n",
    "        \n",
    "        summed = problem_rows.sum()\n",
    "        keep_row['gross_pmt_to_princp'] = summed['gross_pmt_to_princp']\n",
    "        keep_row['gross_pmt_to_int'] = summed['gross_pmt_to_int']\n",
    "        keep_row['gross_pmt_to_late_fee'] = summed['gross_pmt_to_late_fee']\n",
    "        keep_row['m_amt_due'] = summed['m_amt_due']\n",
    "        keep_row['pmt_amt_received'] = summed['pmt_amt_received']\n",
    "        keep_row['charged_off_amt'] = summed['charged_off_amt']\n",
    "        keep_row['gross_charged_off_recovs'] = summed['gross_charged_off_recovs']\n",
    "        keep_row['charged_off_recovs_collection_fees'] = summed['charged_off_recovs_collection_fees']\n",
    "            \n",
    "        df_chunks.append(pd.DataFrame(pd.Series(keep_row),columns=[ori_index[-1]]).T)\n",
    "            \n",
    "    return df_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_grouped = all_loans.groupby('id')\n",
    "\n",
    "already_good = all_loans[~all_loans['id'].isin(dup_date_ids)]\n",
    "to_concat = []\n",
    "for ids, group in tqdm_notebook(id_grouped):\n",
    "    if ids in dup_date_ids:\n",
    "        to_concat.extend(merge_dupe_dates(group))\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "to_concat.append(already_good)\n",
    "examine = pd.concat(to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine['date'] = pd.to_datetime(examine['date'])\n",
    "examine['issue_d'] = pd.to_datetime(examine['issue_d'])\n",
    "examine['pmt_date_received'] = pd.to_datetime(examine['pmt_date_received'])\n",
    "all_loans = examine.sort_values(['id', 'date'])\n",
    "all_loans = all_loans.set_index(['id', 'date'], drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do I need to fix stuff that pays immediately in issuance month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loans[all_loans['m_on_books'] == 0]\n",
    "group = all_loans.ix['10645201',:]\n",
    "group[['issue_d', 'date', 'm_amt_due', 'pmt_amt_received', 'outs_princp_beg', 'outs_princp_end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_lc_loans = add_status_acc_int_lc(all_lc_loans)\n",
    "\n",
    "all_loans = add_cols_lc(all_loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loans['service_fees'] = np.where(\n",
    "    all_loans['date'] == all_loans['issue_d'],\n",
    "    (all_loans['pmt_amt_received'] - all_loans['outs_princp_beg']) * .01,\n",
    "    all_loans['service_fees'])\n",
    "all_loans['service_fees'] = np.where(\n",
    "    all_loans['gross_pmt_to_int'] == 0, 0, all_loans['service_fees'])\n",
    "all_loans['acc_int'] = np.where(all_loans['date'] == all_loans['issue_d'], 0,\n",
    "                                all_loans['acc_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = all_loans.ix['10645201',:]\n",
    "group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now adjust each pmt_history about each loan by the appropriate amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loans = all_loans.fillna(0)\n",
    "id_grouped = all_loans.groupby('id')\n",
    "result = {}\n",
    "charged_off_recovs_collection_fees_list = []\n",
    "gross_charged_off_recovs_list = []\n",
    "pmt_amt_received_list = []\n",
    "outs_princp_end_list = []\n",
    "outs_princp_beg_list = []\n",
    "gross_pmt_to_princp_list = []\n",
    "acc_int_list = []\n",
    "service_fees_list = []\n",
    "gross_pmt_to_int_list = []\n",
    "ids_list = []\n",
    "date_list = []\n",
    "status_list = []\n",
    "m_on_books_list = []\n",
    "charged_off_list = []\n",
    "charged_off_amt_list = []\n",
    "m_amt_due_list = []\n",
    "issue_d_list = []\n",
    "rate_list = []\n",
    "grade_list = []\n",
    "for ids, group in tqdm_notebook(id_grouped):\n",
    "    invest_amt = plat_dict[plat][ids]\n",
    "    ori_index = group.index\n",
    "    funded = group['outs_princp_beg'].values[0]\n",
    "\n",
    "    charged_off_recovs_collection_fees = group[\n",
    "        'charged_off_recovs_collection_fees'].values / funded * invest_amt\n",
    "    charged_off_recovs_collection_fees_list.extend(\n",
    "        charged_off_recovs_collection_fees)\n",
    "\n",
    "    gross_charged_off_recovs = group[\n",
    "        'gross_charged_off_recovs'].values / funded * invest_amt\n",
    "    gross_charged_off_recovs_list.extend(gross_charged_off_recovs)\n",
    "\n",
    "    pmt_amt_received = group['pmt_amt_received'].values / funded * invest_amt\n",
    "    pmt_amt_received_list.extend(pmt_amt_received)\n",
    "\n",
    "    outs_princp_end = group['outs_princp_end'].values / funded * invest_amt\n",
    "    outs_princp_end_list.extend(outs_princp_end)\n",
    "\n",
    "    outs_princp_beg = group['outs_princp_beg'].values / funded * invest_amt\n",
    "    outs_princp_beg_list.extend(outs_princp_beg)\n",
    "\n",
    "    gross_pmt_to_princp = group[\n",
    "        'gross_pmt_to_princp'].values / funded * invest_amt\n",
    "    gross_pmt_to_princp_list.extend(gross_pmt_to_princp)\n",
    "\n",
    "    acc_int = group['acc_int'].values / funded * invest_amt\n",
    "    acc_int_list.extend(acc_int)\n",
    "\n",
    "    service_fees = group['service_fees'].values / funded * invest_amt\n",
    "    service_fees_list.extend(service_fees)\n",
    "\n",
    "    gross_pmt_to_int = group['gross_pmt_to_int'].values / funded * invest_amt\n",
    "    gross_pmt_to_int_list.extend(gross_pmt_to_int)\n",
    "\n",
    "    m_amt_due = group['m_amt_due'].values / funded * invest_amt\n",
    "    m_amt_due_list.extend(m_amt_due)\n",
    "\n",
    "    ids_list.extend([ids] * len(group))\n",
    "    \n",
    "    grade_list.extend(group['grade'].values)\n",
    "\n",
    "    date_list.extend(group['date'].values)\n",
    "\n",
    "    status_list.extend(group['j_status'].values)\n",
    "\n",
    "    m_on_books_list.extend(group['m_on_books'].values)\n",
    "\n",
    "    issue_d_list.extend(group['issue_d'].values)\n",
    "\n",
    "    rate_list.extend(group['rate'].values)\n",
    "\n",
    "    charged_off_list.extend(group['charged_off'].values)\n",
    "\n",
    "    charged_off_amt = group['charged_off_amt'].values / funded * invest_amt\n",
    "    charged_off_amt_list.extend(charged_off_amt)\n",
    "\n",
    "    result[\n",
    "        'charged_off_recovs_collection_fees'] = charged_off_recovs_collection_fees_list\n",
    "    result['gross_charged_off_recovs'] = gross_charged_off_recovs_list\n",
    "    result['pmt_amt_received'] = pmt_amt_received_list\n",
    "    result['outs_princp_end'] = outs_princp_end_list\n",
    "    result['outs_princp_beg'] = outs_princp_beg_list\n",
    "    result['gross_pmt_to_princp'] = gross_pmt_to_princp_list\n",
    "    result['acc_int'] = acc_int_list\n",
    "    result['service_fees'] = service_fees_list\n",
    "    result['gross_pmt_to_int'] = gross_pmt_to_int_list\n",
    "    result['id'] = ids_list\n",
    "    result['date'] = date_list\n",
    "    result['status'] = status_list\n",
    "    result['m_on_books'] = m_on_books_list\n",
    "    result['issue_d'] = issue_d_list\n",
    "    result['rate'] = rate_list\n",
    "    result['charged_off'] = charged_off_list\n",
    "    result['charged_off_amt'] = charged_off_amt_list\n",
    "    result['m_amt_due'] = m_amt_due_list\n",
    "    result['grade'] = grade_list\n",
    "\n",
    "df = pd.DataFrame.from_dict(result)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "# for status adjustment. If it paid and is not late, acc_int - pmt_to_int should equal 0\n",
    "# and thus you're only left with outs_princp_end. If they didn't pay or paid less,\n",
    "# then acc_int - pmt_to_int is > 0 and you add that value to outs_princp_end, and then\n",
    "# adjust it by the lateness\n",
    "df['stat_adj_acc_int'] = np.where(\n",
    "    df['status'] == 'late', df['acc_int'] / 2,\n",
    "    np.where(df['status'] == 'late_60', 0, df['acc_int']))\n",
    "df['stat_adj_outs_princp_end'] = np.where(\n",
    "    df['status'] == 'late', df['outs_princp_end'] / 2,\n",
    "    np.where(df['status'] == 'late_60', 0, df['outs_princp_end']))\n",
    "\n",
    "sorted_df = df.sort_values(['id', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = sorted_df.set_index(['id', 'date'], drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.ix['10645201',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting munge work for emmanuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled['stat_adj_value'] = np.where(\n",
    "    scaled['pmt_amt_received'] >= scaled['m_amt_due'],\n",
    "    scaled['stat_adj_outs_princp_end'],\n",
    "    scaled['stat_adj_outs_princp_end'] +\n",
    "    scaled['stat_adj_acc_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_date = scaled['issue_d'].min()\n",
    "last_date = scaled['date'].max()\n",
    "date_mapper = {}\n",
    "k = 0\n",
    "while zero_date + pd.DateOffset(months=+k) <= last_date:\n",
    "    date_mapper[zero_date + pd.DateOffset(months=+k)] = k\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_grouped = plat_selected_dfs['LC'].groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_status_mapper = {}\n",
    "for ids, group in tqdm_notebook(id_grouped):\n",
    "    last_status_mapper[ids] = group['status'].values[-1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_mapper = plat_selected_dfs['LC'].drop_duplicates('id').set_index('id')['term'].to_dict()\n",
    "rate_mapper = plat_selected_dfs['LC'].drop_duplicates('id').set_index('id')['rate'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled['issue_d_mapped'] = scaled['issue_d'].map(date_mapper)\n",
    "scaled['date_mapped'] = scaled['date'].map(date_mapper)\n",
    "# scaled['last_pmt_d_mapped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_scaled_grouped = scaled.groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mismatch_issue_date_and_date = []\n",
    "# for ids, group in tqdm_notebook(id_scaled_grouped):\n",
    "#     if group['issue_d'].min() != group['date'].min():\n",
    "#         mismatch_issue_date_and_date.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled['days_late'] = np.where(scaled['status'] == 'late', 15,\n",
    "        np.where(scaled['status'] == 'late_60', 45,\n",
    "                np.where(scaled['status'] == 'late_90', 75,\n",
    "                         np.where(scaled['status'] == 'late_120', 105,\n",
    "                                  np.where(scaled['status'] == 'late_max', 135, 0)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled['yr_quarter'] = scaled['date'].dt.year.astype(str).str[-2:] + 'Q' + scaled['date'].dt.quarter.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict = {}\n",
    "for ids, group in tqdm_notebook(id_scaled_grouped):\n",
    "    sub_dict = {}\n",
    "    sub_dict['Grade'] = group['grade'].values[0]\n",
    "    sub_dict['Month of Issuance'] = group['issue_d_mapped'].min()\n",
    "    sub_dict['Month of Last Record'] = group['date_mapped'].max()\n",
    "    sub_dict['Month of First Record'] = group['date_mapped'].min()\n",
    "    try:\n",
    "        sub_dict['Month of Last Payment'] = date_mapper[pd.to_datetime(group[\n",
    "            'date'].iloc[np.nonzero(group['pmt_amt_received']\n",
    "                                    .values)].values.max())]\n",
    "    except:\n",
    "        # if no payment was ever made\n",
    "        sub_dict['Month of Last Payment'] = np.nan\n",
    "    sub_dict['Amount'] = plat_dict['LC'][ids]\n",
    "    sub_dict['Term'] = term_mapper[ids]\n",
    "    sub_dict['Rate'] = rate_mapper[ids]\n",
    "    sub_dict['Status'] = last_status_mapper[ids]\n",
    "\n",
    "    outstandings = np.where(group['pmt_amt_received'] == 0,\n",
    "                            group['outs_princp_end'] + group['acc_int'],\n",
    "                            group['outs_princp_end'])\n",
    "    sub_dict['Outstandings'] = outstandings\n",
    "    sub_dict['Days Late'] = group['days_late'].values\n",
    "#     sub_dict['Status Adjusted Value'] = group['stat_adj_value'].values\n",
    "    \n",
    "    assert type(outstandings) != type(None), print(outstandings, ids)\n",
    "\n",
    "    sub_dict['Gross Payments'] = group['pmt_amt_received'].values\n",
    "    sub_dict['Net Payments'] = group['pmt_amt_received'].values - group['service_fees'].values\n",
    "\n",
    "    if len(group[group['gross_charged_off_recovs'] > 0]):\n",
    "        sub_dict['Month of Recov_timestamp'] = pd.to_datetime(\n",
    "            group[group['gross_charged_off_recovs'] > 0]['date'].values[0])\n",
    "        sub_dict['Month of Recov'] = date_mapper[sub_dict[\n",
    "            'Month of Recov_timestamp']]\n",
    "        recov_net = group.ix[(ids, sub_dict['Month of Recov_timestamp']),\n",
    "                             'gross_charged_off_recovs'] - group.ix[\n",
    "                                 (ids, sub_dict['Month of Recov_timestamp']\n",
    "                                  ), 'charged_off_recovs_collection_fees']\n",
    "        sub_dict['Net Recov'] = recov_net\n",
    "    else:\n",
    "        sub_dict['Month of Recov_timestamp'] = sub_dict['Month of Issuance']\n",
    "        sub_dict['Month of Recov'] = sub_dict['Month of Last Record']\n",
    "        sub_dict['Net Recov'] = 0\n",
    "\n",
    "    sub_dict['CO_amt'] = group['charged_off_amt'].max()\n",
    "    sub_dict['Month of CO'] = np.nan if len(group[group['charged_off'] != 0]) == 0 else group[group['charged_off'] == 1]['date_mapped'].values[0]\n",
    "    sub_dict['yr_qrtr'] = group['yr_quarter'].values[0]\n",
    "    \n",
    "    \n",
    "    combined_dict[ids] = sub_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn all the arrays into lists\n",
    "fixed_dict = {}\n",
    "for ids, sub_dict in combined_dict.iteritems():\n",
    "    fixed_dict[ids] = sub_dict\n",
    "    fixed_dict[ids]['Outstandings'] = fixed_dict[ids]['Outstandings'].tolist()\n",
    "    fixed_dict[ids]['Days Late'] = fixed_dict[ids]['Days Late'].tolist()\n",
    "#     fixed_dict[ids]['Status Adjusted Value'] = fixed_dict[ids]['Status Adjusted Value'].tolist()\n",
    "    fixed_dict[ids]['Net Payments'] = fixed_dict[ids]['Net Payments'].tolist()\n",
    "    fixed_dict[ids]['Gross Payments'] = fixed_dict[ids]['Gross Payments'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix some sequence of dates that are missing some dates by filling with 0s \n",
    "fix_counter = 0\n",
    "for ids, group in tqdm_notebook(id_scaled_grouped):\n",
    "    recorded_months = group['date_mapped'].values\n",
    "    expected_months = np.arange(group['issue_d_mapped'].min(), group['date_mapped'].max()+1)\n",
    "    \n",
    "    month_to_index_dict = {}\n",
    "    k = 0\n",
    "    for month in expected_months:\n",
    "        month_to_index_dict[month] = k\n",
    "        k += 1\n",
    "    indicies_to_insert = set(expected_months)^set(recorded_months)\n",
    "#     if ids == '77511438':\n",
    "#         print(indicies_to_insert)\n",
    "    if len(indicies_to_insert) > 0:\n",
    "        fix_counter += 1\n",
    "        for index in indicies_to_insert:\n",
    "            index = month_to_index_dict[index]\n",
    "            fixed_dict[ids]['Outstandings'].insert(index, 0)\n",
    "            fixed_dict[ids]['Days Late'].insert(index, 0)\n",
    "#             fixed_dict[ids]['Status Adjusted Value'].insert(index, 0)\n",
    "            fixed_dict[ids]['Net Payments'].insert(index, 0)\n",
    "            fixed_dict[ids]['Gross Payments'].insert(index, 0)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_months = np.arange(date_mapper[last_date] + 1)\n",
    "to_df = {}\n",
    "for ids, sub_dict in tqdm_notebook(fixed_dict.iteritems()):\n",
    "    ids_dict = {}\n",
    "    ids_dict = {k: v for k, v in sub_dict.iteritems()}\n",
    "    \n",
    "#     print(type(sub_dict['Month of Last Record']), type(sub_dict['Month of Issuance']), ids)\n",
    "#     expected_format = sub_dict['Month of Issuance'] < sub_dict['Month of First Record']\n",
    "#     months_diff =  int(sub_dict['Month of First Record'] - sub_dict['Month of Issuance'])\n",
    "#     if expected_format:\n",
    "#         n_months = int(sub_dict['Month of Last Record'] - sub_dict['Month of Issuance']) # or First Record instead of issuance\n",
    "#         new_net_recovs = [0] * n_months\n",
    "#     elif sub_dict['Month of Issuance'] == sub_dict['Month of First Record']:\n",
    "#         n_months = int(sub_dict['Month of Last Record'] - sub_dict['Month of Issuance'])+1\n",
    "#         new_net_recovs = [0] * n_months\n",
    "    new_net_recovs = [0] * int(len(sub_dict['Outstandings']))\n",
    "    new_net_recovs[-1] = sub_dict['Net Recov']\n",
    "    new_outstandings = sub_dict['Outstandings']\n",
    "    new_days_late = sub_dict['Days Late']\n",
    "#     new_stat_adj_value = sub_dict['Status Adjusted Value']\n",
    "    new_gross_payments = sub_dict['Gross Payments']\n",
    "    new_net_payments = sub_dict['Net Payments']\n",
    "\n",
    "#     print(months_diff)\n",
    "#     if months_diff > 1:\n",
    "#         n_zeros_to_prepend = int(months_diff - 1)\n",
    "#         new_outstandings = [0]*n_zeros_to_prepend + new_outstandings\n",
    "#         new_gross_payments = [0]*n_zeros_to_prepend + new_gross_payments\n",
    "#         new_net_payments = [0]*n_zeros_to_prepend + new_net_payments\n",
    "    assert(len(new_net_recovs) == len(new_outstandings)), print(new_net_recovs, len(new_net_recovs), new_outstandings, len(new_outstandings), ids)\n",
    "    assert(len(new_gross_payments) == len(new_outstandings))\n",
    "    assert(len(new_days_late) == len(new_outstandings))\n",
    "#     assert(len(new_stat_adj_value) == len(new_outstandings))\n",
    "    assert(len(new_net_payments) == len(new_outstandings))\n",
    "    \n",
    "    # adding padding before and after the lists as necessary\n",
    "    pad_before = [0] * int(sub_dict['Month of Issuance'])\n",
    "    pad_after = [0] * int(all_months.max() - sub_dict['Month of Last Record'])\n",
    "    \n",
    "    new_outstandings = pad_before + new_outstandings + pad_after\n",
    "    new_days_late = pad_before + new_days_late + pad_after\n",
    "#     new_stat_adj_value = pad_before + new_stat_adj_value + pad_after\n",
    "    new_gross_payments = pad_before + new_gross_payments + pad_after\n",
    "    new_net_payments = pad_before + new_net_payments + pad_after\n",
    "    new_net_recovs = pad_before + new_net_recovs + pad_after\n",
    "    \n",
    "# #     print(pad_after, pad_before, sub_dict['Month of First Record'], sub_dict['Month of Last Record'], ids)\n",
    "    \n",
    "    assert len(new_outstandings) == len(all_months)#, print(len(new_outstandings), len(all_months), ids)\n",
    "#     assert len(new_stat_adj_value) == len(all_months)\n",
    "    assert len(new_days_late) == len(all_months)\n",
    "    assert len(new_gross_payments) == len(all_months)\n",
    "    assert len(new_net_payments) == len(all_months)\n",
    "    assert len(new_net_recovs) == len(all_months)\n",
    "    \n",
    "\n",
    "    ids_dict['Outstandings'] = new_outstandings\n",
    "    ids_dict['Days Late'] = new_days_late\n",
    "#     ids_dict['Status Adjusted Value'] = new_stat_adj_value\n",
    "    ids_dict['Gross Payments'] = new_gross_payments\n",
    "    ids_dict['Net Payments'] = new_net_payments\n",
    "    ids_dict['Net Recov'] = new_net_recovs\n",
    "    to_df[ids] = ids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export = pd.DataFrame.from_dict(to_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export = to_export.drop(['Month of Recov', 'Month of Recov_timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export[to_export['Month of CO'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export['Status'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export['Amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.to_pickle('/Users/justinhsi/LRData/lendingclub/emmanuel_pmts_format.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.to_csv('/Users/justinhsi/LRData/lendingclub/pmts_csv_form.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.drop('Status', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.drop('Rate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_LC = scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_LC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do it for Prosper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_prosper_loans = plat_selected_dfs['P'].copy(deep=True)\n",
    "cols_P = ['LoanID', 'ListingNumber', 'LoanAmount', 'Term', 'OriginationDate', 'Observation_Month', 'BorrowerRate',\n",
    "          'ScheduledMonthlyPaymentAmount', 'Completed_Month', 'Monthof_Last_Payment', 'Debt_Sale_Month',\n",
    "          'NetCashToInvestorsFromDebtSale', 'CycleCounter', 'DaysPastDue', 'DaysPastDue_EOM',\n",
    "          'PaymentsReceived', 'CollectionFees', 'PrincipalPaid', 'InterestPaid', 'LateFees', 'ServicingFees',\n",
    "          'RecoveryPayments', 'RecoveryPrin', 'BOMPrin', 'EOMPrin', 'ProsperRating']\n",
    "p_loans = original_prosper_loans[cols_P].sort_values(['LoanID', 'Observation_Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that there's a row corresponding to origination month, that there's one and only one entry per obs\n",
    "# month\n",
    "\n",
    "id_grouped = p_loans.groupby('LoanID')\n",
    "for ids, group in tqdm_notebook(id_grouped):\n",
    "    assert len(group[group['Observation_Month']==group['OriginationDate'].values[0]] == 1)\n",
    "    assert len(group) == len(group['Observation_Month'].unique()), print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add acc_int\n",
    "p_loans['acc_int'] = p_loans['BOMPrin'] * p_loans['BorrowerRate']/12\n",
    "p_loans['acc_int'] = np.where(p_loans['OriginationDate'] == p_loans['Observation_Month'], 0, p_loans['acc_int'])\n",
    "\n",
    "p_loans['ScheduledMonthlyPaymentAmount'] = np.where(p_loans['acc_int'] == 0, 0, p_loans['ScheduledMonthlyPaymentAmount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now scale amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_loans = p_loans.fillna(0)\n",
    "id_grouped = p_loans.groupby('LoanID')\n",
    "\n",
    "result = {}\n",
    "\n",
    "ids_list = []\n",
    "listing_list = []\n",
    "amt_list = []\n",
    "term_list = []\n",
    "issue_d_list = []\n",
    "date_list = []\n",
    "rate_list = []\n",
    "m_amt_due_list = []\n",
    "acc_int_list = []\n",
    "recovs_debt_sale_list = []\n",
    "days_late_list = []\n",
    "payments_received_list = []\n",
    "collection_fees_list = []\n",
    "principal_paid_list = []\n",
    "interest_paid_list = []\n",
    "late_fees_list = []\n",
    "servicing_fees_list = []\n",
    "recovs_pmts_list = []\n",
    "recov_prin_list = []\n",
    "outs_princp_beg_list = []\n",
    "outs_princp_end_list = []\n",
    "\n",
    "plat = 'P'\n",
    "for ids, group in id_grouped:\n",
    "    list_number = str(group['ListingNumber'].values[0])\n",
    "    invest_amt = plat_dict[plat][list_number]\n",
    "    #     ori_index = group.index\n",
    "    funded = group['BOMPrin'].values[0]\n",
    "\n",
    "    ids_list.extend(group['LoanID'].values)\n",
    "    listing_list.extend([list_number] * len(group))\n",
    "    amt_list.extend([invest_amt] * len(group))\n",
    "    term_list.extend(group['Term'].values)\n",
    "    issue_d_list.extend(group['OriginationDate'].values)\n",
    "    date_list.extend(group['Observation_Month'].values)\n",
    "    rate_list.extend(group['BorrowerRate'].values)\n",
    "    m_amt_due_list.extend(group['ScheduledMonthlyPaymentAmount'].values *\n",
    "                          (invest_amt / funded))\n",
    "    acc_int_list.extend(group['acc_int'].values * (invest_amt / funded))\n",
    "    recovs_debt_sale_list.extend(group['NetCashToInvestorsFromDebtSale'].values\n",
    "                                 * (invest_amt / funded))\n",
    "    days_late_list.extend(group['DaysPastDue'].values)\n",
    "    payments_received_list.extend(group['PaymentsReceived'].values *\n",
    "                                  (invest_amt / funded))\n",
    "    collection_fees_list.extend(group['CollectionFees'].values *\n",
    "                                (invest_amt / funded))\n",
    "    principal_paid_list.extend(group['PrincipalPaid'].values *\n",
    "                               (invest_amt / funded))\n",
    "    interest_paid_list.extend(group['InterestPaid'].values *\n",
    "                              (invest_amt / funded))\n",
    "    late_fees_list.extend(group['LateFees'].values * (invest_amt / funded))\n",
    "    servicing_fees_list.extend(group['ServicingFees'].values *\n",
    "                               (invest_amt / funded))\n",
    "    recovs_pmts_list.extend(group['RecoveryPayments'].values *\n",
    "                            (invest_amt / funded))\n",
    "    recov_prin_list.extend(group['RecoveryPrin'].values *\n",
    "                           (invest_amt / funded))\n",
    "    outs_princp_beg_list.extend(group['BOMPrin'].values *\n",
    "                                (invest_amt / funded))\n",
    "    outs_princp_end_list.extend(group['EOMPrin'].values *\n",
    "                                (invest_amt / funded))\n",
    "#     print(len(ids_list), len(outs_princp_end_list))\n",
    "\n",
    "result['id'] = ids_list\n",
    "result['listing'] = listing_list\n",
    "result['amt'] = amt_list\n",
    "result['term'] = term_list\n",
    "result['issue_d'] = issue_d_list\n",
    "result['date'] = date_list\n",
    "result['rate'] = rate_list\n",
    "result['m_amt_due'] = m_amt_due_list\n",
    "result['acc_int'] = acc_int_list\n",
    "result['recovs_sale'] = recovs_debt_sale_list\n",
    "result['days_late'] = days_late_list\n",
    "result['net_norm_payments'] = payments_received_list\n",
    "result['collection_fees'] = collection_fees_list\n",
    "result['princp_paid'] = principal_paid_list\n",
    "result['int_paid'] = interest_paid_list\n",
    "result['late_fees'] = late_fees_list\n",
    "result['servicing_fees'] = servicing_fees_list\n",
    "result['recov_payments'] = recovs_pmts_list\n",
    "result['recov_princp'] = recov_prin_list\n",
    "result['outs_princp_beg'] = outs_princp_beg_list\n",
    "result['outs_princp_end'] = outs_princp_end_list\n",
    "\n",
    "df = pd.DataFrame.from_dict(result)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['issue_d'] = pd.to_datetime(df['issue_d'])\n",
    "\n",
    "sorted_df = df.sort_values(['id', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_mapper = plat_selected_dfs['P'].drop_duplicates('LoanID').set_index('LoanID')['Term'].to_dict()\n",
    "rate_mapper = plat_selected_dfs['P'].drop_duplicates('LoanID').set_index('LoanID')['BorrowerRate'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled['issue_d_mapped'] = scaled['issue_d'].map(date_mapper)\n",
    "scaled['date_mapped'] = scaled['date'].map(date_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_scaled_grouped = scaled.groupby('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict = {}\n",
    "for ids, group in tqdm_notebook(id_scaled_grouped):\n",
    "    sub_dict = {}\n",
    "#     sub_dict['Grade'] = group['grade'].values[0]\n",
    "    sub_dict['Month of Issuance'] = group['issue_d_mapped'].min()\n",
    "    sub_dict['Month of Last Record'] = group['date_mapped'].max()\n",
    "    sub_dict['Month of First Record'] = group['date_mapped'].min()\n",
    "    try:\n",
    "        sub_dict['Month of Last Payment'] = date_mapper[pd.to_datetime(group[\n",
    "            'date'].iloc[np.nonzero(group['pmt_amt_received']\n",
    "                                    .values)].values.max())]\n",
    "    except:\n",
    "        # if no payment was ever made\n",
    "        sub_dict['Month of Last Payment'] = np.nan\n",
    "        \n",
    "\n",
    "    sub_dict['Amount'] = group['amt'].values[0]\n",
    "    sub_dict['Term'] = term_mapper[ids]\n",
    "    sub_dict['Rate'] = rate_mapper[ids]\n",
    "#     sub_dict['Status'] = last_status_mapper[ids]\n",
    "\n",
    "    outstandings = np.where((group['net_norm_payments'] == 0) & (group['recov_payments'] == 0),\n",
    "                            group['outs_princp_end'] + group['acc_int'],\n",
    "                            group['outs_princp_end'])\n",
    "    sub_dict['Outstandings'] = outstandings\n",
    "    sub_dict['Days Late'] = group['days_late'].values\n",
    "#     sub_dict['Status Adjusted Value'] = group['stat_adj_value'].values\n",
    "    \n",
    "    assert type(outstandings) != type(None), print(outstandings, ids)\n",
    "\n",
    "    sub_dict['Gross Payments'] = group['late_fees'].values + group['princp_paid'].values + group['int_paid'].values\n",
    "    sub_dict['Net Payments'] = group['net_norm_payments'].values\n",
    "\n",
    "#     if len(group[group['gross_charged_off_recovs'] > 0]):\n",
    "#         sub_dict['Month of Recov_timestamp'] = pd.to_datetime(\n",
    "#             group[group['gross_charged_off_recovs'] > 0]['date'].values[0])\n",
    "#         sub_dict['Month of Recov'] = date_mapper[sub_dict[\n",
    "#             'Month of Recov_timestamp']]\n",
    "#         recov_net = group.ix[(ids, sub_dict['Month of Recov_timestamp']),\n",
    "#                              'gross_charged_off_recovs'] - group.ix[\n",
    "#                                  (ids, sub_dict['Month of Recov_timestamp']\n",
    "#                                   ), 'charged_off_recovs_collection_fees']\n",
    "#         sub_dict['Net Recov'] = recov_net\n",
    "#     else:\n",
    "#         sub_dict['Month of Recov_timestamp'] = sub_dict['Month of Issuance']\n",
    "#         sub_dict['Month of Recov'] = sub_dict['Month of Last Record']\n",
    "#         sub_dict['Net Recov'] = 0\n",
    "    sub_dict['Month of Recov_teimstamp'] = 0\n",
    "    sub_dict['Month of Recov'] = 0\n",
    "    sub_dict['Net Recov'] = group['recov_payments'].values + group['recovs_sale'].values\n",
    "\n",
    "    combined_dict[ids] = sub_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict['185490']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn all the arrays into lists\n",
    "fixed_dict = {}\n",
    "for ids, sub_dict in combined_dict.iteritems():\n",
    "    fixed_dict[ids] = sub_dict\n",
    "    fixed_dict[ids]['Outstandings'] = fixed_dict[ids]['Outstandings'].tolist()\n",
    "    fixed_dict[ids]['Days Late'] = fixed_dict[ids]['Days Late'].tolist()\n",
    "#     fixed_dict[ids]['Status Adjusted Value'] = fixed_dict[ids]['Status Adjusted Value'].tolist()\n",
    "    fixed_dict[ids]['Net Payments'] = fixed_dict[ids]['Net Payments'].tolist()\n",
    "    fixed_dict[ids]['Gross Payments'] = fixed_dict[ids]['Gross Payments'].tolist()\n",
    "    fixed_dict[ids]['Net Recov'] = fixed_dict[ids]['Net Recov'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix some sequence of dates that are missing some dates by filling with 0s \n",
    "fix_counter = 0\n",
    "for ids, group in tqdm_notebook(id_scaled_grouped):\n",
    "    recorded_months = group['date_mapped'].values\n",
    "    expected_months = np.arange(group['issue_d_mapped'].min(), group['date_mapped'].max()+1)\n",
    "    \n",
    "    month_to_index_dict = {}\n",
    "    k = 0\n",
    "    for month in expected_months:\n",
    "        month_to_index_dict[month] = k\n",
    "        k += 1\n",
    "    indicies_to_insert = set(expected_months)^set(recorded_months)\n",
    "#     if ids == '77511438':\n",
    "#         print(indicies_to_insert)\n",
    "    if len(indicies_to_insert) > 0:\n",
    "        fix_counter += 1\n",
    "        for index in indicies_to_insert:\n",
    "            index = month_to_index_dict[index]\n",
    "            fixed_dict[ids]['Outstandings'].insert(index, 0)\n",
    "            fixed_dict[ids]['Days Late'].insert(index, 0)\n",
    "#             fixed_dict[ids]['Status Adjusted Value'].insert(index, 0)\n",
    "            fixed_dict[ids]['Net Payments'].insert(index, 0)\n",
    "            fixed_dict[ids]['Gross Payments'].insert(index, 0)\n",
    "            fixed_dict[ids]['Net Recov'].insert(index, 0)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_dict['185490']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_months = np.arange(date_mapper[last_date] + 1)\n",
    "to_df = {}\n",
    "for ids, sub_dict in tqdm_notebook(fixed_dict.iteritems()):\n",
    "    ids_dict = {}\n",
    "    ids_dict = {k: v for k, v in sub_dict.iteritems()}\n",
    "    \n",
    "#     print(type(sub_dict['Month of Last Record']), type(sub_dict['Month of Issuance']), ids)\n",
    "#     expected_format = sub_dict['Month of Issuance'] < sub_dict['Month of First Record']\n",
    "#     months_diff =  int(sub_dict['Month of First Record'] - sub_dict['Month of Issuance'])\n",
    "#     if expected_format:\n",
    "#         n_months = int(sub_dict['Month of Last Record'] - sub_dict['Month of Issuance']) # or First Record instead of issuance\n",
    "#         new_net_recovs = [0] * n_months\n",
    "#     elif sub_dict['Month of Issuance'] == sub_dict['Month of First Record']:\n",
    "#         n_months = int(sub_dict['Month of Last Record'] - sub_dict['Month of Issuance'])+1\n",
    "#         new_net_recovs = [0] * n_months\n",
    "#     new_net_recovs = [0] * int(len(sub_dict['Outstandings']))\n",
    "    new_net_recovs = sub_dict['Net Recov']\n",
    "    new_outstandings = sub_dict['Outstandings']\n",
    "    new_days_late = sub_dict['Days Late']\n",
    "#     new_stat_adj_value = sub_dict['Status Adjusted Value']\n",
    "    new_gross_payments = sub_dict['Gross Payments']\n",
    "    new_net_payments = sub_dict['Net Payments']\n",
    "\n",
    "#     print(months_diff)\n",
    "#     if months_diff > 1:\n",
    "#         n_zeros_to_prepend = int(months_diff - 1)\n",
    "#         new_outstandings = [0]*n_zeros_to_prepend + new_outstandings\n",
    "#         new_gross_payments = [0]*n_zeros_to_prepend + new_gross_payments\n",
    "#         new_net_payments = [0]*n_zeros_to_prepend + new_net_payments\n",
    "    assert(len(new_net_recovs) == len(new_outstandings)), print(new_net_recovs, len(new_net_recovs), new_outstandings, len(new_outstandings), ids)\n",
    "    assert(len(new_gross_payments) == len(new_outstandings))\n",
    "    assert(len(new_days_late) == len(new_outstandings))\n",
    "#     assert(len(new_stat_adj_value) == len(new_outstandings))\n",
    "    assert(len(new_net_payments) == len(new_outstandings))\n",
    "    \n",
    "    # adding padding before and after the lists as necessary\n",
    "    pad_before = [0] * int(sub_dict['Month of Issuance'])\n",
    "    pad_after = [0] * int(all_months.max() - sub_dict['Month of Last Record'])\n",
    "    \n",
    "    new_outstandings = pad_before + new_outstandings + pad_after\n",
    "    new_days_late = pad_before + new_days_late + pad_after\n",
    "#     new_stat_adj_value = pad_before + new_stat_adj_value + pad_after\n",
    "    new_gross_payments = pad_before + new_gross_payments + pad_after\n",
    "    new_net_payments = pad_before + new_net_payments + pad_after\n",
    "    new_net_recovs = pad_before + new_net_recovs + pad_after\n",
    "    \n",
    "# #     print(pad_after, pad_before, sub_dict['Month of First Record'], sub_dict['Month of Last Record'], ids)\n",
    "    \n",
    "    assert len(new_outstandings) == len(all_months)#, print(len(new_outstandings), len(all_months), ids)\n",
    "#     assert len(new_stat_adj_value) == len(all_months)\n",
    "    assert len(new_days_late) == len(all_months)\n",
    "    assert len(new_gross_payments) == len(all_months)\n",
    "    assert len(new_net_payments) == len(all_months)\n",
    "    assert len(new_net_recovs) == len(all_months)\n",
    "    \n",
    "\n",
    "    ids_dict['Outstandings'] = new_outstandings\n",
    "    ids_dict['Days Late'] = new_days_late\n",
    "#     ids_dict['Status Adjusted Value'] = new_stat_adj_value\n",
    "    ids_dict['Gross Payments'] = new_gross_payments\n",
    "    ids_dict['Net Payments'] = new_net_payments\n",
    "    ids_dict['Net Recov'] = new_net_recovs\n",
    "    to_df[ids] = ids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export_P = pd.DataFrame.from_dict(to_df).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export['plat'] = 'LC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export_P['plat'] = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_export = pd.concat([to_export, to_export_P])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This next bit is just for Stephen because he wanted the payment history for this guy Charles Guest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guest_lc = pd.read_csv('/Users/justinhsi/Downloads/charles_guest_loans_lc.csv')\n",
    "guest_p = pd.read_csv('/Users/justinhsi/Downloads/charles_guest_loans_p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_loans = plat_selected_dfs['LC'][plat_selected_dfs['LC']['id'].isin(guest_lc['loan_id'].astype(str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_loans.to_csv('/Users/justinhsi/Downloads/charles_lc_pmts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_loans = plat_selected_dfs['P'][plat_selected_dfs['P']['LoanID'].isin(guest_p['loan_id'].astype(str))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_export.to_pickle('/Users/justinhsi/LRData/lendingclub/emmanuel_pmts_format.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#185490 , 185266\n",
    "len(to_export_P.ix['185490','Net Recov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payments Reived is net everything but recoveries. It includes principal, interest, late fees (good for investor)\n",
    "# less collection fees and service fees (both bad for investor)\n",
    "# Recovery Payments are payments, assume no fees associated. \n",
    "# NetCashToInvestorsFromDebtSale is different from recovery payments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine = p_loans[p_loans['LoanID'] == '607186']\n",
    "# p_loans[p_loans['NetCashToInvestorsFromDebtSale']==1175.89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_loans[p_loans['RecoveryPayments'] != p_loans['RecoveryPrin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "644.03 + 410.83 + 52.74 - 25.66 - 188.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.pmt(.224800/12, 36, -6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to justin stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adding the actual fully combined stat_adjusted_value column, which is stat_adj_outs_princp if the loan\n",
    "# # made a payment, or stat_adj_outs_princp + stat_adj_acc_int if no payment was received.\n",
    "\n",
    "# scaled['stat_adj_value'] = np.where(\n",
    "#     scaled['pmt_amt_received'] >= scaled['m_amt_due'],\n",
    "#     scaled['stat_adj_outs_princp_end'],\n",
    "#     scaled['stat_adj_outs_princp_end'] +\n",
    "#     scaled['stat_adj_acc_int'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate fake loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fresh_prng(int):\n",
    "    prng = np.random.RandomState(int)\n",
    "    return prng\n",
    "\n",
    "\n",
    "def pmt_amt_received(int_rate, term, loan_amt):\n",
    "    # find what a prototypical loan looks like (36 month, 10% interest rate, fully amortizing)\n",
    "    m_int_rate = int_rate / 12\n",
    "    m_installment = np.pmt(m_int_rate, term, -loan_amt)\n",
    "    pmt_amt_received = [0] + [m_installment] * term\n",
    "    return pd.Series(pmt_amt_received)\n",
    "\n",
    "\n",
    "def rem_outs_princp(int_rate, term, loan_amt):\n",
    "    pmts_list = pmt_amt_received(int_rate, term, loan_amt)\n",
    "    ori_amt = loan_amt\n",
    "    m_int_rate = int_rate / 12\n",
    "    rem_outs_princp_list = [ori_amt]\n",
    "    for i in np.arange(len(pmts_list) - 1):\n",
    "        ori_amt *= (1 + m_int_rate)\n",
    "        ori_amt -= pmts_list[i + 1]\n",
    "        rem_outs_princp_list.append(ori_amt)\n",
    "    return pd.Series(rem_outs_princp_list)\n",
    "\n",
    "\n",
    "def gross_charged_off_recovs(term):\n",
    "    return pd.Series([0] * (term + 1))\n",
    "\n",
    "\n",
    "def charged_off_recovs_collection_fees(term):\n",
    "    return pd.Series([0] * (term + 1))\n",
    "\n",
    "\n",
    "def m_on_books(term):\n",
    "    return pd.Series(np.arange(term + 1))\n",
    "\n",
    "\n",
    "def set_loan_counter():\n",
    "    global loan_counter\n",
    "    loan_counter = 0\n",
    "\n",
    "\n",
    "def increment_loan_counter():\n",
    "    global loan_counter\n",
    "    loan_counter += 1\n",
    "\n",
    "def make_late_loan_history(int_rate, term, loan_amt):\n",
    "    pass\n",
    "    \n",
    "def make_loan_history(int_rate, term, loan_amt):\n",
    "    df_dict = {}\n",
    "    df_dict['pmt_amt_received'] = pmt_amt_received(int_rate, term, loan_amt)\n",
    "    df_dict['rem_outs_princp_end'] = rem_outs_princp(int_rate, term, loan_amt)\n",
    "    df_dict['gross_charged_off_recovs'] = gross_charged_off_recovs(term)\n",
    "    df_dict[\n",
    "        'charged_off_recovs_collection_fees'] = charged_off_recovs_collection_fees(\n",
    "            term)\n",
    "    df_dict['m_on_books'] = m_on_books(term)\n",
    "    df_dict['id'] = loan_counter\n",
    "    m_int_rate = int_rate / 12\n",
    "    df_dict['pmt_to_int'] = np.where(df_dict['pmt_amt_received'] == 0, 0,\n",
    "                                     df_dict['rem_outs_princp_end'].shift(1) *\n",
    "                                     m_int_rate)\n",
    "    df_dict['acc_int'] = df_dict['pmt_to_int']\n",
    "    df_dict['pmt_to_princp'] = np.where(\n",
    "        df_dict['pmt_amt_received'] == 0, 0,\n",
    "        df_dict['pmt_amt_received'] - df_dict['pmt_to_int'])\n",
    "    increment_loan_counter()\n",
    "    return pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "\n",
    "def add_rem_outs_princp_beg(loan_history):\n",
    "    loan_history['rem_outs_princp_beg'] = loan_history[\n",
    "        'rem_outs_princp_end'].shift(1)\n",
    "    return loan_history\n",
    "\n",
    "\n",
    "def make_fake_pmt_history(loan,\n",
    "                          start_date,\n",
    "                          m_worth_of_pmts,\n",
    "                          seed_number,\n",
    "                          random_loans_per_month=True,\n",
    "                          growing_loan_amounts=False):\n",
    "    set_loan_counter()\n",
    "    global loan_counter\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    int_rate = loan['int_rate']\n",
    "    term = loan['term']\n",
    "    loan_amt = loan['loan_amt']\n",
    "    prng = fresh_prng(seed_number)\n",
    "    \n",
    "    if growing_loan_amounts:\n",
    "        month_num = np.arange(m_worth_of_pmts)\n",
    "        growth_rate = [1+.3/12] * m_worth_of_pmts\n",
    "        multiplier = np.power(growth_rate,month_num)\n",
    "    else:\n",
    "        multiplier = np.array([1] * m_worth_of_pmts)\n",
    "        \n",
    "    if random_loans_per_month == True:\n",
    "        loans_per_month = prng.randint(2, 20, m_worth_of_pmts)\n",
    "    else:\n",
    "        loans_per_month = [20] * (m_worth_of_pmts)\n",
    "    loans_per_month = np.multiply(np.array(loans_per_month), multiplier)\n",
    "    segment_to_concat = []\n",
    "    for i in np.arange(len(loans_per_month)):\n",
    "        s_date = start_date + pd.DateOffset(months=+i)\n",
    "        n_loans = loans_per_month[i]\n",
    "        to_concat = []\n",
    "        date_col = []\n",
    "        for i in np.arange(n_loans):\n",
    "            to_concat.append(\n",
    "                add_rem_outs_princp_beg(\n",
    "                    make_loan_history(int_rate, term, loan_amt)))\n",
    "            date_col.extend(\n",
    "                pd.date_range(s_date, periods=term + 1, freq='MS').tolist())\n",
    "        segment = pd.concat(to_concat)\n",
    "        segment['date'] = date_col\n",
    "        segment_to_concat.append(segment)\n",
    "    complete = pd.concat(segment_to_concat)\n",
    "    return complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2010-01-01')\n",
    "loan={}\n",
    "loan['int_rate'] = .10\n",
    "loan['term'] = 36\n",
    "loan['loan_amt'] = 100\n",
    "m_int_rate = loan['int_rate']\n",
    "term = loan['term']\n",
    "loan_amt = loan['loan_amt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 200 months of data, 20 loans per month with growth rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history = make_fake_pmt_history(loan, start_date, 80, 42, False, True)\n",
    "# quick rename\n",
    "test_history.rename(columns={'pmt_to_int':'gross_pmt_to_int',\n",
    "                             'pmt_to_princp':'gross_pmt_to_princp',\n",
    "                             'rem_outs_princp_end':'outs_princp_end',\n",
    "                             'rem_outs_princp_beg':'outs_princp_beg'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history['status'] = 'current'\n",
    "test_history['stat_adj_outs_princp_end'] = test_history['outs_princp_end']\n",
    "test_history['charged_off'] = 0\n",
    "test_history['m_amt_due'] = np.pmt(m_int_rate, term, -loan_amt)\n",
    "test_history['stat_adj_value'] = test_history['stat_adj_outs_princp_end']\n",
    "test_history['rate'] = m_int_rate*12\n",
    "test_history['service_fees'] = test_history['pmt_amt_received']*.01\n",
    "test_history['stat_adj_acc_int'] = test_history['acc_int']\n",
    "test_history['charged_off_amt'] = 0\n",
    "test_history['issue_d'] = start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summing_std_pmt_history(std_pmt_hist, test = False):\n",
    "    result = {}\n",
    "    seen_id_set = set()\n",
    "    date_grouped = std_pmt_hist.groupby('date')\n",
    "    \n",
    "    k = 0\n",
    "    for date, group in date_grouped:\n",
    "        sub_dict = {}\n",
    "        \n",
    "        newly_funded_loans = group[~group['id'].isin(seen_id_set)]\n",
    "        newly_funded_ids = newly_funded_loans['id'].unique()\n",
    "        seen_ids = group['id'].unique()\n",
    "        seen_id_set.update(seen_ids)\n",
    "        \n",
    "        new_funds_needed = 0\n",
    "        for new_ids in newly_funded_ids:\n",
    "            if test == False:\n",
    "                new_funds_needed += plat_dict[plat][new_ids]\n",
    "            elif test == 'all':\n",
    "                new_funds_needed += lc_funded_dict[new_ids]\n",
    "            else:\n",
    "                new_funds_needed += 100\n",
    "        \n",
    "        # split group into 2 groups, those that don't pay in origination month and \n",
    "        # those that do, then split up work and combine in sums\n",
    "        pay_at_ori_group = group[(group['date'] == group['issue_d']) & (group['pmt_amt_received'] > 0)]\n",
    "        \n",
    "        other_group = group[~group['id'].isin(pay_at_ori_group['id'].values)]\n",
    "        \n",
    "#         deconstructed_seen_ids = set(np.concatenate([pay_at_ori_group['id'].values, other_group['id'].values]))\n",
    "#         print(type(seen_ids))\n",
    "#         print(set(seen_ids)^deconstructed_seen_ids)\n",
    "        \n",
    "        assert len(group) == (len(pay_at_ori_group) + len(other_group))#, print(len(group), len(pay_at_ori_group), len(other_group), date)\n",
    "        \n",
    "        #other_group\n",
    "        outs_princp_end = other_group['outs_princp_end'].sum()\n",
    "        outs_princp_beg = other_group['outs_princp_beg'].sum()\n",
    "        gross_pmt_to_princp = other_group['gross_pmt_to_princp'].sum()\n",
    "        gross_pmt_to_int = other_group['gross_pmt_to_int'].sum()\n",
    "        acc_int = other_group['acc_int'].sum()\n",
    "        stat_adj_acc_int = other_group['stat_adj_acc_int'].sum()\n",
    "        stat_adj_outs_princp_end = other_group['stat_adj_outs_princp_end'].sum()\n",
    "        stat_adj_value = other_group['stat_adj_value'].sum()\n",
    "        pmt_amt_received = other_group['pmt_amt_received'].sum()\n",
    "        gross_charged_off_recovs = other_group['gross_charged_off_recovs'].sum()\n",
    "        charged_off_recovs_collection_fees = other_group[\n",
    "            'charged_off_recovs_collection_fees'].sum()\n",
    "        service_fees = other_group['service_fees'].sum()\n",
    "        \n",
    "        #pay at ori group\n",
    "        outs_princp_end += pay_at_ori_group['outs_princp_end'].sum()\n",
    "        outs_princp_beg += pay_at_ori_group['outs_princp_end'].sum() + pay_at_ori_group['gross_pmt_to_princp'].sum()\n",
    "        gross_pmt_to_princp += pay_at_ori_group['gross_pmt_to_princp'].sum()\n",
    "        gross_pmt_to_int += pay_at_ori_group['gross_pmt_to_int'].sum()\n",
    "        acc_int += pay_at_ori_group['acc_int'].sum()\n",
    "        stat_adj_acc_int += pay_at_ori_group['stat_adj_acc_int'].sum()\n",
    "        stat_adj_outs_princp_end += pay_at_ori_group['stat_adj_outs_princp_end'].sum()\n",
    "        stat_adj_value += pay_at_ori_group['stat_adj_value'].sum()\n",
    "        pmt_amt_received += pay_at_ori_group['pmt_amt_received'].sum()\n",
    "        gross_charged_off_recovs += pay_at_ori_group['gross_charged_off_recovs'].sum()\n",
    "        charged_off_recovs_collection_fees += pay_at_ori_group[\n",
    "            'charged_off_recovs_collection_fees'].sum()\n",
    "        service_fees += pay_at_ori_group['service_fees'].sum()\n",
    "\n",
    "        sub_dict['outs_princp_end'] = outs_princp_end\n",
    "        sub_dict['outs_princp_beg'] = outs_princp_beg\n",
    "        sub_dict['pmt_amt_received'] = pmt_amt_received\n",
    "        sub_dict['gross_pmt_to_princp'] = gross_pmt_to_princp\n",
    "        sub_dict['gross_pmt_to_int'] = gross_pmt_to_int\n",
    "        sub_dict['acc_int'] = acc_int\n",
    "        sub_dict['gross_charged_off_recovs'] = gross_charged_off_recovs\n",
    "        sub_dict[\n",
    "            'charged_off_recovs_collection_fees'] = charged_off_recovs_collection_fees\n",
    "        sub_dict['service_fees'] = service_fees\n",
    "        sub_dict['n_newly_funded_loans'] = len(newly_funded_ids)\n",
    "        sub_dict['new_funds_needed'] = new_funds_needed\n",
    "        sub_dict['new_investor_cash'] = max(\n",
    "            0, new_funds_needed - pmt_amt_received)\n",
    "        sub_dict['stat_adj_acc_int'] = stat_adj_acc_int\n",
    "        sub_dict['stat_adj_outs_princp_end'] = stat_adj_outs_princp_end\n",
    "        sub_dict['stat_adj_value'] = stat_adj_value\n",
    "\n",
    "        result[date] = sub_dict\n",
    "        df = pd.DataFrame.from_dict(result).T\n",
    "        df['stat_adj_outs_princp_end_no_newly_funded'] = df['stat_adj_outs_princp_end'] - df['new_funds_needed']\n",
    "        df['stat_adj_value_no_newly_funded'] = df['stat_adj_value'] - df['new_funds_needed']\n",
    "    return df\n",
    "\n",
    "def compute_unit_values(beg_unit_value, summed_pmt_hist, LR_fee = True):\n",
    "    summed_pmt_hist = summed_pmt_hist.fillna(0)\n",
    "    summed_pmt_hist['beg_unit_value'] = '?'\n",
    "    summed_pmt_hist['new_units_created'] = '?'\n",
    "    summed_pmt_hist['units_beg'] = '?'\n",
    "    summed_pmt_hist['units_end'] = '?'\n",
    "    summed_pmt_hist['beg_value'] = '?'\n",
    "    summed_pmt_hist['total_cash'] = '?'\n",
    "    summed_pmt_hist['total_note_value'] = '?'\n",
    "    summed_pmt_hist['LR_fee'] = '?'\n",
    "    summed_pmt_hist['beg_value_netfee'] = '?'\n",
    "    #     summed_pmt_hist['outs_princp_end_no_newly_issued'] = summed_pmt_hist[\n",
    "    #         'outs_princp_end'] - summed_pmt_hist['new_funds_needed']\n",
    "    for i in np.arange(len(summed_pmt_hist)):\n",
    "        if i == 0:\n",
    "            summed_pmt_hist.ix[i, 'beg_unit_value'] = beg_unit_value\n",
    "            summed_pmt_hist.ix[i, 'units_beg'] = 0\n",
    "            summed_pmt_hist.ix[i, 'new_units_created'] = max(\n",
    "                0, summed_pmt_hist.ix[i, 'new_investor_cash'] /\n",
    "                summed_pmt_hist.ix[i, 'beg_unit_value'])\n",
    "            summed_pmt_hist.ix[i, 'units_end'] = summed_pmt_hist.ix[\n",
    "                i, 'units_beg'] + summed_pmt_hist.ix[i, 'new_units_created']\n",
    "            summed_pmt_hist.ix[i, 'end_unit_value'] = beg_unit_value\n",
    "            summed_pmt_hist.ix[i, 'dragging_cash_netfee_from_this_period'] = 0\n",
    "            summed_pmt_hist.ix[i, 'prev_undeployed_cash'] = 0\n",
    "            summed_pmt_hist.ix[i, 'beg_value'] = summed_pmt_hist.ix[\n",
    "                i, 'units_end'] * summed_pmt_hist.ix[i, 'beg_unit_value']\n",
    "            summed_pmt_hist.ix[i, 'beg_value_netfee'] = summed_pmt_hist.ix[\n",
    "                i, 'units_end'] * summed_pmt_hist.ix[i, 'beg_unit_value']\n",
    "            summed_pmt_hist.ix[i, 'total_cash'] = 0\n",
    "            summed_pmt_hist.ix[i, 'total_note_value'] = summed_pmt_hist.ix[\n",
    "                i, 'new_investor_cash']\n",
    "            summed_pmt_hist.ix[i, 'LR_fee'] = 0\n",
    "\n",
    "        else:\n",
    "            #             ratio = summed_pmt_hist.ix[i, 'outs_princp_beg'] = summed_pmt_hist.ix[i-1, 'total_note_value_netfee']\n",
    "            summed_pmt_hist.ix[i, 'prev_undeployed_cash'] = summed_pmt_hist.ix[\n",
    "                i - 1, 'dragging_cash_netfee_from_this_period']\n",
    "            summed_pmt_hist.ix[i, 'units_beg'] = summed_pmt_hist.ix[\n",
    "                i - 1, 'units_end']\n",
    "\n",
    "            # All Cash:\n",
    "            cash = (\n",
    "                summed_pmt_hist.ix[i, 'pmt_amt_received'] -\n",
    "                summed_pmt_hist.ix[i, 'service_fees'] +\n",
    "                summed_pmt_hist.ix[i, 'gross_charged_off_recovs'] -\n",
    "                summed_pmt_hist.ix[i, 'charged_off_recovs_collection_fees'] +\n",
    "                summed_pmt_hist.ix[i, 'prev_undeployed_cash']\n",
    "            )  # idle cash this period before receiving payments, netfee from this period\n",
    "\n",
    "            summed_pmt_hist.ix[i, 'total_cash'] = cash\n",
    "\n",
    "            \n",
    "            # Applying our discount for note value definitely changes the value of things a lot.\n",
    "            note_value = summed_pmt_hist.ix[i,\n",
    "                                            'stat_adj_value_no_newly_funded']\n",
    "#             note_value = summed_pmt_hist.ix[i,\n",
    "#                                             'outs_princp_end'] - summed_pmt_hist.ix[i,\n",
    "#                                             'new_funds_needed']            \n",
    "\n",
    "            summed_pmt_hist.ix[i, 'total_note_value'] = note_value\n",
    "\n",
    "            summed_pmt_hist.ix[i, 'beg_value'] = cash + note_value\n",
    "            if LR_fee == True:\n",
    "                summed_pmt_hist.ix[i, 'LR_fee'] = summed_pmt_hist.ix[\n",
    "                    i, 'beg_value'] * (.0045 / 12)\n",
    "            else:\n",
    "                summed_pmt_hist.ix[i, 'LR_fee'] = summed_pmt_hist.ix[\n",
    "                    i, 'beg_value'] * 0\n",
    "\n",
    "            summed_pmt_hist.ix[i, 'beg_value_netfee'] = (\n",
    "                summed_pmt_hist.ix[i, 'beg_value'] -\n",
    "                summed_pmt_hist.ix[i, 'LR_fee'])\n",
    "\n",
    "            summed_pmt_hist.ix[i, 'beg_unit_value'] = (\n",
    "                summed_pmt_hist.ix[i, 'beg_value_netfee'] /\n",
    "                summed_pmt_hist.ix[i, 'units_beg'])\n",
    "\n",
    "            summed_pmt_hist.ix[i, 'new_investor_cash'] = max(\n",
    "                0, summed_pmt_hist.ix[i, 'new_funds_needed'] -\n",
    "                (cash - summed_pmt_hist.ix[i, 'LR_fee']))\n",
    "            summed_pmt_hist.ix[i, 'new_units_created'] = summed_pmt_hist.ix[\n",
    "                i, 'new_investor_cash'] / summed_pmt_hist.ix[i,\n",
    "                                                             'beg_unit_value']\n",
    "            summed_pmt_hist.ix[i, 'units_end'] = summed_pmt_hist.ix[\n",
    "                i, 'units_beg'] + summed_pmt_hist.ix[i, 'new_units_created']\n",
    "            summed_pmt_hist.ix[\n",
    "                i, 'dragging_cash_netfee_from_this_period'] = max(\n",
    "                    0, (cash - summed_pmt_hist.ix[i, 'LR_fee']\n",
    "                        ) - summed_pmt_hist.ix[i, 'new_funds_needed'])\n",
    "            # This SHOULD match beg_unit_value but it is off by a few cents????\n",
    "            summed_pmt_hist.ix[i, 'end_unit_value'] = (\n",
    "                summed_pmt_hist.ix[i, 'beg_value_netfee'] +\n",
    "                summed_pmt_hist.ix[i, 'new_investor_cash']  # + \n",
    "                #                 summed_pmt_hist.ix[i, 'dragging_cash']\n",
    "            ) / (summed_pmt_hist.ix[i, 'units_end'])\n",
    "\n",
    "    # adding return\n",
    "    summed_pmt_hist['return'] = (summed_pmt_hist['end_unit_value'] /\n",
    "                                 summed_pmt_hist['end_unit_value'].shift(1)\n",
    "                                 ) - 1\n",
    "    summed_pmt_hist['ann_return'] = (summed_pmt_hist['end_unit_value'] /\n",
    "                                     summed_pmt_hist['end_unit_value'].shift(1)\n",
    "                                     )**12 - 1\n",
    "    \n",
    "    # adding pct dollar discount\n",
    "    summed_pmt_hist['outs_princp_end_no_newly_funded'] = summed_pmt_hist['outs_princp_end'] - summed_pmt_hist['new_funds_needed']\n",
    "    summed_pmt_hist['dollar_discount'] = summed_pmt_hist['outs_princp_end_no_newly_funded'] - summed_pmt_hist['total_note_value']\n",
    "    summed_pmt_hist['dollar_discount_pct'] = summed_pmt_hist['dollar_discount']/summed_pmt_hist['outs_princp_end_no_newly_funded']\n",
    "\n",
    "    return summed_pmt_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_summed_pmt_hist = summing_std_pmt_history(test_history, test=True)\n",
    "fake_results_with_fee = compute_unit_values(100, fake_summed_pmt_hist)\n",
    "fake_results_no_fee = compute_unit_values(100, fake_summed_pmt_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fake_results_no_fee.index, fake_results_no_fee['ann_return'], label='no_fee')\n",
    "plt.plot(fake_results_with_fee.index, fake_results_with_fee['ann_return'], label='with_fee')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_results_with_fee[['LR_fee', 'total_cash', 'total_note_value', 'dragging_cash_netfee_from_this_period']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_history.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_compute_unit_values(beg_unit_value, std_pmt_hist, test=False):\n",
    "    result = {}\n",
    "    seen_id_set = set()\n",
    "    if test == False:\n",
    "        date_grouped = std_pmt_hist.groupby('date_mapped')\n",
    "    else:\n",
    "        date_grouped = std_pmt_hist.groupby('date')\n",
    "    k = 0\n",
    "    for date, group in date_grouped:\n",
    "        sub_dict = {}\n",
    "        \n",
    "        if test == False:\n",
    "            print(group['issue_d_mapped'].value_counts(dropna=False))\n",
    "        newly_funded_loans = group[~group['id'].isin(seen_id_set)]\n",
    "        newly_funded_ids = newly_funded_loans['id'].unique()\n",
    "        seen_ids = group['id'].unique()\n",
    "        seen_id_set.update(seen_ids)\n",
    "\n",
    "        new_funds_needed = 0\n",
    "        for new_ids in newly_funded_ids:\n",
    "            if test == False:\n",
    "                new_funds_needed += plat_dict[plat][new_ids]\n",
    "            elif test == 'all':\n",
    "                new_funds_needed += lc_funded_dict[new_ids]\n",
    "            else:\n",
    "                new_funds_needed += 100\n",
    "\n",
    "        # split group into 2 groups, those that don't pay in origination month and \n",
    "        # those that do, then split up work and combine in sums\n",
    "        if test == False:\n",
    "            pay_at_ori_group = group[(group['date_mapped'] == group['issue_d_mapped']) &\n",
    "                                     (group['pmt_amt_received'] > 0)]\n",
    "\n",
    "            other_group = group[~group['id'].isin(pay_at_ori_group['id'].values)]\n",
    "        else:\n",
    "            pay_at_ori_group = group[(group['date'] == group['issue_d']) &\n",
    "                                     (group['pmt_amt_received'] > 0)]\n",
    "\n",
    "            other_group = group[~group['id'].isin(pay_at_ori_group['id'].values)]\n",
    "\n",
    "        assert len(group) == (len(pay_at_ori_group) + len(other_group))\n",
    "\n",
    "        #other_group\n",
    "        stat_adj_value = other_group['stat_adj_value'].sum()\n",
    "        pmt_amt_received = other_group['pmt_amt_received'].sum()\n",
    "        gross_charged_off_recovs = other_group[\n",
    "            'gross_charged_off_recovs'].sum()\n",
    "        charged_off_recovs_collection_fees = other_group[\n",
    "            'charged_off_recovs_collection_fees'].sum()\n",
    "        service_fees = other_group['service_fees'].sum()\n",
    "\n",
    "        #pay at ori group\n",
    "        stat_adj_value += pay_at_ori_group['stat_adj_value'].sum()\n",
    "        pmt_amt_received += pay_at_ori_group['pmt_amt_received'].sum()\n",
    "        gross_charged_off_recovs += pay_at_ori_group[\n",
    "            'gross_charged_off_recovs'].sum()\n",
    "        charged_off_recovs_collection_fees += pay_at_ori_group[\n",
    "            'charged_off_recovs_collection_fees'].sum()\n",
    "        service_fees += pay_at_ori_group['service_fees'].sum()\n",
    "\n",
    "        sub_dict['stat_adj_value'] = stat_adj_value\n",
    "        sub_dict['pmt_amt_received'] = pmt_amt_received\n",
    "        sub_dict['gross_charged_off_recovs'] = gross_charged_off_recovs\n",
    "        sub_dict[\n",
    "            'charged_off_recovs_collection_fees'] = charged_off_recovs_collection_fees\n",
    "        sub_dict['service_fees'] = service_fees\n",
    "        sub_dict['n_newly_funded_loans'] = len(newly_funded_ids)\n",
    "        sub_dict['new_funds_needed'] = new_funds_needed\n",
    "        sub_dict['stat_adj_value_no_newly_funded'] = sub_dict[\n",
    "            'stat_adj_value'] - new_funds_needed\n",
    "        result[date] = sub_dict\n",
    "\n",
    "    df = pd.DataFrame.from_dict(result).T\n",
    "    df['prev_dragging_cash'] = '?'\n",
    "    df['stat_adj_value_no_newly_funded'] = df['stat_adj_value'] - df[\n",
    "        'new_funds_needed']\n",
    "    df['beg_value'] = '?'\n",
    "    df['LR_fee'] = '?'\n",
    "    df['beg_value_netfee'] = '?'\n",
    "    df['units_beg'] = '?'\n",
    "    df['beg_unit_value'] = '?'\n",
    "    df['new_investor_cash'] = '?'\n",
    "    df['new_units_created'] = '?'\n",
    "    df['units_end'] = '?'\n",
    "    df['end_unit_value'] = '?'\n",
    "    df['dragging_cash'] = '?'\n",
    "\n",
    "    # iterate row after row to fill in the blanks\n",
    "    for _ in np.arange(len(df)):\n",
    "        if _ == 0:\n",
    "            df.ix[_, 'prev_dragging_cash'] = 0\n",
    "            df.ix[_, 'beg_value'] = df.ix[\n",
    "                _, 'stat_adj_value_no_newly_funded'] + df.ix[\n",
    "                    _, 'prev_dragging_cash']\n",
    "            df.ix[_, 'LR_fee'] = df.ix[_, 'beg_value'] * .0045/12\n",
    "#             df.ix[_, 'LR_fee'] = df.ix[_, 'new_funds_needed'] * .0045/12\n",
    "            df.ix[_, 'beg_value_netfee'] = df.ix[_, 'beg_value'] - df.ix[\n",
    "                _, 'service_fees'] - df.ix[_, 'LR_fee']\n",
    "            df.ix[_, 'units_beg'] = 0\n",
    "            df.ix[_, 'beg_unit_value'] = beg_unit_value\n",
    "            df.ix[_, 'new_investor_cash'] = df.ix[_, 'new_funds_needed']\n",
    "            df.ix[_, 'new_units_created'] = df.ix[\n",
    "                _, 'new_investor_cash'] / df.ix[_, 'beg_unit_value']\n",
    "            df.ix[_, 'units_end'] = df.ix[_, 'new_units_created'] + df.ix[\n",
    "                _, 'units_beg']\n",
    "            df.ix[_, 'end_unit_value'] = (\n",
    "                df.ix[_, 'beg_value_netfee'] + df.ix[_, 'new_investor_cash']\n",
    "            ) / df.ix[_, 'units_end']\n",
    "            df.ix[_, 'dragging_cash'] = 0\n",
    "        else:\n",
    "            df.ix[_, 'prev_dragging_cash'] = df.ix[_ - 1, 'dragging_cash']\n",
    "            df.ix[_, 'beg_value'] = (df.ix[_, 'stat_adj_value_no_newly_funded'] +\n",
    "                                     df.ix[_, 'pmt_amt_received'] - \n",
    "                                     df.ix[_, 'service_fees'] + \n",
    "                                     df.ix[_, 'gross_charged_off_recovs'] -\n",
    "                                     df.ix[_, 'charged_off_recovs_collection_fees'] + \n",
    "                                     df.ix[_, 'prev_dragging_cash'])\n",
    "            df.ix[_, 'LR_fee'] = df.ix[_, 'beg_value'] * .0045/12\n",
    "            df.ix[_, 'beg_value_netfee'] = df.ix[_, 'beg_value'] - df.ix[_, 'LR_fee']\n",
    "            df.ix[_, 'units_beg'] = df.ix[_-1, 'units_end']\n",
    "            df.ix[_, 'beg_unit_value'] = df.ix[_, 'beg_value_netfee']/df.ix[_, 'units_beg']\n",
    "            df.ix[_, 'new_investor_cash'] = max(0, df.ix[_, 'new_funds_needed'] - \n",
    "                                                   (df.ix[_, 'pmt_amt_received'] -\n",
    "                                                 df.ix[_, 'service_fees'] + \n",
    "                                                 df.ix[_, 'gross_charged_off_recovs'] -\n",
    "                                                 df.ix[_, 'charged_off_recovs_collection_fees'] + \n",
    "                                                 df.ix[_, 'prev_dragging_cash'] -\n",
    "                                                 df.ix[_, 'LR_fee']))\n",
    "            df.ix[_, 'new_units_created'] = df.ix[\n",
    "                _, 'new_investor_cash'] / df.ix[_, 'beg_unit_value']\n",
    "            df.ix[_, 'units_end'] = df.ix[_, 'new_units_created'] + df.ix[\n",
    "                _, 'units_beg']\n",
    "            df.ix[_, 'end_unit_value'] = (\n",
    "                df.ix[_, 'beg_value_netfee'] + df.ix[_, 'new_investor_cash']\n",
    "            ) / df.ix[_, 'units_end']\n",
    "            df.ix[_, 'dragging_cash'] = max(0, df.ix[_, 'pmt_amt_received'] -\n",
    "                                         df.ix[_, 'service_fees'] + \n",
    "                                         df.ix[_, 'gross_charged_off_recovs'] -\n",
    "                                         df.ix[_, 'charged_off_recovs_collection_fees'] + \n",
    "                                         df.ix[_, 'prev_dragging_cash'] -\n",
    "                                         df.ix[_, 'LR_fee'] -\n",
    "                                         df.ix[_, 'new_funds_needed'])\n",
    "            \n",
    "#             pmt_amt_received - service_fees + gross_charged_off_recovs -\n",
    "#              charged_off_recovs_collection_fees\n",
    "            \n",
    "#             df.ix[_, 'dragging_cash'] = max(\n",
    "#                 0, (df.ix[_, 'pmt_amt_received'] - df.ix[_, 'service_fees'] +\n",
    "#                     df.ix[_, 'gross_charged_off_recovs'] -\n",
    "#                     df.ix[_, 'charged_off_recovs_collection_fees'] -\n",
    "#                     df.ix[_, 'LR_fee']) - df.ix[_, 'new_funds_needed'])\n",
    "    df['return'] = df['end_unit_value']/df['end_unit_value'].shift(1)-1\n",
    "    df['ann_return'] = (1+df['return'])**12-1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_approach(beg_unit_value, pmts_hist):\n",
    "    months = pmts_hist['date_mapped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine = combined_compute_unit_values(100, scaled, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.drop_duplicates('id')['issue_d_mapped'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_mapped_grouped = scaled.groupby('date_mapped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = date_mapped_grouped.get_group(1)\n",
    "group1[group1['issue_d_mapped'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export.ix['17814923']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export[to_export['Month of Issuance'] == 1]['Month of First Record'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export[to_export['Month of Issuance'] == 0]['Month of First Record'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export[(to_export['Month of Issuance'] == 0) & (to_export['Month of First Record'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df[original_df['LOAN_ID'] == '15471076']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.ix['15471076']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating small loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten_loan_ids = np.random.choice(scaled_to_invest_amt_dfs['LC']['id'].unique(), 10)\n",
    "# examine_ids = ['11696485', '74492661', '20006612', '17744006']\n",
    "prepaid_id_1 = ['10024615']\n",
    "prepaid_id_2 = ['738934']\n",
    "gone_late_and_paid_id_1 = ['16382558']\n",
    "gone_late_and_paid_id_2 = ['16240827']\n",
    "defaulted_id_1 = ['11696485']\n",
    "defaulted_id_2 = ['75173629']\n",
    "random_3_ids_1 = np.random.choice(plat_selected_dfs['LC']['id'].unique(), 3, replace = False)\n",
    "\n",
    "random_10_ids_1 = np.random.choice(plat_selected_dfs['LC']['id'].unique(), 10, replace = False)\n",
    "\n",
    "random_ids = np.random.choice(plat_selected_dfs['LC']['id'].unique(), 50000, replace = False)\n",
    "\n",
    "\n",
    "test_id = random_ids\n",
    "examine = scaled_to_invest_amt_dfs['LC'][scaled_to_invest_amt_dfs['LC']['id'].isin(test_id)]\n",
    "summed_examine = summing_std_pmt_history(examine)\n",
    "unit_vals = compute_unit_values(100, summed_examine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_to_invest_amt_dfs['LC'][scaled_to_invest_amt_dfs['LC']['id'].isin(test_id)][['date', 'm_amt_due', 'pmt_amt_received', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_vals[['new_investor_cash', 'pmt_amt_received', 'service_fees', 'beg_unit_value', 'new_units_created', 'units_beg', 'units_end', 'total_cash', 'total_note_value', 'beg_value_netfee', 'end_unit_value', 'prev_undeployed_cash', 'ann_return']]#, 'dollar_discount', 'dollar_discount_pct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_vals['ann_return'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All unit value stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loans_unit_vals = compute_unit_values(100, summing_std_pmt_history(scaled_to_invest_amt_dfs['LC']))\n",
    "all_loans_unit_vals['outs_princp_end_no_newly_funded'] = all_loans_unit_vals['outs_princp_end'] - all_loans_unit_vals['new_funds_needed']\n",
    "all_loans_unit_vals['dollar_discount'] = all_loans_unit_vals['outs_princp_end_no_newly_funded'] - all_loans_unit_vals['total_note_value']\n",
    "all_loans_unit_vals['dollar_discount_pct'] = all_loans_unit_vals['dollar_discount']/all_loans_unit_vals['outs_princp_end_no_newly_funded']\n",
    "all_loans_unit_vals['return'] = all_loans_unit_vals['end_unit_value']/all_loans_unit_vals['end_unit_value'].shift(1)-1\n",
    "all_loans_unit_vals['ann_return'] = (all_loans_unit_vals['end_unit_value']/all_loans_unit_vals['end_unit_value'].shift(1))**12-1\n",
    "all_loans_unit_vals['ann_return'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loans_unit_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loans_unit_vals[['LR_fee', 'total_cash', 'total_note_value']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_loans_unit_vals['gross_charged_off_recovs']/all_loans_unit_vals['dollar_discount'].shift(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do unit value comparison for all lendingclub loans in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_store = '/Users/justinhsi/LRData/lendingclub/lendingclub_store.h5'\n",
    "lc_iterator = pd.read_hdf(datapath_store, 'clean_pmt_history', chunksize = 200000)\n",
    "\n",
    "merge_lc = []\n",
    "for chunk in tqdm_notebook(lc_iterator):\n",
    "    merge_lc.append(chunk)\n",
    "all_lc_pmt_hist = pd.concat(merge_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lc_pmt_hist = lc_rename_cols(all_lc_pmt_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop loans with multiple entries per month just for ease of computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many loans do have a double entry in same month\n",
    "print(all_lc_pmt_hist.shape)\n",
    "loans_with_two_entries_in_same_month = all_lc_pmt_hist[all_lc_pmt_hist.duplicated(['id', 'date'])]\n",
    "all_lc_pmt_hist = all_lc_pmt_hist[~all_lc_pmt_hist['id'].isin(loans_with_two_entries_in_same_month['id'].values)]\n",
    "print(all_lc_pmt_hist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find a way to chunk through the dataframe because the kernel crashes otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cols_lc(all_lc_pmt_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_lc_pmt_hist['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lc_pmt_hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_record_each = all_lc_pmt_hist.drop_duplicates(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_funded_dict = dict(zip(one_record_each['id'], one_record_each['outs_princp_beg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lc_summed_pmt_hist = summing_std_pmt_history(all_lc_pmt_hist, test='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lc_summed_pmt_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
