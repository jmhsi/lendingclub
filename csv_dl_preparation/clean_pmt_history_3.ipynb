{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Justin Hsi\n",
    "## Part 3 of cleaning lending club payment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dir_constants as dc\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_previous_record(ids, issue_d, first_date, actual_months, month):\n",
    "    '''This function finds the closest previous month that is in the group. \n",
    "    It is here to handle cases where a record of one month is missing, but the\n",
    "    record before that missing month is also missing.'''\n",
    "    offset = pd.DateOffset(months=-1)\n",
    "    prev_month = month + offset\n",
    "    if month < issue_d:\n",
    "        print(ids)\n",
    "        return first_date\n",
    "    elif prev_month in actual_months:\n",
    "        return prev_month\n",
    "    else:\n",
    "        find_closest_previous_record(ids, issue_d, first_date, actual_months, prev_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'lendingclub'\n",
    "\n",
    "store =  pd.HDFStore(\n",
    "    dc.home_path+'/justin_tinkering/data_science/lendingclub/{0}_store.h5'.\n",
    "    format(platform),\n",
    "    append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are loans that have multiple row entries per month (as in multiple pmts in same month) and there are also loans that don't have any entry for a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix loans with no record at all for a specific month ________________________\n",
    "pmt_hist_ids = store['pmt_hist_ids'].astype(int)\n",
    "max_id = pmt_hist_ids.max()\n",
    "chunksize = 800\n",
    "n_chunks = len(pmt_hist_ids)//chunksize + 1\n",
    "\n",
    "already_good_dfs = []\n",
    "better_sized_already_good_dfs = []\n",
    "fixed_dfs = []\n",
    "# k = 0\n",
    "for n in tqdm_notebook(np.arange(n_chunks)):\n",
    "    if n == 0:\n",
    "        left_bound = 0\n",
    "    else:\n",
    "        left_bound = pmt_hist_ids[n*chunksize]\n",
    "    if n == (n_chunks - 1):\n",
    "        right_bound = max_id\n",
    "    else:\n",
    "        right_bound = pmt_hist_ids[(n+1)*chunksize]\n",
    "    \n",
    "    chunk = pd.read_hdf(\n",
    "        store,\n",
    "        'pmt_hist_intermediary_2',\n",
    "        where='(loan_id_num > left_bound) & (loan_id_num <= right_bound)')\n",
    "    \n",
    "    id_grouped = chunk.groupby('loan_id')\n",
    "    for ids, group in id_grouped:\n",
    "        # Copy Paste finished below\n",
    "        issue_d = group['issue_d'].min()\n",
    "        first_date = group['date'].min()\n",
    "        last_date = group['date'].max()\n",
    "        expected_months = set(pd.DatetimeIndex(start=first_date, end=last_date, freq='MS'))\n",
    "        actual_months = set(group['date'])\n",
    "        to_make_months = list(expected_months.symmetric_difference(actual_months))\n",
    "        to_make_months.sort()\n",
    "        if len(to_make_months) > 1:\n",
    "            months_to_copy = []\n",
    "            for month in to_make_months:\n",
    "                months_to_copy.append(find_closest_previous_record(ids, issue_d, first_date, actual_months, month))\n",
    "            copied = group[group['date'].isin(months_to_copy)].copy()\n",
    "            copied['amt_paid'] = 0.0\n",
    "            copied['date'] = to_make_months\n",
    "            copied['amt_due'] = np.where(copied['date'] < first_date, 0, copied['amt_due'])\n",
    "            fixed_dfs.append(pd.concat([group, copied]))\n",
    "        else:\n",
    "            already_good_dfs.append(group)\n",
    "            if len(already_good_dfs) == chunksize:\n",
    "                better_sized_already_good_dfs.append(pd.concat(already_good_dfs))\n",
    "                already_good_dfs = []\n",
    "            if n+1 == n_chunks: # if on the last chunk\n",
    "                better_sized_already_good_dfs.append(pd.concat(already_good_dfs))\n",
    "                already_good_dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create min_itemsize_dict for allocating size when storing ___________________\n",
    "min_itemsize_dict = {}\n",
    "#arbitrarily take last 10000 to hopefully be long enough for min item size\n",
    "example = pd.concat(better_sized_already_good_dfs[-20:]) \n",
    "for col in example.columns:\n",
    "    if example[col].dtype == np.object:\n",
    "        print(col, example[col].str.len().max())\n",
    "        if col in ['State', 'VINTAGE', 'grade']:\n",
    "            pass\n",
    "        else:\n",
    "            min_itemsize_dict[col] = 15\n",
    "\n",
    "col_dtype_map = better_sized_already_good_dfs[0].dtypes.to_dict()\n",
    "all_fixed_dfs = pd.concat(fixed_dfs)\n",
    "for col, dtype in col_dtype_map.items():\n",
    "    all_fixed_dfs[col] = all_fixed_dfs[col].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for chunk in tqdm_notebook([all_fixed_dfs] + better_sized_already_good_dfs):\n",
    "    sorted_chunk = chunk.sort_values(['loan_id', 'date'])\n",
    "    if k == 0:\n",
    "        store.append(\n",
    "            'pmt_hist_clean',\n",
    "            sorted_chunk,\n",
    "            data_columns=True,\n",
    "            index=True,\n",
    "            append=False,\n",
    "            min_itemsize=min_itemsize_dict)\n",
    "        k += 1\n",
    "    else:\n",
    "        store.append(\n",
    "            'pmt_hist_clean',\n",
    "            sorted_chunk,\n",
    "            data_columns=True,\n",
    "            index=True,\n",
    "            append=True)       \n",
    "        \n",
    "store.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "598px",
    "left": "361px",
    "right": "279px",
    "top": "11px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
