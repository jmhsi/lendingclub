{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:37:00.033270Z",
     "start_time": "2019-06-27T22:37:00.015166Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../lc_utils.py\n",
    "import pandas as pd\n",
    "from j_utils import munging as mg\n",
    "import hyperlearn.hyperlearn.impute.SVDImpute as hpl_imp\n",
    "\n",
    "def gen_expt_datasets(today, oldest, valid_start, base_loan_info, eval_loan_info, target, valid_end=None, verbose=False):\n",
    "    '''\n",
    "    all loans from oldest until today are taken as train. All loans issued after today until valid_end are used for validation. Uses hyperlearn svd_impute to impute missing values. Returns the train and test datasets. target can be single colname or list of colnames\n",
    "    '''\n",
    "    train_ids = eval_loan_info[(eval_loan_info['issue_d'] <= today) & (eval_loan_info['issue_d'] >= oldest)]['id'].unique()\n",
    "    if valid_end:\n",
    "        valid_ids = eval_loan_info[(eval_loan_info['issue_d'] >= valid_start) & (eval_loan_info['issue_d'] <= valid_end)]['id'].unique()\n",
    "    else:\n",
    "        valid_ids = eval_loan_info[(eval_loan_info['issue_d'] >= valid_start)]['id'].unique()\n",
    "    train = base_loan_info[base_loan_info['id'].isin(train_ids)]\n",
    "    valid = base_loan_info[base_loan_info['id'].isin(valid_ids)]\n",
    "    \n",
    "    # setup for catboost\n",
    "    # a bit more data processing and nan handling for catboost\n",
    "    train_copy = train.copy()\n",
    "    valid_copy = valid.copy()\n",
    "    \n",
    "    # get ready for hyperlearn svdimpute\n",
    "    train_copy, max_dict, min_dict, cats_dict, norm_dict = mg.train_hpl_proc(train_copy, verbose=verbose)\n",
    "    valid_copy = mg.val_test_hpl_proc(valid_copy, train_copy, max_dict, min_dict, cats_dict, verbose=verbose)\n",
    "\n",
    "    # fit to train\n",
    "    S, VT, mean, std, mins, standardise = hpl_imp.fit(train_copy.values)\n",
    "    \n",
    "    # impute on train\n",
    "    train_svdimp = hpl_imp.transform(train_copy.values, S, VT, mean, std, mins, standardise)\n",
    "    train_svdimp = pd.DataFrame(train_svdimp)\n",
    "    train_svdimp.index = train_copy.index\n",
    "    train_svdimp.columns = train_copy.columns\n",
    "    \n",
    "    # impute on test\n",
    "    valid_svdimp = hpl_imp.transform(valid_copy.values, S, VT, mean, std, mins, standardise)\n",
    "    valid_svdimp = pd.DataFrame(valid_svdimp)\n",
    "    valid_svdimp.index = valid_copy.index\n",
    "    valid_svdimp.columns = valid_copy.columns\n",
    "    \n",
    "    # imputing changes some ids. Make the ids the originals again.\n",
    "    train_svdimp['id'] = train_ids\n",
    "    valid_svdimp['id'] = valid_ids\n",
    "    \n",
    "    train_y = eval_loan_info[eval_loan_info['id'].isin(train_ids)][target]\n",
    "    valid_y = eval_loan_info[eval_loan_info['id'].isin(valid_ids)][target]\n",
    "    \n",
    "    return train_svdimp, train_y, valid_svdimp, valid_y, train_ids, valid_ids\n",
    "\n",
    "# make a crude test set for now\n",
    "def get_split_date(df, date_column, quantile): \n",
    "\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/31018622/pandas-quantile-function-for-dates\n",
    "    Get the date on which to split a dataframe for timeseries splitting\n",
    "    Adjusted coerce param to errors since SO is old.\n",
    "    \"\"\" \n",
    "\n",
    "    # 1. convert date_column to datetime (useful in case it is a string) \n",
    "    # 2. convert into int (for sorting) \n",
    "    # 3. get the quantile \n",
    "    # 4. get the corresponding date\n",
    "    # 5. return, pray that it works \n",
    "\n",
    "    quantile_date = pd.to_datetime(df[date_column], errors = 'raise').astype('int64').quantile(q=quantile)#.astype('datetime64[ns]')\n",
    "\n",
    "    return pd.to_datetime(quantile_date)\n",
    "\n",
    "def split_out_traintestable_loans(df, eval_df, oldness_thrsh=.9):\n",
    "    '''Can train/test on loans that pass the oldness_thrsh or have status paid/defaulted/charged_off'''\n",
    "    old_enough_ids = eval_df[(eval_df['maturity_time_stat_adj'] >= oldness_thrsh) | \n",
    "                                    (eval_df['maturity_paid_stat_adj'] >= oldness_thrsh) | \n",
    "                                    (eval_df['loan_status'].isin(['paid', 'defaulted', 'charged_off']))]['id'].unique()\n",
    "    df = df[df['id'].isin(old_enough_ids)]\n",
    "    eval_df = eval_df[eval_df['id'].isin(old_enough_ids)]\n",
    "    return df, eval_df\n",
    "\n",
    "\n",
    "def add_custom_lc_features(df):\n",
    "    # added features\n",
    "    df['monthly_inc'] = df['annual_inc'] / 12\n",
    "    df['dti_w_loan'] = (df['dti'] * df['monthly_inc'] +\n",
    "                                    df['installment']) / df['monthly_inc']\n",
    "    df['delinq_to_monthly_inc'] = df['delinq_amnt'] / \\\n",
    "        df['monthly_inc']\n",
    "    df['tot_cur_bal_to_monthly_inc'] = df['tot_cur_bal'] / \\\n",
    "        df['monthly_inc']\n",
    "    df['loan_to_inc'] = df['loan_amount'] / \\\n",
    "        df['monthly_inc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
