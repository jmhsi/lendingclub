{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/lct14558/imbalanced-data-why-you-should-not-use-roc-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T23:36:13.585668Z",
     "start_time": "2019-09-03T23:36:12.743300Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "sys.path.append(os.path.join(os.path.expanduser('~'), 'projects'))\n",
    "import j_utils.munging as mg\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,auc,precision_recall_curve,roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ppath = os.path.join(os.path.expanduser('~'), 'projects', 'lendingclub', )\n",
    "dpath = os.path.join(ppath,'data')\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T23:36:18.200472Z",
     "start_time": "2019-09-03T23:36:18.177092Z"
    }
   },
   "outputs": [],
   "source": [
    "check_cols = ['maturity_time', 'maturity_paid', 'maturity_time_stat_adj', 'maturity_paid_stat_adj',\n",
    "              'target_loose', 'target_strict', 'loan_status', 'issue_d', 'end_d', 'id']\n",
    "good_statuses = ['paid', 'current']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T23:36:23.052167Z",
     "start_time": "2019-09-03T23:36:19.473822Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_loan_info = pd.read_feather(os.path.join(dpath,'eval_loan_info.fth'))\n",
    "# scaled_pmt_hist = pd.read_feather(os.path.join(dpath,'scaled_pmt_hist.fth'))\n",
    "base_loan_info = pd.read_feather(os.path.join(dpath,'base_loan_info.fth'))\n",
    "# str_loan_info = pd.read_feather(os.path.join(dpath,'str_loan_info.fth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T23:36:53.574426Z",
     "start_time": "2019-09-03T23:36:53.108914Z"
    }
   },
   "outputs": [],
   "source": [
    "# get loans that are >= .95 maturity time, maturity paid, or status is in defaulted, charged_off, paid\n",
    "trainable_loan_ids = eval_loan_info[(eval_loan_info['maturity_time_stat_adj'] >= .95) |\n",
    "                               (eval_loan_info['maturity_paid_stat_adj'] >= .95) |\n",
    "                               (eval_loan_info['loan_status'].isin(['paid', 'charged_off', 'defaulted']))\n",
    "                              ]['id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# fix step to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:23.329419Z",
     "start_time": "2019-08-18T08:32:22.855659Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# quick fix to eval_loan_info, future times see if this cell needs to be run\n",
    "eval_loan_info['maturity_time_stat_adj'] = np.where(\n",
    "    (eval_loan_info['maturity_time_stat_adj'] == -1) & (eval_loan_info['loan_status'] == 'paid'), 1,\n",
    "         np.where(\n",
    "             (eval_loan_info['maturity_time_stat_adj'] == -1) & (eval_loan_info['loan_status'] == 'current'), \n",
    " eval_loan_info['maturity_time'], eval_loan_info['maturity_time_stat_adj']))\n",
    "\n",
    "eval_loan_info['maturity_paid_stat_adj'] = np.where(\n",
    "    (eval_loan_info['maturity_paid_stat_adj'] == -1) & (eval_loan_info['loan_status'] == 'paid'), 1,\n",
    "         np.where(\n",
    "             (eval_loan_info['maturity_paid_stat_adj'] == -1) & (eval_loan_info['loan_status'] == 'current'), \n",
    " eval_loan_info['maturity_paid'], eval_loan_info['maturity_paid_stat_adj']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:25.364650Z",
     "start_time": "2019-08-18T08:32:23.462809Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_loan_info.to_feather(os.path.join(dpath,'eval_loan_info.fth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:25.387518Z",
     "start_time": "2019-08-18T08:32:25.367033Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(eval_loan_info['maturity_paid_stat_adj'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T03:12:22.213240Z",
     "start_time": "2019-08-18T03:12:22.186869Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(eval_loan_info['maturity_time_stat_adj'] < 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T00:10:36.424519Z",
     "start_time": "2019-08-18T00:10:36.406416Z"
    }
   },
   "source": [
    "# continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T23:37:18.159079Z",
     "start_time": "2019-09-03T23:37:17.210692Z"
    }
   },
   "outputs": [],
   "source": [
    "trainable_loans = eval_loan_info[eval_loan_info['id'].isin(trainable_loan_ids)]\n",
    "untrainable_loans = eval_loan_info[~eval_loan_info['id'].isin(trainable_loan_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T23:37:18.430138Z",
     "start_time": "2019-09-03T23:37:18.161181Z"
    }
   },
   "outputs": [],
   "source": [
    "# make sure untrainable loans actually look untrainable\n",
    "untrainable_loans.groupby('loan_status',).apply(lambda x: x.sample(min(len(x), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure untrainable loans actually look untrainable\n",
    "untrainable_loans.groupby('loan_status',).apply(lambda x: x.sample(min(len(x), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:28:59.630352Z",
     "start_time": "2019-08-18T23:28:58.861254Z"
    }
   },
   "outputs": [],
   "source": [
    "trainable_eli = trainable_loans\n",
    "trainable_li = base_loan_info[base_loan_info['id'].isin(trainable_loan_ids)]\n",
    "print(trainable_eli.shape, trainable_li.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:40:49.498209Z",
     "start_time": "2019-08-18T23:40:43.862023Z"
    }
   },
   "outputs": [],
   "source": [
    "df = trainable_li.merge(trainable_eli[['target_strict', 'id', 'loan_status']], on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split into time_series_cv splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:40:50.533467Z",
     "start_time": "2019-08-18T23:40:49.499773Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('loan_status', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:40:50.678604Z",
     "start_time": "2019-08-18T23:40:50.535501Z"
    }
   },
   "outputs": [],
   "source": [
    "# get categorical feature indices for catboost\n",
    "obj_cols = df.select_dtypes(['object', 'datetime']).columns\n",
    "categorical_features_indices = [df.columns.get_loc(col) for col in obj_cols]\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:22.608486Z",
     "start_time": "2019-08-18T23:40:50.680153Z"
    }
   },
   "outputs": [],
   "source": [
    "# map dates and strings to numbers\n",
    "date_cols = df.select_dtypes(['datetime', 'object']).columns\n",
    "for col in date_cols:\n",
    "    mapper = {np.NaN: 0}\n",
    "    for i, val in enumerate(sorted(df[col].unique()), 1):\n",
    "        mapper[val] = i\n",
    "    df[col] = df[col].replace(mapper)\n",
    "    if col == 'issue_d':\n",
    "        issue_d_mapper = mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:23.394364Z",
     "start_time": "2019-08-18T23:42:23.163098Z"
    }
   },
   "outputs": [],
   "source": [
    "# for scikit, make sure everything is number and nulls are filled\n",
    "non_num_cols = df.select_dtypes(['object', 'datetime']).columns\n",
    "assert len(non_num_cols) == 0\n",
    "df.fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:23.784460Z",
     "start_time": "2019-08-18T23:42:23.395837Z"
    }
   },
   "outputs": [],
   "source": [
    "# split out the test set, say the last 12 months\n",
    "test = df[df['issue_d'] >= (df['issue_d'].max() - 12)]\n",
    "train = df[df['issue_d'] < (df['issue_d'].max() - 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:23.878738Z",
     "start_time": "2019-08-18T23:42:23.785830Z"
    }
   },
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:23.957971Z",
     "start_time": "2019-08-18T23:42:23.880169Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:23.974509Z",
     "start_time": "2019-08-18T23:42:23.959845Z"
    }
   },
   "outputs": [],
   "source": [
    "# see if theres any difference in pct defaulted from train and test\n",
    "print(test['target_strict'].sum()/len(test), train['target_strict'].sum()/len(train))\n",
    "\n",
    "# a slightly higher percentage of defaulting loans. This makes sense due to defaulting loans finishing faster, thus being able to be included in trainable loans, compared to ongoing loans that won't default but still need to reach term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:23.987231Z",
     "start_time": "2019-08-18T23:42:23.976118Z"
    }
   },
   "outputs": [],
   "source": [
    "# basic split for now, probably some leakage (using some loans issued in same month for train and validation. Go with this for now, come back and make better custom splits later)\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:23.999159Z",
     "start_time": "2019-08-18T23:42:23.988426Z"
    }
   },
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:24.014305Z",
     "start_time": "2019-08-18T23:42:24.000349Z"
    }
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in tscv.split(train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:24.651585Z",
     "start_time": "2019-08-18T23:42:24.015609Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train['target_strict']\n",
    "train.drop('target_strict', axis=1, inplace=True)\n",
    "X = train\n",
    "\n",
    "X_train = X.iloc[train_index,:]\n",
    "y_train = y.iloc[train_index]\n",
    "\n",
    "X_valid = X.iloc[test_index,:]\n",
    "y_valid = y.iloc[test_index]\n",
    "\n",
    "y_test = test['target_strict']\n",
    "test.drop('target_strict', axis=1, inplace=True)\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:42:24.666736Z",
     "start_time": "2019-08-18T23:42:24.652855Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_non_def, y_test_def = y_test.value_counts()\n",
    "y_test_non_def, y_test_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:43:30.271202Z",
     "start_time": "2019-08-18T23:43:30.232158Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:46:08.544651Z",
     "start_time": "2019-08-18T23:46:08.519418Z"
    }
   },
   "outputs": [],
   "source": [
    "def PlotConfusionMatrix(y_test,pred,y_test_legit,y_test_fraud):\n",
    "\n",
    "    cfn_matrix = confusion_matrix(y_test,pred)\n",
    "    cfn_norm_matrix = np.array([[1.0 / y_test_legit,1.0/y_test_legit],[1.0/y_test_fraud,1.0/y_test_fraud]])\n",
    "    norm_cfn_matrix = cfn_matrix * cfn_norm_matrix\n",
    "\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    sns.heatmap(cfn_matrix,cmap='coolwarm_r',linewidths=1,annot=True,ax=ax)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Real Classes')\n",
    "    plt.xlabel('Predicted Classes')\n",
    "\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    sns.heatmap(norm_cfn_matrix,cmap='coolwarm_r',linewidths=1,annot=True,ax=ax)\n",
    "\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.ylabel('Real Classes')\n",
    "    plt.xlabel('Predicted Classes')\n",
    "    plt.show()\n",
    "    \n",
    "    print('---Classification Report---')\n",
    "    print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:44:44.209068Z",
     "start_time": "2019-08-18T23:44:44.178057Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:46:10.905587Z",
     "start_time": "2019-08-18T23:46:10.553170Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "pred = lr_model.predict(X_test)\n",
    "PlotConfusionMatrix(y_test,pred,y_test_non_def,y_test_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:49:01.475537Z",
     "start_time": "2019-08-18T23:48:07.883040Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(class_weight='balanced')\n",
    "lr_model.fit(X_train, y_train)\n",
    "pred = lr_model.predict(X_test)\n",
    "PlotConfusionMatrix(y_test,pred,y_test_non_def,y_test_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:53:56.462203Z",
     "start_time": "2019-08-18T23:50:44.539668Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for w in [1,5,10,100,500,1000]:\n",
    "    print('---Weight of {} for Default class---'.format(w))\n",
    "    lr_model = LogisticRegression(class_weight={0:1,1:w})\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    pred = lr_model.predict(X_test)\n",
    "    PlotConfusionMatrix(y_test,pred,y_test_non_def,y_test_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T23:58:21.907630Z",
     "start_time": "2019-08-18T23:54:53.085663Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.set_xlim([-0.05,1.05])\n",
    "ax1.set_ylim([-0.05,1.05])\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title('PR Curve')\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.set_xlim([-0.05,1.05])\n",
    "ax2.set_ylim([-0.05,1.05])\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title('ROC Curve')\n",
    "\n",
    "for w,k in zip([1,5,10,20,50,100,10000],'bgrcmykw'):\n",
    "    lr_model = LogisticRegression(class_weight={0:1,1:w})\n",
    "    lr_model.fit(X_train,y_train)\n",
    "    pred_prob = lr_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    p,r,_ = precision_recall_curve(y_test,pred_prob)\n",
    "    tpr,fpr,_ = roc_curve(y_test,pred_prob)\n",
    "    \n",
    "    ax1.plot(r,p,c=k,label=w)\n",
    "    ax2.plot(tpr,fpr,c=k,label=w)\n",
    "ax1.legend(loc='lower left')    \n",
    "ax2.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:53.860654Z",
     "start_time": "2019-08-18T08:33:53.845605Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a custom loss function that puts more emphasis on missclasifying defaulting\n",
    "class CustomObjective(object):\n",
    "    '''\n",
    "    for derivations\n",
    "    https://stats.stackexchange.com/questions/231220/how-to-compute-the-gradient-and-hessian-of-logarithmic-loss-question-is-based\n",
    "    https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x\n",
    "    https://socratic.org/questions/what-is-the-derivative-of-e-x-8\n",
    "    '''\n",
    "    \n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "        \n",
    "        result = []\n",
    "        for index in range(len(targets)):\n",
    "            e = np.exp(approxes[index])\n",
    "            p = e / (1 + e)\n",
    "            # der 1 and 2 have negative in front because they are gradient?\n",
    "            der1 = 4*(-1)*(p - 1) if targets[index] > 0.0 else -p\n",
    "            der2 = -p * (1 - p)\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:39:38.932618Z",
     "start_time": "2019-08-18T08:39:38.910149Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': 1000,\n",
    "#     'one_hot_max_size': 45,\n",
    "#     'learning_rate': 0.01,\n",
    "    'has_time': True,\n",
    "    'eval_metric': 'Accuracy',\n",
    "    'random_seed': 42,\n",
    "    'logging_level': 'Silent',\n",
    "    'use_best_model': True,\n",
    "    'task_type': 'GPU',\n",
    "    'boosting_type': 'Ordered',\n",
    "#     'loss_function': 'Log',\n",
    "    'custom_metric': ['F1', 'Precision', 'Recall', 'Accuracy', 'AUC'],\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:39:40.169364Z",
     "start_time": "2019-08-18T08:39:40.148493Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:42:05.152407Z",
     "start_time": "2019-08-18T08:39:40.582078Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_valid, y_valid),\n",
    "#     logging_level='Verbose',  # you can uncomment this for text output\n",
    "    plot=True\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:58:44.642830Z",
     "start_time": "2019-08-18T08:58:44.619017Z"
    }
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "def hyperopt_objective(params):\n",
    "    model = CatBoostClassifier(**params)\n",
    "    \n",
    "    print(model.get_params())\n",
    "    \n",
    "    cv_data = cv(\n",
    "        Pool(X, y, cat_features=categorical_features_indices),\n",
    "        model.get_params(),\n",
    "        type = 'TimeSeries',\n",
    "        plot=True,\n",
    "    )\n",
    "    best_accuracy = np.max(cv_data['test-Accuracy-mean'])\n",
    "    \n",
    "    return 1 - best_accuracy # as hyperopt minimises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T14:11:25.335137Z",
     "start_time": "2019-08-18T08:58:45.233514Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "params_space = {\n",
    "    'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n",
    "    'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 5e-1),\n",
    "#     'iterations': 1000,\n",
    "#     'one_hot_max_size': 45,\n",
    "#     'learning_rate': 0.01,\n",
    "    'has_time': True,\n",
    "    'eval_metric': 'Accuracy',\n",
    "    'random_seed': 42,\n",
    "    'logging_level': 'Silent',\n",
    "    'use_best_model': True,\n",
    "    'task_type': 'GPU',\n",
    "    'boosting_type': 'Ordered',\n",
    "    'loss_function': 'Logloss',\n",
    "#     'custom_metric': ['F1', 'Precision', 'Recall', 'Accuracy', 'AUC'],\n",
    "#     'od_type': 'Iter',\n",
    "#     'od_wait': 300,\n",
    "}\n",
    "\n",
    "trials = hyperopt.Trials()\n",
    "\n",
    "best = hyperopt.fmin(\n",
    "    hyperopt_objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(123)\n",
    ")\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:58:05.646808Z",
     "start_time": "2019-08-18T08:58:05.606113Z"
    }
   },
   "outputs": [],
   "source": [
    "cv??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
