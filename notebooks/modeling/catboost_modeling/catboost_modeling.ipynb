{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T00:37:47.396267Z",
     "start_time": "2019-08-19T00:37:47.365903Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "sys.path.append(os.path.join(os.path.expanduser('~'), 'projects'))\n",
    "import j_utils.munging as mg\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,auc,precision_recall_curve,roc_curve, accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "\n",
    "ppath = os.path.join(os.path.expanduser('~'), 'projects', 'lendingclub', )\n",
    "dpath = os.path.join(ppath,'data')\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:18.658117Z",
     "start_time": "2019-08-18T08:32:18.637774Z"
    }
   },
   "outputs": [],
   "source": [
    "check_cols = ['maturity_time', 'maturity_paid', 'maturity_time_stat_adj', 'maturity_paid_stat_adj',\n",
    "              'target_loose', 'target_strict', 'loan_status', 'issue_d', 'end_d', 'id']\n",
    "good_statuses = ['paid', 'current']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:20.187636Z",
     "start_time": "2019-08-18T08:32:19.464917Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_loan_info = pd.read_feather(os.path.join(dpath,'eval_loan_info.fth'))\n",
    "# scaled_pmt_hist = pd.read_feather(os.path.join(dpath,'scaled_pmt_hist.fth'))\n",
    "base_loan_info = pd.read_feather(os.path.join(dpath,'base_loan_info.fth'))\n",
    "# str_loan_info = pd.read_feather(os.path.join(dpath,'str_loan_info.fth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:20.213762Z",
     "start_time": "2019-08-18T08:32:20.189550Z"
    }
   },
   "outputs": [],
   "source": [
    "# add in issue_d\n",
    "base_loan_info['issue_d'] = eval_loan_info['issue_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:21.454002Z",
     "start_time": "2019-08-18T08:32:21.000161Z"
    }
   },
   "outputs": [],
   "source": [
    "# get loans that are >= .95 maturity time, maturity paid, or status is in defaulted, charged_off, paid\n",
    "trainable_loan_ids = eval_loan_info[(eval_loan_info['maturity_time_stat_adj'] >= .95) |\n",
    "                               (eval_loan_info['maturity_paid_stat_adj'] >= .95) |\n",
    "                               (eval_loan_info['loan_status'].isin(['paid', 'charged_off', 'defaulted']))\n",
    "                              ]['id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# fix step to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:23.329419Z",
     "start_time": "2019-08-18T08:32:22.855659Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# quick fix to eval_loan_info, future times see if this cell needs to be run\n",
    "eval_loan_info['maturity_time_stat_adj'] = np.where(\n",
    "    (eval_loan_info['maturity_time_stat_adj'] == -1) & (eval_loan_info['loan_status'] == 'paid'), 1,\n",
    "         np.where(\n",
    "             (eval_loan_info['maturity_time_stat_adj'] == -1) & (eval_loan_info['loan_status'] == 'current'), \n",
    " eval_loan_info['maturity_time'], eval_loan_info['maturity_time_stat_adj']))\n",
    "\n",
    "eval_loan_info['maturity_paid_stat_adj'] = np.where(\n",
    "    (eval_loan_info['maturity_paid_stat_adj'] == -1) & (eval_loan_info['loan_status'] == 'paid'), 1,\n",
    "         np.where(\n",
    "             (eval_loan_info['maturity_paid_stat_adj'] == -1) & (eval_loan_info['loan_status'] == 'current'), \n",
    " eval_loan_info['maturity_paid'], eval_loan_info['maturity_paid_stat_adj']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:25.364650Z",
     "start_time": "2019-08-18T08:32:23.462809Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eval_loan_info.to_feather(os.path.join(dpath,'eval_loan_info.fth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:25.387518Z",
     "start_time": "2019-08-18T08:32:25.367033Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(eval_loan_info['maturity_paid_stat_adj'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T03:12:22.213240Z",
     "start_time": "2019-08-18T03:12:22.186869Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(eval_loan_info['maturity_time_stat_adj'] < 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T00:10:36.424519Z",
     "start_time": "2019-08-18T00:10:36.406416Z"
    }
   },
   "source": [
    "# continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:42.212563Z",
     "start_time": "2019-08-18T08:32:41.275666Z"
    }
   },
   "outputs": [],
   "source": [
    "trainable_loans = eval_loan_info[eval_loan_info['id'].isin(trainable_loan_ids)]\n",
    "untrainable_loans = eval_loan_info[~eval_loan_info['id'].isin(trainable_loan_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:42.470839Z",
     "start_time": "2019-08-18T08:32:42.214201Z"
    }
   },
   "outputs": [],
   "source": [
    "# make sure untrainable loans actually look untrainable\n",
    "untrainable_loans.groupby('loan_status',).apply(lambda x: x.sample(min(len(x), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:43.884597Z",
     "start_time": "2019-08-18T08:32:43.117334Z"
    }
   },
   "outputs": [],
   "source": [
    "trainable_eli = trainable_loans\n",
    "trainable_li = base_loan_info[base_loan_info['id'].isin(trainable_loan_ids)]\n",
    "print(trainable_eli.shape, trainable_li.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:49.846094Z",
     "start_time": "2019-08-18T08:32:44.047401Z"
    }
   },
   "outputs": [],
   "source": [
    "df = trainable_li.merge(trainable_eli[['target_strict', 'id', 'loan_status']], on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split into time_series_cv splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:50.912284Z",
     "start_time": "2019-08-18T08:32:49.847723Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop('loan_status', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:32:51.061407Z",
     "start_time": "2019-08-18T08:32:50.914272Z"
    }
   },
   "outputs": [],
   "source": [
    "# get categorical feature indices for catboost\n",
    "obj_cols = df.select_dtypes(['object', 'datetime']).columns\n",
    "categorical_features_indices = [df.columns.get_loc(col) for col in obj_cols]\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:52.156357Z",
     "start_time": "2019-08-18T08:32:51.062773Z"
    }
   },
   "outputs": [],
   "source": [
    "# map dates to numbers\n",
    "date_cols = df.select_dtypes('datetime').columns\n",
    "for col in date_cols:\n",
    "    mapper = {}\n",
    "    for i, val in enumerate(sorted(df[col].unique())):\n",
    "        mapper[val] = i\n",
    "    df[col] = df[col].replace(mapper)\n",
    "    if col == 'issue_d':\n",
    "        issue_d_mapper = mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:52.172909Z",
     "start_time": "2019-08-18T08:33:52.157864Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(issue_d_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:52.632248Z",
     "start_time": "2019-08-18T08:33:52.176577Z"
    }
   },
   "outputs": [],
   "source": [
    "# split out the test set, say the last 12 months\n",
    "test = df[df['issue_d'] >= (df['issue_d'].max() - 12)]\n",
    "train = df[df['issue_d'] < (df['issue_d'].max() - 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:52.710212Z",
     "start_time": "2019-08-18T08:33:52.634022Z"
    }
   },
   "outputs": [],
   "source": [
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:52.784221Z",
     "start_time": "2019-08-18T08:33:52.711512Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:52.798969Z",
     "start_time": "2019-08-18T08:33:52.785555Z"
    }
   },
   "outputs": [],
   "source": [
    "# see if theres any difference in pct defaulted from train and test\n",
    "print(test['target_strict'].sum()/len(test), train['target_strict'].sum()/len(train))\n",
    "\n",
    "# a slightly higher percentage of defaulting loans. This makes sense due to defaulting loans finishing faster, thus being able to be included in trainable loans, compared to ongoing loans that won't default but still need to reach term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:53.070078Z",
     "start_time": "2019-08-18T08:33:52.800315Z"
    }
   },
   "outputs": [],
   "source": [
    "# basic split for now, probably some leakage (using some loans issued in same month for train and validation. Go with this for now, come back and make better custom splits later)\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:53.084228Z",
     "start_time": "2019-08-18T08:33:53.072337Z"
    }
   },
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:20:22.622294Z",
     "start_time": "2019-08-19T01:20:22.594520Z"
    }
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in tscv.split(train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:53.844141Z",
     "start_time": "2019-08-18T08:33:53.130723Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train['target_strict']\n",
    "train.drop('target_strict', axis=1, inplace=True)\n",
    "X = train\n",
    "\n",
    "X_train = X.iloc[train_index,:]\n",
    "y_train = y.iloc[train_index]\n",
    "\n",
    "X_valid = X.iloc[test_index,:]\n",
    "y_valid = y.iloc[test_index]\n",
    "\n",
    "y_test = test['target_strict']\n",
    "test.drop('target_strict', axis=1, inplace=True)\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T08:33:53.860654Z",
     "start_time": "2019-08-18T08:33:53.845605Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a custom loss function that puts more emphasis on missclasifying defaulting\n",
    "class CustomObjective(object):\n",
    "    '''\n",
    "    for derivations\n",
    "    https://stats.stackexchange.com/questions/231220/how-to-compute-the-gradient-and-hessian-of-logarithmic-loss-question-is-based\n",
    "    https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x\n",
    "    https://socratic.org/questions/what-is-the-derivative-of-e-x-8\n",
    "    '''\n",
    "    \n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "        \n",
    "        result = []\n",
    "        for index in range(len(targets)):\n",
    "            e = np.exp(approxes[index])\n",
    "            p = e / (1 + e)\n",
    "            # der 1 and 2 have negative in front because they are gradient?\n",
    "            der1 = 4*(-1)*(p - 1) if targets[index] > 0.0 else -p\n",
    "            der2 = -p * (1 - p)\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:02:19.355623Z",
     "start_time": "2019-08-19T01:02:19.331368Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': 1000,\n",
    "#     'one_hot_max_size': 45,\n",
    "#     'learning_rate': 0.01,\n",
    "    'has_time': True,\n",
    "    'eval_metric': 'Logloss',\n",
    "    'random_seed': 42,\n",
    "    'logging_level': 'Silent',\n",
    "    'use_best_model': True,\n",
    "    'task_type': 'GPU',\n",
    "    'boosting_type': 'Ordered',\n",
    "#     'loss_function': 'Log',\n",
    "    'custom_metric': ['F1', 'Precision', 'Recall', 'Accuracy', 'AUC'],\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:02:19.684499Z",
     "start_time": "2019-08-19T01:02:19.657669Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:03:41.731715Z",
     "start_time": "2019-08-19T01:02:21.353480Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_valid, y_valid),\n",
    "#     logging_level='Verbose',  # you can uncomment this for text output\n",
    "    plot=True\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:03:42.001554Z",
     "start_time": "2019-08-19T01:03:41.733469Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:03:42.022754Z",
     "start_time": "2019-08-19T01:03:42.003641Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:03:42.036856Z",
     "start_time": "2019-08-19T01:03:42.023999Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:03:42.205273Z",
     "start_time": "2019-08-19T01:03:42.038050Z"
    }
   },
   "outputs": [],
   "source": [
    "# eval_metric = Logloss\n",
    "p,r,_ = precision_recall_curve(y_test, pred_prob[:,1])\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.set_xlim([-0.05,1.05])\n",
    "ax1.set_ylim([-0.05,1.05])\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title('PR Curve')\n",
    "\n",
    "ax1.plot(r, p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T01:01:31.529894Z",
     "start_time": "2019-08-19T01:01:31.357222Z"
    }
   },
   "outputs": [],
   "source": [
    "# eval_metric = Recall\n",
    "p,r,_ = precision_recall_curve(y_test, pred_prob[:,1])\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.set_xlim([-0.05,1.05])\n",
    "ax1.set_ylim([-0.05,1.05])\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title('PR Curve')\n",
    "\n",
    "ax1.plot(r, p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T00:40:26.722718Z",
     "start_time": "2019-08-19T00:40:26.519553Z"
    }
   },
   "outputs": [],
   "source": [
    "# eval_metric = AUC\n",
    "p,r,_ = precision_recall_curve(y_test, pred_prob[:,1])\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.set_xlim([-0.05,1.05])\n",
    "ax1.set_ylim([-0.05,1.05])\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title('PR Curve')\n",
    "\n",
    "ax1.plot(r, p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-18T21:06:48.632590Z",
     "start_time": "2019-08-18T21:06:48.605690Z"
    }
   },
   "source": [
    "# hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what matters:\n",
    "# according to P/R-plots above, best eval_metric is probably Logloss\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T02:52:22.090160Z",
     "start_time": "2019-08-19T02:52:22.060778Z"
    }
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "\n",
    "def hyperopt_objective(params_holder):\n",
    "    '''pick 500 loans, trying to maximize return'''\n",
    "    to_store = {}\n",
    "    \n",
    "#     # corrections to params\n",
    "#     params_holder['cb']['one_hot_max_size'] = int(params_holder['cb']['one_hot_max_size'])\n",
    "    params = params_holder['cb']\n",
    "    cv_params = params_holder['cv']\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train, cat_features=categorical_features_indices,\n",
    "              eval_set=(X_valid, y_valid), logging_level='Silent', plot=True)\n",
    "    \n",
    "    # get predictions on test\n",
    "    pred_probs = model.predict_proba(X_test)[:,1]\n",
    "    pred_ser = pd.Series(data=pred_probs, index=X_test['id'].values)\n",
    "    pred_ser.sort_values(inplace=True) #ascending\n",
    "    \n",
    "    # get top 200 at 7% discount rate\n",
    "    returns = eval_loan_info[eval_loan_info['id'].isin(pred_ser.index[:200])]\n",
    "    mean_returns = returns['0.07'].mean()\n",
    "    \n",
    "    \n",
    "    # store things\n",
    "    to_store['params'] = params_holder\n",
    "    to_store['pred_ser'] = pred_ser\n",
    "    to_store['mean_returns'] = mean_returns\n",
    "    \n",
    "    if stats_dict.keys():\n",
    "        t = max(stats_dict.keys())+1\n",
    "        stats_dict[t] = to_store\n",
    "    else:\n",
    "        stats_dict[0] = to_store\n",
    "#     cv_data = cv(\n",
    "#         Pool(X, y, cat_features=categorical_features_indices),\n",
    "#         model.get_params(),\n",
    "#         **cv_params\n",
    "#     )\n",
    "#     best_accuracy = np.max(cv_data['test-{0}-mean'.format()])\n",
    "    \n",
    "    return 1 - mean_returns # as hyperopt minimises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T02:59:41.918761Z",
     "start_time": "2019-08-19T02:59:41.887092Z"
    }
   },
   "outputs": [],
   "source": [
    "params_space = {'cb': {\n",
    "    # Common Params _____________\n",
    "    'eval_metric': 'Logloss',\n",
    "    'learning_rate': hyperopt.hp.uniform('learning_rate', 1e-3, 5e-1),\n",
    "    'l2_leaf_reg': hyperopt.hp.qloguniform('l2_leaf_reg', 0, 2, 1),\n",
    "    'bootstrap_type': hyperopt.hp.choice('bootstrap_type', ['Bayesian', 'Bernoulli', 'Poisson']),\n",
    "    'random_strength': hyperopt.hp.uniform('random_strength', 1e-1, 1e1),\n",
    "    'use_best_model': True,\n",
    "    'min_data_in_leaf': hyperopt.hp.uniform('min_data_in_leaf', 1, 1e2),\n",
    "#     'one_hot_max_size': hyperopt.hp.uniform('one_hot_max_size', 2, 50),\n",
    "    'has_time': hyperopt.hp.choice('has_time', [True, False]),\n",
    "    'class_weights': hyperopt.hp.choice('class_weights', [None, [1, 4]]),\n",
    "    'boosting_type': hyperopt.hp.choice('boosting_type', ['Ordered', 'Plain']),\n",
    "    'random_seed': 42,\n",
    "    'logging_level': 'Silent',\n",
    "    'use_best_model': True,\n",
    "    'task_type': 'GPU',\n",
    "    'boosting_type': 'Ordered',\n",
    "#     'custom_metric': ['F1', 'Precision', 'Recall', 'Accuracy', 'AUC'],\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 300,\n",
    "}, 'cv':\n",
    "    {'type': 'TimeSeries',\n",
    "     'shuffle': hyperopt.hp.choice('shuffle', [True, False])\n",
    "     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-19T02:59:42.382Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "stats_dict = {}\n",
    "\n",
    "trials = hyperopt.Trials()\n",
    "\n",
    "best = hyperopt.fmin(\n",
    "    hyperopt_objective,\n",
    "    space=params_space,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials,\n",
    "    rstate=RandomState(123)\n",
    ")\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_params = {'cb': {'eval_metric': 'Logloss',\n",
    "#   'learning_rate': <hyperopt.pyll.base.Apply at 0x7f8400e66978>,\n",
    "#   'l2_leaf_reg': <hyperopt.pyll.base.Apply at 0x7f8400e66b00>,\n",
    "#   'bootstrap_type': <hyperopt.pyll.base.Apply at 0x7f8400e66c18>,\n",
    "#   'random_strength': <hyperopt.pyll.base.Apply at 0x7f8400e66e48>,\n",
    "#   'use_best_model': True,\n",
    "#   'min_data_in_leaf': <hyperopt.pyll.base.Apply at 0x7f8400e66f98>,\n",
    "#   'one_hot_max_size': <hyperopt.pyll.base.Apply at 0x7f8400e5d128>,\n",
    "#   'has_time': <hyperopt.pyll.base.Apply at 0x7f8400e5d240>,\n",
    "#   'class_weights': <hyperopt.pyll.base.Apply at 0x7f8400e5d3c8>,\n",
    "  'boosting_type': 'Ordered',\n",
    "  'random_seed': 42,\n",
    "  'logging_level': 'Silent',\n",
    "  'task_type': 'GPU',\n",
    "  'od_type': 'Iter',\n",
    "  'od_wait': 300},\n",
    " 'cv': {'type': 'TimeSeries',\n",
    "#   'shuffle': <hyperopt.pyll.base.Apply at 0x7f8400e5d518>\n",
    "       }}\n",
    "\n",
    "hyperopt_objective(example_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
