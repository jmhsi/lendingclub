{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:44:22.995714Z",
     "start_time": "2019-07-27T15:44:22.979860Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T01:34:18.479913Z",
     "start_time": "2019-07-27T01:34:18.446593Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../lc_utils.py\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.expanduser('~'),'projects','j_utils',))\n",
    "import munging as mg\n",
    "import hyperlearn.hyperlearn.impute.SVDImpute as hpl_imp\n",
    "\n",
    "def gen_expt_datasets(today, oldest, valid_start, base_loan_info, eval_loan_info, target, valid_end=None, verbose=False):\n",
    "    '''\n",
    "    all loans from oldest until today are taken as train. All loans issued after today until valid_end are used for validation. Uses hyperlearn svd_impute to impute missing values. Returns the train and test datasets. target can be single colname or list of colnames\n",
    "    '''\n",
    "    train_ids = eval_loan_info[(eval_loan_info['issue_d'] <= today) & (eval_loan_info['issue_d'] >= oldest)]['id'].unique()\n",
    "    if valid_end:\n",
    "        valid_ids = eval_loan_info[(eval_loan_info['issue_d'] >= valid_start) & (eval_loan_info['issue_d'] <= valid_end)]['id'].unique()\n",
    "    else:\n",
    "        valid_ids = eval_loan_info[(eval_loan_info['issue_d'] >= valid_start)]['id'].unique()\n",
    "    train = base_loan_info[base_loan_info['id'].isin(train_ids)]\n",
    "    valid = base_loan_info[base_loan_info['id'].isin(valid_ids)]\n",
    "    \n",
    "    # setup for catboost\n",
    "    # a bit more data processing and nan handling for catboost\n",
    "    train_copy = train.copy()\n",
    "    valid_copy = valid.copy()\n",
    "    \n",
    "    # get ready for hyperlearn svdimpute\n",
    "    train_copy, max_dict, min_dict, cats_dict, norm_dict = mg.train_hpl_proc(train_copy, verbose=verbose)\n",
    "    valid_copy = mg.val_test_hpl_proc(valid_copy, train_copy, max_dict, min_dict, cats_dict, verbose=verbose)\n",
    "\n",
    "    # fit to train\n",
    "    S, VT, mean, std, mins, standardise = hpl_imp.fit(train_copy.values)\n",
    "    \n",
    "    # impute on train\n",
    "    train_svdimp = hpl_imp.transform(train_copy.values, S, VT, mean, std, mins, standardise)\n",
    "    train_svdimp = pd.DataFrame(train_svdimp)\n",
    "    train_svdimp.index = train_copy.index\n",
    "    train_svdimp.columns = train_copy.columns\n",
    "    \n",
    "    # impute on test\n",
    "    valid_svdimp = hpl_imp.transform(valid_copy.values, S, VT, mean, std, mins, standardise)\n",
    "    valid_svdimp = pd.DataFrame(valid_svdimp)\n",
    "    valid_svdimp.index = valid_copy.index\n",
    "    valid_svdimp.columns = valid_copy.columns\n",
    "    \n",
    "    # imputing changes some ids. Make the ids the originals again.\n",
    "    train_svdimp['id'] = train_ids\n",
    "    valid_svdimp['id'] = valid_ids\n",
    "    \n",
    "    train_y = eval_loan_info[eval_loan_info['id'].isin(train_ids)][target]\n",
    "    valid_y = eval_loan_info[eval_loan_info['id'].isin(valid_ids)][target]\n",
    "    \n",
    "    return train_svdimp, train_y, valid_svdimp, valid_y, train_ids, valid_ids\n",
    "\n",
    "# make a crude test set for now\n",
    "def get_split_date(df, date_column, quantile): \n",
    "\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/31018622/pandas-quantile-function-for-dates\n",
    "    Get the date on which to split a dataframe for timeseries splitting\n",
    "    Adjusted coerce param to errors since SO is old.\n",
    "    \"\"\" \n",
    "\n",
    "    # 1. convert date_column to datetime (useful in case it is a string) \n",
    "    # 2. convert into int (for sorting) \n",
    "    # 3. get the quantile \n",
    "    # 4. get the corresponding date\n",
    "    # 5. return, pray that it works \n",
    "\n",
    "    quantile_date = pd.to_datetime(df[date_column], errors = 'raise').astype('int64').quantile(q=quantile)#.astype('datetime64[ns]')\n",
    "\n",
    "    return pd.to_datetime(quantile_date)\n",
    "\n",
    "def split_out_traintestable_loans(df, eval_df, oldness_thrsh=.9):\n",
    "    '''Can train/test on loans that pass the oldness_thrsh or have status paid/defaulted/charged_off'''\n",
    "    old_enough_ids = eval_df[(eval_df['maturity_time_stat_adj'] >= oldness_thrsh) | \n",
    "                                    (eval_df['maturity_paid_stat_adj'] >= oldness_thrsh) | \n",
    "                                    (eval_df['loan_status'].isin(['paid', 'defaulted', 'charged_off']))]['id'].unique()\n",
    "    df = df[df['id'].isin(old_enough_ids)]\n",
    "    eval_df = eval_df[eval_df['id'].isin(old_enough_ids)]\n",
    "    return df, eval_df\n",
    "\n",
    "\n",
    "def add_custom_lc_features(df):\n",
    "    # added features\n",
    "    df['monthly_inc'] = df['annual_inc'] / 12\n",
    "    df['dti_w_loan'] = (df['dti'] * df['monthly_inc'] +\n",
    "                                    df['installment']) / df['monthly_inc']\n",
    "    df['delinq_to_monthly_inc'] = df['delinq_amnt'] / \\\n",
    "        df['monthly_inc']\n",
    "    df['tot_cur_bal_to_monthly_inc'] = df['tot_cur_bal'] / \\\n",
    "        df['monthly_inc']\n",
    "    df['loan_to_inc'] = df['loan_amount'] / \\\n",
    "        df['monthly_inc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # test hyperlearn impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:44:27.192633Z",
     "start_time": "2019-07-27T15:44:27.176399Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:44:33.338642Z",
     "start_time": "2019-07-27T15:44:29.665633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that first time import of HyperLearn will be slow, since NUMBA code has to be compiled to machine code for optimization purposes.\n"
     ]
    }
   ],
   "source": [
    "import hyperlearn.hyperlearn.impute.SVDImpute as hpl_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:44:41.246579Z",
     "start_time": "2019-07-27T15:44:41.226873Z"
    }
   },
   "outputs": [],
   "source": [
    "base_row = [1,1]\n",
    "for i in range(1,10):\n",
    "    base_row.append(base_row[i] + base_row[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:44:41.927118Z",
     "start_time": "2019-07-27T15:44:41.904977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:44:42.608691Z",
     "start_time": "2019-07-27T15:44:42.588398Z"
    }
   },
   "outputs": [],
   "source": [
    "mat = [base_row]\n",
    "for i in range(20):\n",
    "    next_row = mat[-1][:]\n",
    "    next_row.append(next_row[-1] + next_row[-2])\n",
    "    mat.append(next_row[1:])\n",
    "mat = np.array(mat, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:44:43.691767Z",
     "start_time": "2019-07-27T15:44:43.670306Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = np.random.randint(2, size=mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:44:44.407920Z",
     "start_time": "2019-07-27T15:44:44.388941Z"
    }
   },
   "outputs": [],
   "source": [
    "to_imp = mat.copy()\n",
    "to_imp[mask == 1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T16:12:50.846376Z",
     "start_time": "2019-07-27T16:12:50.817017Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'f' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-62c56ea0e01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandardise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpl_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/hyperlearn/hyperlearn/impute/SVDImpute.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(X, n_components, standardise, copy)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomizedEig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mS\u001b[0m \u001b[0;34m**=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mVT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyperlearn/hyperlearn/big_data/randomized.py\u001b[0m in \u001b[0;36mrandomizedEig\u001b[0;34m(X, n_components, max_iter, solver, n_oversamples)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mS2\u001b[0m \u001b[0;34m**=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mS2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU_decision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mS2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyperlearn/hyperlearn/linalg.py\u001b[0m in \u001b[0;36meig\u001b[0;34m(X, alpha, fast, U_decision, svd, stable)\u001b[0m\n\u001b[1;32m    486\u001b[0m                         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                 \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_XTX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                         \u001b[0mS\u001b[0m \u001b[0;34m**=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyperlearn/hyperlearn/linalg.py\u001b[0m in \u001b[0;36meigh\u001b[0;34m(XTX, alpha, fast, svd, positive, qr)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mold_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mdecomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlapack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"syevd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eigh\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mqr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlapack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"syevr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/hyperlearn/hyperlearn/utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, function, fast, numba)\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'numba.{function}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'f' referenced before assignment"
     ]
    }
   ],
   "source": [
    "S, VT, mean, std, mins, standardise = hpl_imp.fit(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:58:38.896616Z",
     "start_time": "2019-07-27T15:49:33.936990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/justin/hyperlearn/hyperlearn/utils.py\u001b[0m(35)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     33 \u001b[0;31m                        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'numba.{function}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m                        \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 35 \u001b[0;31m                        \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> dir\n",
      "<built-in function dir>\n",
      "ipdb> dir()\n",
      "['fast', 'function', 'numba', 'self']\n",
      "ipdb> function\n",
      "'syevd'\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/justin/hyperlearn/hyperlearn/linalg.py\u001b[0m(396)\u001b[0;36meigh\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    394 \u001b[0;31m        \u001b[0mold_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    395 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 396 \u001b[0;31m        \u001b[0mdecomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlapack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"syevd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eigh\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mqr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlapack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"syevr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    397 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    398 \u001b[0;31m        \u001b[0;32mwhile\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> gr\n",
      "*** NameError: name 'gr' is not defined\n",
      "ipdb> qr\n",
      "False\n",
      "ipdb> lapack('syevd', fast, 'eigh')\n",
      "*** UnboundLocalError: local variable 'f' referenced before assignment\n",
      "ipdb> d\n",
      "> \u001b[0;32m/home/justin/hyperlearn/hyperlearn/utils.py\u001b[0m(35)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     33 \u001b[0;31m                        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'numba.{function}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m                        \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 35 \u001b[0;31m                        \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> dir()\n",
      "['fast', 'function', 'numba', 'self']\n",
      "ipdb> USE_NUMBA\n",
      "True\n",
      "ipdb> numba\n",
      "'eigh'\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute on train\n",
    "imputed = hpl_imp.transform(to_imp, S, VT, mean, std, mins, standardise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:58:06.307142Z",
     "start_time": "2019-07-27T06:53:20.423839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/justin/hyperlearn/hyperlearn/linalg.py\u001b[0m(398)\u001b[0;36meigh\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    396 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    397 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mqr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 398 \u001b[0;31m                \u001b[0meig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlapack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"syevd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eigh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    399 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    400 \u001b[0;31m                \u001b[0meig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlapack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"syevr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"eigh\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
