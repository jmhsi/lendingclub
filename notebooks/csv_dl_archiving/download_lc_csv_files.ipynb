{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# updated on 5/25/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions that go into download_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T05:21:59.003714Z",
     "start_time": "2019-06-11T05:21:58.985558Z"
    },
    "code_folding": [
     15,
     66,
     140,
     155,
     164,
     203,
     224
    ]
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import subprocess\n",
    "# import time\n",
    "# from stat import S_ISDIR, ST_CTIME, ST_MODE\n",
    "# from shutil import copytree, rmtree\n",
    "# import pause\n",
    "# from selenium.webdriver import Chrome\n",
    "# from selenium.webdriver.chrome import webdriver as chrome_webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "# # relative import to grab user_creds\n",
    "# sys.path.append('../../user_creds/')\n",
    "# import account_info as acc_info\n",
    "\n",
    "# class DriverBuilder():\n",
    "#     # https://stackoverflow.com/questions/45631715/downloading-with-chrome-headless-and-selenium\n",
    "#     def get_driver(self, download_location=None, headless=False):\n",
    "#         driver = self._get_chrome_driver(download_location, headless)\n",
    "#         driver.set_window_size(1400, 700)\n",
    "#         return driver\n",
    "\n",
    "#     def _get_chrome_driver(self, download_location, headless):\n",
    "#         chrome_options = chrome_webdriver.Options()\n",
    "#         if download_location:\n",
    "#             prefs = {'download.default_directory': download_location,\n",
    "#                      'download.prompt_for_download': False,\n",
    "#                      'download.directory_upgrade': True,\n",
    "#                      'safebrowsing.enabled': False,\n",
    "#                      'safebrowsing.disable_download_protection': True}\n",
    "#             chrome_options.add_experimental_option('prefs', prefs)\n",
    "#             chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "#         if headless:\n",
    "#             chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "#         driver_path = '/usr/bin/chromedriver'\n",
    "\n",
    "#         if sys.platform.startswith(\"win\"):\n",
    "#             driver_path += \".exe\"\n",
    "\n",
    "#         driver = Chrome(executable_path=driver_path,\n",
    "#                         chrome_options=chrome_options)\n",
    "#         if headless:\n",
    "#             self.enable_download_in_headless_chrome(driver, download_location)\n",
    "#         return driver\n",
    "\n",
    "#     def enable_download_in_headless_chrome(self, driver, download_dir):\n",
    "#         \"\"\"\n",
    "#         there is currently a \"feature\" in chrome where\n",
    "#         headless does not allow file download: https://bugs.chromium.org/p/chromium/issues/detail?id=696481\n",
    "#         This method is a hacky work-around until the official chromedriver support for this.\n",
    "#         Requires chrome version 62.0.3196.0 or above.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # add missing support for chrome \"send_command\"  to selenium webdriver\n",
    "#         driver.command_executor._commands[\"send_command\"] = (\n",
    "#             \"POST\", '/session/$sessionId/chromium/send_command')\n",
    "\n",
    "#         params = {'cmd': 'Page.setDownloadBehavior', 'params': {\n",
    "#             'behavior': 'allow', 'downloadPath': download_dir}}\n",
    "#         command_result = driver.execute(\"send_command\", params)\n",
    "#         print(\"response from browser:\")\n",
    "#         for key in command_result:\n",
    "#             print(\"result:\" + key + \":\" + str(command_result[key]))\n",
    "\n",
    "# def download_csvs(download_path):\n",
    "#     '''\n",
    "#     downloads all loan_info csvs and pmt_history csv\n",
    "#     '''\n",
    "#     # setup constants\n",
    "#     email = acc_info.email_throwaway\n",
    "#     password = acc_info.password_throwaway\n",
    "#     url_dl = \"https://www.lendingclub.com/info/download-data.action\"\n",
    "#     url_signin = \"https://www.lendingclub.com/auth/login\"\n",
    "#     url_pmt_hist = \"https://www.lendingclub.com/site/additional-statistics\"\n",
    "\n",
    "#     d_builder = DriverBuilder()\n",
    "#     driver = d_builder.get_driver(\n",
    "#         download_location=download_path, headless=True)\n",
    "    \n",
    "#     # sign in\n",
    "#     driver.get(url_signin)\n",
    "#     email_box = driver.find_element_by_xpath(\n",
    "#         '/html/body/div[2]/div[1]/div[2]/form[1]/label[1]/input')\n",
    "#     password_box = driver.find_element_by_xpath(\n",
    "#         '/html/body/div[2]/div[1]/div[2]/form[1]/label[2]/input')\n",
    "\n",
    "#     pause.milliseconds(1000)\n",
    "#     email_box.send_keys(email)\n",
    "#     password_box.send_keys(password)\n",
    "\n",
    "#     button = driver.find_element_by_xpath(\n",
    "#         '/html/body/div[2]/div[1]/div[2]/form[1]/button')\n",
    "#     button.click()\n",
    "#     pause.milliseconds(3000)\n",
    "\n",
    "#     # download loan_info\n",
    "#     driver.get(url_dl)\n",
    "#     download_btn = driver.find_element_by_xpath(\n",
    "#         '//*[@id=\"currentLoanStatsFileName\"]')\n",
    "\n",
    "#     select = driver.find_element_by_xpath(\n",
    "#         '//*[@id=\"loanStatsDropdown\"]')  # get the select element\n",
    "#     options = select.find_elements_by_tag_name(\n",
    "#         \"option\")  # get all the options into a list\n",
    "\n",
    "#     options_dict = {}\n",
    "#     for option in options:  # iterate over the options, place attribute value in list\n",
    "#         options_dict[option.get_attribute(\"value\")] = option.text\n",
    "\n",
    "#     for opt_val, text in options_dict.items():\n",
    "#         print(\"starting download on option {0}, {1}\".format(opt_val, text))\n",
    "\n",
    "#         select = driver.find_element_by_xpath(\n",
    "#             '//*[@id=\"loanStatsDropdown\"]')\n",
    "#         selection = Select(select)\n",
    "#         selection.select_by_value(opt_val)\n",
    "#         download_btn.click()\n",
    "#         pause.milliseconds(2000)\n",
    "\n",
    "#     # payment history downloads\n",
    "#     driver.get(url_pmt_hist)\n",
    "\n",
    "#     pmt_history = driver.find_element_by_xpath(\n",
    "#         '/html/body/div[2]/section/div[2]/div/p[2]/a[2]')\n",
    "#     pmt_history.click()\n",
    "\n",
    "#     # wait for all downloads to finish\n",
    "#     while True:\n",
    "#         if len(os.listdir(download_path)) != (\n",
    "#                 len(options_dict) + 1):  # +1 for one pmt history file\n",
    "#             time.sleep(5)\n",
    "#             print('waiting for all csv downloads to start')\n",
    "#             continue\n",
    "#         else:\n",
    "#             files = os.listdir(download_path)\n",
    "#             k = 0\n",
    "#             time.sleep(5)\n",
    "#             print('checking/waiting for all csv downloads to finish')\n",
    "#             for filename in files:\n",
    "#                 if 'crdownload' in filename:\n",
    "#                     print('{0} is still downloading'.format(filename))\n",
    "#                     time.sleep(30)\n",
    "#                 else:\n",
    "#                     k += 1\n",
    "#     #                 print(k)\n",
    "#             if k == len(files):\n",
    "#                 time.sleep(2)\n",
    "#                 break\n",
    "\n",
    "#     print('done downloading')\n",
    "#     driver.close()\n",
    "#     return True\n",
    "\n",
    "# def get_hashes(path):\n",
    "#     hashes = {}\n",
    "#     files = os.listdir(path)\n",
    "#     for file_ in files:\n",
    "#         a = subprocess.check_output(\n",
    "#             'shasum -a 256 {0}'.format(path + '/' + file_), shell=True)\n",
    "#         hashes[file_] = a.split()[0]\n",
    "#     return hashes\n",
    "\n",
    "# def check_file_changes(csv_folders, just_dled_hashes):\n",
    "#     need_to_clean = False\n",
    "#     try:\n",
    "#         previous_dled_hashes = get_hashes(csv_folders[-2][1])\n",
    "\n",
    "#         # compare new download to previous download\n",
    "#         # check for added or deleted files\n",
    "#         dne_files = set(just_dled_hashes.keys()).intersection(\n",
    "#             set(previous_dled_hashes.keys()))\n",
    "#         add_files = set(previous_dled_hashes.keys()).intersection(\n",
    "#             set(just_dled_hashes.keys()))\n",
    "#         if len(just_dled_hashes) != len(previous_dled_hashes):\n",
    "#             need_to_clean = True\n",
    "#             print(\"Compared to the previous time new csv's were downloaded, the following files were deleted: \\n {0}\".format(\n",
    "#                 dne_files))\n",
    "#             print(\"Compared to the previous time new csv's were downloaded, the following files are new additions: \\n {0}\".format(\n",
    "#                 add_files))\n",
    "#         else:\n",
    "#             print('No files were added or deleted since previous downloading of csvs')\n",
    "\n",
    "#         # check for shasum256 changes\n",
    "#         changed_files = []\n",
    "#         for key in just_dled_hashes.keys() & previous_dled_hashes.keys():\n",
    "#             if previous_dled_hashes[key] != just_dled_hashes[key]:\n",
    "#                     changed_files.append(key)\n",
    "                \n",
    "#         if len(changed_files) == 0:\n",
    "#             print('There are no changes to previous downloaded lending club csvs (loan_info and pmt_hist) via shasum256 hashes')\n",
    "#         else:\n",
    "#             need_to_clean = True\n",
    "#             print('Compared to the previous data download, the shasum256 hashes changed for the following files: {0}'.format(\n",
    "#                 changed_files))\n",
    "\n",
    "#     except IndexError:\n",
    "#         need_to_clean = True\n",
    "#         print('Could not find previously download directory? This is probably your first time downloading the csvs or the first download to a new path.')\n",
    "\n",
    "#     return need_to_clean\n",
    "\n",
    "# def get_sorted_creationtime_dirs(ppath):\n",
    "#     csv_folders = [os.path.join(ppath, fn) for fn in os.listdir(\n",
    "#         ppath) if fn not in ['archived_csvs', 'working_csvs']]\n",
    "#     csv_folders = [(os.stat(path), path) for path in csv_folders]\n",
    "#     csv_folders = [(stat[ST_CTIME], path)\n",
    "#                    for stat, path in csv_folders if S_ISDIR(stat[ST_MODE])]\n",
    "#     return sorted(csv_folders)\n",
    "\n",
    "# def archiver(archive_flag, ppath, archiver_dir=None):\n",
    "#     archiver_dir = os.path.join(os.path.expanduser(\n",
    "#         '~'), 'projects', 'lendingclub', 'data', 'csvs', 'archived_csvs') if not archiver_dir else archiver_dir\n",
    "#     os.makedirs(archiver_dir, exist_ok=True)\n",
    "#     if archive_flag:\n",
    "#         just_dled = get_sorted_creationtime_dirs(ppath)[-1][1]\n",
    "        \n",
    "#         newest_folder = os.path.split(just_dled)[1]\n",
    "        \n",
    "#         copytree(just_dled, os.path.join(archiver_dir, newest_folder))\n",
    "        \n",
    "#         print('copied {0} to {1}'.format(newest_folder, archiver_dir))\n",
    "\n",
    "# def cleaner(ppath):\n",
    "#     just_dled = os.path.split(get_sorted_creationtime_dirs(ppath)[-1][1])[1]\n",
    "#     keep_dirs = ['archived_csvs', 'working_csvs', just_dled]\n",
    "#     for tree in os.listdir(ppath):\n",
    "#         if tree not in keep_dirs:\n",
    "#             rmtree(os.path.join(ppath, tree))\n",
    "#             print('removing old dirs {0}'.format(tree))\n",
    "#     return just_dled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T05:22:02.437044Z",
     "start_time": "2019-06-11T05:22:02.422071Z"
    }
   },
   "outputs": [],
   "source": [
    "# # setup\n",
    "# rel_path = '../../data/csvs'\n",
    "# now = time.strftime(\"%m_%d_%Hh_%Mm_%Ss_%Y\")\n",
    "# download_dir = 'csvs_' + now\n",
    "# os.mkdir(download_dir)\n",
    "\n",
    "# # download csvs\n",
    "# download_csvs(download_dir)\n",
    "\n",
    "# # calculate shasum256 hash on just downloaded csvs\n",
    "# just_dled_hashes = get_hashes(download_dir)\n",
    "\n",
    "# # copy the downloaded files to data location\n",
    "# copytree(download_dir, os.path.join(rel_path, download_dir))\n",
    "\n",
    "# # delete the original\n",
    "# rmtree(download_dir)\n",
    "\n",
    "# # get the dirs holding downloaded csvs by creation time (not archived_csvs dir)\n",
    "# csv_folders = get_sorted_creationtime_dirs(rel_path)\n",
    "\n",
    "# # check if compared to previous time, there are changes/additions/deletions in csvs\n",
    "# archive_flag = check_file_changes(csv_folders, just_dled_hashes)\n",
    "\n",
    "# # if something was different (archive_flag), then store a copy of just_downloaded to archives\n",
    "# archiver(archive_flag, rel_path)\n",
    "\n",
    "# # removes old downloads\n",
    "# cleaner(rel_path)\n",
    "\n",
    "# print('done downloading, checking, and archiving (when necessary) the csv files!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loadscript for editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T00:47:53.048693Z",
     "start_time": "2019-09-24T00:47:53.031250Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('/home/justin/projects/lendingclub/src/csv_dl_archiving/')\n",
    "sys.path.append('/home/justin/projects/lendingclub/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T01:01:26.966742Z",
     "start_time": "2019-09-24T00:47:53.702274Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading csvs to /home/justin/projects/lendingclub/notebooks/csv_dl_archiving/csvs_09_23_17h_47m_53s_2019\n",
      "response from browser:\n",
      "result:sessionId:c78c3b40678055d72776d68b50b31ab7\n",
      "result:status:0\n",
      "result:value:None\n",
      "starting download on option 0, 2007 - 2011\n",
      "starting download on option 1, 2012 - 2013\n",
      "starting download on option 2, 2014\n",
      "starting download on option 3, 2015\n",
      "starting download on option 4, 2016 Q1\n",
      "starting download on option 5, 2016 Q2\n",
      "starting download on option 6, 2016 Q3\n",
      "starting download on option 7, 2016 Q4\n",
      "starting download on option 8, 2017 Q1\n",
      "starting download on option 9, 2017 Q2\n",
      "starting download on option 10, 2017 Q3\n",
      "starting download on option 11, 2017 Q4\n",
      "starting download on option 12, 2018 Q1\n",
      "starting download on option 13, 2018 Q2\n",
      "starting download on option 14, 2018 Q3\n",
      "starting download on option 15, 2018 Q4\n",
      "starting download on option 16, 2019 Q1\n",
      "starting download on option 17, 2019 Q2\n",
      "waiting for all csv downloads to start\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "LoanStats_securev1_2019Q2.csv.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n",
      "checking/waiting for all csv downloads to finish\n",
      "All_Payments_2019_09.zip.crdownload is still downloading\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-76bb467f12ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# download csvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_csvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# # calculate shasum256 hash on just downloaded csvs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/lendingclub/src/csv_dl_archiving/download_prep.py\u001b[0m in \u001b[0;36mdownload_csvs\u001b[0;34m(download_path)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# wait for all downloads to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             if len(os.listdir(download_path)) != (\n\u001b[0m\u001b[1;32m    172\u001b[0m                     len(options_dict) + 1):  # +1 for one pmt history file\n\u001b[1;32m    173\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load /home/justin/projects/lendingclub/src/csv_dl_archiving/download_and_check_csvs.py\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from shutil import copytree, rmtree\n",
    "import download_prep as dp\n",
    "import config\n",
    "\n",
    "# print(dp.__file__)\n",
    "# print(sys.path)\n",
    "# print(config.src_dir)\n",
    "\n",
    "# setup\n",
    "config.csv_dir = '../../data/csvs'\n",
    "now = time.strftime(\"%m_%d_%Hh_%Mm_%Ss_%Y\")\n",
    "download_dir = 'csvs_' + now\n",
    "os.mkdir(download_dir)\n",
    "\n",
    "# download csvs\n",
    "dp.download_csvs(download_dir)\n",
    "\n",
    "# # calculate shasum256 hash on just downloaded csvs\n",
    "# just_dled_hashes = dp.get_hashes(download_dir)\n",
    "\n",
    "# # copy the downloaded files to data location\n",
    "# copytree(download_dir, os.path.join(config.csv_dir, download_dir))\n",
    "\n",
    "# # delete the original\n",
    "# rmtree(download_dir)\n",
    "\n",
    "# # get the dirs holding downloaded csvs by creation time (not archived_csvs dir)\n",
    "# csv_folders = dp.get_sorted_creationtime_dirs(config.csv_dir)\n",
    "\n",
    "# # check if compared to previous time, there are changes/additions/deletions in csvs\n",
    "# archive_flag = dp.check_file_changes(csv_folders, just_dled_hashes)\n",
    "\n",
    "# # if something was different (archive_flag), then store a copy of just_downloaded to archives\n",
    "# dp.archiver(archive_flag, config.csv_dir)\n",
    "\n",
    "# # removes old downloads\n",
    "# dp.cleaner(config.csv_dir)\n",
    "\n",
    "# print('done downloading, checking, and archiving (when necessary) the csv files!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:14:12.024393Z",
     "start_time": "2019-09-24T04:14:12.003436Z"
    }
   },
   "outputs": [],
   "source": [
    "from lendingclub import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:30:27.856901Z",
     "start_time": "2019-09-24T04:30:27.839127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/justin/projects/lendingclub/lendingclub/config.py'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:30:21.010791Z",
     "start_time": "2019-09-24T04:30:20.991863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/justin/projects/lendingclub/lendingclub'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.src_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:30:31.795581Z",
     "start_time": "2019-09-24T04:30:31.777630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/justin/projects/lendingclub'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.prj_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:30:43.389607Z",
     "start_time": "2019-09-24T04:30:43.369359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/justin/projects/lendingclub/data'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:30:46.939541Z",
     "start_time": "2019-09-24T04:30:46.921994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/justin/projects/lendingclub/data/csvs'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T04:53:08.145947Z",
     "start_time": "2019-09-24T04:53:08.006425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34marchived_csvs\u001b[0m/  \u001b[01;34mlatest_csvs\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls {config.csv_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# writing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T01:02:32.341823Z",
     "start_time": "2019-06-13T01:02:32.320264Z"
    },
    "code_folding": [
     18,
     69,
     160,
     173,
     222,
     235
    ],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../scripts/csv_dl_archiving/download_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../scripts/csv_dl_archiving/download_prep.py\n",
    "# driver download https://github.com/mozilla/geckodriver/releases\n",
    "# extracted geckodriver to /usr/local/bin in ubuntu\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "from stat import S_ISDIR, ST_CTIME, ST_MODE\n",
    "from shutil import copytree, rmtree\n",
    "import pause\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome import webdriver as chrome_webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "# # relative import to grab user_creds\n",
    "sys.path.append(os.path.join(os.path.expanduser('~'),'projects'))\n",
    "import lendingclub.user_creds.account_info as acc_info\n",
    "\n",
    "class DriverBuilder():\n",
    "    # https://stackoverflow.com/questions/45631715/downloading-with-chrome-headless-and-selenium\n",
    "    def get_driver(self, download_location=None, headless=False):\n",
    "        driver = self._get_chrome_driver(download_location, headless)\n",
    "        driver.set_window_size(1400, 700)\n",
    "        return driver\n",
    "\n",
    "    def _get_chrome_driver(self, download_location, headless):\n",
    "        chrome_options = chrome_webdriver.Options()\n",
    "        if download_location:\n",
    "            prefs = {'download.default_directory': download_location,\n",
    "                     'download.prompt_for_download': False,\n",
    "                     'download.directory_upgrade': True,\n",
    "                     'safebrowsing.enabled': False,\n",
    "                     'safebrowsing.disable_download_protection': True}\n",
    "            chrome_options.add_experimental_option('prefs', prefs)\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "        if headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "        driver_path = '/usr/bin/chromedriver'\n",
    "\n",
    "        if sys.platform.startswith(\"win\"):\n",
    "            driver_path += \".exe\"\n",
    "\n",
    "        driver = Chrome(executable_path=driver_path,\n",
    "                        chrome_options=chrome_options)\n",
    "        if headless:\n",
    "            self.enable_download_in_headless_chrome(driver, download_location)\n",
    "        return driver\n",
    "\n",
    "    def enable_download_in_headless_chrome(self, driver, download_dir):\n",
    "        \"\"\"\n",
    "        there is currently a \"feature\" in chrome where\n",
    "        headless does not allow file download: https://bugs.chromium.org/p/chromium/issues/detail?id=696481\n",
    "        This method is a hacky work-around until the official chromedriver support for this.\n",
    "        Requires chrome version 62.0.3196.0 or above.\n",
    "        \"\"\"\n",
    "\n",
    "        # add missing support for chrome \"send_command\"  to selenium webdriver\n",
    "        driver.command_executor._commands[\"send_command\"] = (\n",
    "            \"POST\", '/session/$sessionId/chromium/send_command')\n",
    "\n",
    "        params = {'cmd': 'Page.setDownloadBehavior', 'params': {\n",
    "            'behavior': 'allow', 'downloadPath': download_dir}}\n",
    "        command_result = driver.execute(\"send_command\", params)\n",
    "        print(\"response from browser:\")\n",
    "        for key in command_result:\n",
    "            print(\"result:\" + key + \":\" + str(command_result[key]))\n",
    "\n",
    "def download_csvs(download_path):\n",
    "    '''\n",
    "    downloads all loan_info csvs and pmt_history csv\n",
    "    '''\n",
    "    print('downloading csvs to {0}'.format(os.path.abspath(download_path)))\n",
    "    \n",
    "    # setup constants\n",
    "    email = acc_info.email_throwaway\n",
    "    password = acc_info.password_throwaway\n",
    "    url_dl = \"https://www.lendingclub.com/info/download-data.action\"\n",
    "    url_signin = \"https://www.lendingclub.com/auth/login\"\n",
    "    url_pmt_hist = \"https://www.lendingclub.com/site/additional-statistics\"\n",
    "\n",
    "    d_builder = DriverBuilder()\n",
    "    driver = d_builder.get_driver(\n",
    "        download_location=download_path, headless=True)\n",
    "    \n",
    "    # sign in\n",
    "    driver.get(url_signin)\n",
    "    email_box = driver.find_element_by_xpath(\n",
    "        '/html/body/div[2]/div[1]/div[2]/form[1]/label[1]/input')\n",
    "    password_box = driver.find_element_by_xpath(\n",
    "        '/html/body/div[2]/div[1]/div[2]/form[1]/label[2]/input')\n",
    "\n",
    "    pause.milliseconds(1000)\n",
    "    email_box.send_keys(email)\n",
    "    password_box.send_keys(password)\n",
    "\n",
    "    button = driver.find_element_by_xpath(\n",
    "        '/html/body/div[2]/div[1]/div[2]/form[1]/button')\n",
    "    button.click()\n",
    "    pause.milliseconds(3000)\n",
    "\n",
    "    # download loan_info\n",
    "    driver.get(url_dl)\n",
    "    download_btn = driver.find_element_by_xpath(\n",
    "        '//*[@id=\"currentLoanStatsFileName\"]')\n",
    "\n",
    "    select = driver.find_element_by_xpath(\n",
    "        '//*[@id=\"loanStatsDropdown\"]')  # get the select element\n",
    "    options = select.find_elements_by_tag_name(\n",
    "        \"option\")  # get all the options into a list\n",
    "\n",
    "    options_dict = {}\n",
    "    for option in options:  # iterate over the options, place attribute value in list\n",
    "        options_dict[option.get_attribute(\"value\")] = option.text\n",
    "\n",
    "    for opt_val, text in options_dict.items():\n",
    "        print(\"starting download on option {0}, {1}\".format(opt_val, text))\n",
    "\n",
    "        select = driver.find_element_by_xpath(\n",
    "            '//*[@id=\"loanStatsDropdown\"]')\n",
    "        selection = Select(select)\n",
    "        selection.select_by_value(opt_val)\n",
    "        download_btn.click()\n",
    "        pause.milliseconds(2000)\n",
    "\n",
    "    # payment history downloads\n",
    "    driver.get(url_pmt_hist)\n",
    "\n",
    "    pmt_history = driver.find_element_by_xpath(\n",
    "        '/html/body/div[2]/section/div[2]/div/p[2]/a[2]')\n",
    "    pmt_history.click()\n",
    "\n",
    "    # wait for all downloads to finish\n",
    "    while True:\n",
    "        if len(os.listdir(download_path)) != (\n",
    "                len(options_dict) + 1):  # +1 for one pmt history file\n",
    "            time.sleep(5)\n",
    "            print('waiting for all csv downloads to start')\n",
    "            continue\n",
    "        else:\n",
    "            files = os.listdir(download_path)\n",
    "            k = 0\n",
    "            time.sleep(5)\n",
    "            print('checking/waiting for all csv downloads to finish')\n",
    "            for filename in files:\n",
    "                if 'crdownload' in filename:\n",
    "                    print('{0} is still downloading'.format(filename))\n",
    "                    time.sleep(30)\n",
    "                else:\n",
    "                    k += 1\n",
    "    #                 print(k)\n",
    "            if k == len(files):\n",
    "                time.sleep(2)\n",
    "                break\n",
    "\n",
    "    print('done downloading')\n",
    "    driver.close()\n",
    "    return True\n",
    "\n",
    "def get_hashes(path):\n",
    "    '''\n",
    "    gets shasum hashes for files to check for file changes\n",
    "    '''\n",
    "    print('computing shasum for files in {0}'.format(os.path.abspath(path)))\n",
    "    hashes = {}\n",
    "    files = os.listdir(path)\n",
    "    for file_ in files:\n",
    "        a = subprocess.check_output(\n",
    "            'shasum -a 256 {0}'.format(path + '/' + file_), shell=True)\n",
    "        hashes[file_] = a.split()[0]\n",
    "    return hashes\n",
    "\n",
    "def check_file_changes(csv_folders, just_dled_hashes):\n",
    "    need_to_clean = False\n",
    "    print('starting to check for file changes comparing what was just downloaded.')\n",
    "    try:\n",
    "        previous_dled_hashes = get_hashes(csv_folders[-2][1])\n",
    "\n",
    "        # compare new download to previous download\n",
    "        # check for added or deleted files\n",
    "        dne_files = set(just_dled_hashes.keys()).intersection(\n",
    "            set(previous_dled_hashes.keys()))\n",
    "        add_files = set(previous_dled_hashes.keys()).intersection(\n",
    "            set(just_dled_hashes.keys()))\n",
    "        if len(just_dled_hashes) != len(previous_dled_hashes):\n",
    "            need_to_clean = True\n",
    "            print(\"Compared to the previous time new csv's were downloaded, the following files were deleted: \\n {0}\".format(\n",
    "                dne_files))\n",
    "            print(\"Compared to the previous time new csv's were downloaded, the following files are new additions: \\n {0}\".format(\n",
    "                add_files))\n",
    "        else:\n",
    "            print('No files were added or deleted since previous downloading of csvs')\n",
    "\n",
    "        # check for shasum256 changes\n",
    "        changed_files = []\n",
    "        for key in just_dled_hashes.keys() & previous_dled_hashes.keys():\n",
    "            if previous_dled_hashes[key] != just_dled_hashes[key]:\n",
    "                    changed_files.append(key)\n",
    "                \n",
    "        if len(changed_files) == 0:\n",
    "            print('There are no changes to previous downloaded lending club csvs (loan_info and pmt_hist) via shasum256 hashes')\n",
    "        else:\n",
    "            need_to_clean = True\n",
    "            print('Compared to the previous data download, the shasum256 hashes changed for the following files: {0}'.format(\n",
    "                changed_files))\n",
    "\n",
    "    except IndexError:\n",
    "        need_to_clean = True\n",
    "        print('Could not find previously download directory? This is probably your first time downloading the csvs or the first download to a new path.')\n",
    "\n",
    "    return need_to_clean\n",
    "\n",
    "def get_sorted_creationtime_dirs(ppath):\n",
    "    print('getting folders sorted by creation time in {0}'.format(os.path.abspath(ppath)))\n",
    "    csv_folders = [os.path.join(ppath, fn) for fn in os.listdir(\n",
    "        ppath) if fn not in ['archived_csvs', 'working_csvs', 'latest_csvs']]\n",
    "    csv_folders = [(os.stat(path), path) for path in csv_folders]\n",
    "    csv_folders = [(stat[ST_CTIME], path)\n",
    "                   for stat, path in csv_folders if S_ISDIR(stat[ST_MODE])]\n",
    "    return sorted(csv_folders)\n",
    "\n",
    "def archiver(archive_flag, ppath, archiver_dir=None):\n",
    "    archiver_dir = os.path.join(os.path.expanduser(\n",
    "        '~'), 'projects', 'lendingclub', 'data', 'csvs', 'archived_csvs') if not archiver_dir else archiver_dir\n",
    "    os.makedirs(archiver_dir, exist_ok=True)\n",
    "    if archive_flag:\n",
    "        just_dled = get_sorted_creationtime_dirs(ppath)[-1][1]\n",
    "        \n",
    "        newest_folder = os.path.split(just_dled)[1]\n",
    "        \n",
    "        copytree(just_dled, os.path.join(archiver_dir, newest_folder))\n",
    "        \n",
    "        print('copied {0} to {1}'.format(newest_folder, os.path.abspath(archiver_dir)))\n",
    "\n",
    "def cleaner(ppath):\n",
    "    just_dled = os.path.split(get_sorted_creationtime_dirs(ppath)[-1][1])[1]\n",
    "    keep_dirs = ['archived_csvs', 'working_csvs', just_dled]\n",
    "    for tree in os.listdir(ppath):\n",
    "        if tree not in keep_dirs:\n",
    "            rmtree(os.path.join(ppath, tree))\n",
    "            print('removing old dirs {0}'.format(tree))\n",
    "    return just_dled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T01:02:33.121012Z",
     "start_time": "2019-06-13T01:02:33.103616Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../scripts/csv_dl_archiving/download_and_check_csvs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../scripts/csv_dl_archiving/download_and_check_csvs.py\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from shutil import copytree, rmtree\n",
    "import download_prep as dp\n",
    "\n",
    "# setup\n",
    "rel_path = '../../data/csvs'\n",
    "now = time.strftime(\"%m_%d_%Hh_%Mm_%Ss_%Y\")\n",
    "download_dir = 'csvs_' + now\n",
    "os.mkdir(download_dir)\n",
    "\n",
    "# download csvs\n",
    "dp.download_csvs(download_dir)\n",
    "\n",
    "# calculate shasum256 hash on just downloaded csvs\n",
    "just_dled_hashes = dp.get_hashes(download_dir)\n",
    "\n",
    "# copy the downloaded files to data location\n",
    "copytree(download_dir, os.path.join(rel_path, download_dir))\n",
    "\n",
    "# delete the original\n",
    "rmtree(download_dir)\n",
    "\n",
    "# get the dirs holding downloaded csvs by creation time (not archived_csvs dir)\n",
    "csv_folders = dp.get_sorted_creationtime_dirs(rel_path)\n",
    "\n",
    "# check if compared to previous time, there are changes/additions/deletions in csvs\n",
    "archive_flag = dp.check_file_changes(csv_folders, just_dled_hashes)\n",
    "\n",
    "# if something was different (archive_flag), then store a copy of just_downloaded to archives\n",
    "dp.archiver(archive_flag, rel_path)\n",
    "\n",
    "# removes old downloads\n",
    "dp.cleaner(rel_path)\n",
    "\n",
    "print('done downloading, checking, and archiving (when necessary) the csv files!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Below was for storing in s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = \n",
    "aws_secret_access_key = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath,d))]\n",
    "dirs.sort()\n",
    "most_recent_dls = dirs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files_to_store = os.listdir(ppath+'/'+most_recent_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ppath+'/'+most_recent_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bucket_name = ''\n",
    "for file_ in tqdm_notebook(files_to_store):\n",
    "    data = open('{0}'.format(ppath+'/'+most_recent_dls+'/'+file_), 'rb')\n",
    "    s3.Bucket(bucket_name).put_object(Key='{0}/{1}'.format(most_recent_dls, file_), Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
