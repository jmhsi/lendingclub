{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# updated on 5/25/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions that go into download_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T05:21:59.003714Z",
     "start_time": "2019-06-11T05:21:58.985558Z"
    },
    "code_folding": [
     15,
     66,
     140,
     155,
     164,
     203,
     224
    ]
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import subprocess\n",
    "# import time\n",
    "# from stat import S_ISDIR, ST_CTIME, ST_MODE\n",
    "# from shutil import copytree, rmtree\n",
    "# import pause\n",
    "# from selenium.webdriver import Chrome\n",
    "# from selenium.webdriver.chrome import webdriver as chrome_webdriver\n",
    "# from selenium.webdriver.support.ui import Select\n",
    "\n",
    "# # relative import to grab user_creds\n",
    "# sys.path.append('../../user_creds/')\n",
    "# import account_info as acc_info\n",
    "\n",
    "# class DriverBuilder():\n",
    "#     # https://stackoverflow.com/questions/45631715/downloading-with-chrome-headless-and-selenium\n",
    "#     def get_driver(self, download_location=None, headless=False):\n",
    "#         driver = self._get_chrome_driver(download_location, headless)\n",
    "#         driver.set_window_size(1400, 700)\n",
    "#         return driver\n",
    "\n",
    "#     def _get_chrome_driver(self, download_location, headless):\n",
    "#         chrome_options = chrome_webdriver.Options()\n",
    "#         if download_location:\n",
    "#             prefs = {'download.default_directory': download_location,\n",
    "#                      'download.prompt_for_download': False,\n",
    "#                      'download.directory_upgrade': True,\n",
    "#                      'safebrowsing.enabled': False,\n",
    "#                      'safebrowsing.disable_download_protection': True}\n",
    "#             chrome_options.add_experimental_option('prefs', prefs)\n",
    "#             chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "#         if headless:\n",
    "#             chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "#         driver_path = '/usr/bin/chromedriver'\n",
    "\n",
    "#         if sys.platform.startswith(\"win\"):\n",
    "#             driver_path += \".exe\"\n",
    "\n",
    "#         driver = Chrome(executable_path=driver_path,\n",
    "#                         chrome_options=chrome_options)\n",
    "#         if headless:\n",
    "#             self.enable_download_in_headless_chrome(driver, download_location)\n",
    "#         return driver\n",
    "\n",
    "#     def enable_download_in_headless_chrome(self, driver, download_dir):\n",
    "#         \"\"\"\n",
    "#         there is currently a \"feature\" in chrome where\n",
    "#         headless does not allow file download: https://bugs.chromium.org/p/chromium/issues/detail?id=696481\n",
    "#         This method is a hacky work-around until the official chromedriver support for this.\n",
    "#         Requires chrome version 62.0.3196.0 or above.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # add missing support for chrome \"send_command\"  to selenium webdriver\n",
    "#         driver.command_executor._commands[\"send_command\"] = (\n",
    "#             \"POST\", '/session/$sessionId/chromium/send_command')\n",
    "\n",
    "#         params = {'cmd': 'Page.setDownloadBehavior', 'params': {\n",
    "#             'behavior': 'allow', 'downloadPath': download_dir}}\n",
    "#         command_result = driver.execute(\"send_command\", params)\n",
    "#         print(\"response from browser:\")\n",
    "#         for key in command_result:\n",
    "#             print(\"result:\" + key + \":\" + str(command_result[key]))\n",
    "\n",
    "# def download_csvs(download_path):\n",
    "#     '''\n",
    "#     downloads all loan_info csvs and pmt_history csv\n",
    "#     '''\n",
    "#     # setup constants\n",
    "#     email = acc_info.email_throwaway\n",
    "#     password = acc_info.password_throwaway\n",
    "#     url_dl = \"https://www.lendingclub.com/info/download-data.action\"\n",
    "#     url_signin = \"https://www.lendingclub.com/auth/login\"\n",
    "#     url_pmt_hist = \"https://www.lendingclub.com/site/additional-statistics\"\n",
    "\n",
    "#     d_builder = DriverBuilder()\n",
    "#     driver = d_builder.get_driver(\n",
    "#         download_location=download_path, headless=True)\n",
    "    \n",
    "#     # sign in\n",
    "#     driver.get(url_signin)\n",
    "#     email_box = driver.find_element_by_xpath(\n",
    "#         '/html/body/div[2]/div[1]/div[2]/form[1]/label[1]/input')\n",
    "#     password_box = driver.find_element_by_xpath(\n",
    "#         '/html/body/div[2]/div[1]/div[2]/form[1]/label[2]/input')\n",
    "\n",
    "#     pause.milliseconds(1000)\n",
    "#     email_box.send_keys(email)\n",
    "#     password_box.send_keys(password)\n",
    "\n",
    "#     button = driver.find_element_by_xpath(\n",
    "#         '/html/body/div[2]/div[1]/div[2]/form[1]/button')\n",
    "#     button.click()\n",
    "#     pause.milliseconds(3000)\n",
    "\n",
    "#     # download loan_info\n",
    "#     driver.get(url_dl)\n",
    "#     download_btn = driver.find_element_by_xpath(\n",
    "#         '//*[@id=\"currentLoanStatsFileName\"]')\n",
    "\n",
    "#     select = driver.find_element_by_xpath(\n",
    "#         '//*[@id=\"loanStatsDropdown\"]')  # get the select element\n",
    "#     options = select.find_elements_by_tag_name(\n",
    "#         \"option\")  # get all the options into a list\n",
    "\n",
    "#     options_dict = {}\n",
    "#     for option in options:  # iterate over the options, place attribute value in list\n",
    "#         options_dict[option.get_attribute(\"value\")] = option.text\n",
    "\n",
    "#     for opt_val, text in options_dict.items():\n",
    "#         print(\"starting download on option {0}, {1}\".format(opt_val, text))\n",
    "\n",
    "#         select = driver.find_element_by_xpath(\n",
    "#             '//*[@id=\"loanStatsDropdown\"]')\n",
    "#         selection = Select(select)\n",
    "#         selection.select_by_value(opt_val)\n",
    "#         download_btn.click()\n",
    "#         pause.milliseconds(2000)\n",
    "\n",
    "#     # payment history downloads\n",
    "#     driver.get(url_pmt_hist)\n",
    "\n",
    "#     pmt_history = driver.find_element_by_xpath(\n",
    "#         '/html/body/div[2]/section/div[2]/div/p[2]/a[2]')\n",
    "#     pmt_history.click()\n",
    "\n",
    "#     # wait for all downloads to finish\n",
    "#     while True:\n",
    "#         if len(os.listdir(download_path)) != (\n",
    "#                 len(options_dict) + 1):  # +1 for one pmt history file\n",
    "#             time.sleep(5)\n",
    "#             print('waiting for all csv downloads to start')\n",
    "#             continue\n",
    "#         else:\n",
    "#             files = os.listdir(download_path)\n",
    "#             k = 0\n",
    "#             time.sleep(5)\n",
    "#             print('checking/waiting for all csv downloads to finish')\n",
    "#             for filename in files:\n",
    "#                 if 'crdownload' in filename:\n",
    "#                     print('{0} is still downloading'.format(filename))\n",
    "#                     time.sleep(30)\n",
    "#                 else:\n",
    "#                     k += 1\n",
    "#     #                 print(k)\n",
    "#             if k == len(files):\n",
    "#                 time.sleep(2)\n",
    "#                 break\n",
    "\n",
    "#     print('done downloading')\n",
    "#     driver.close()\n",
    "#     return True\n",
    "\n",
    "# def get_hashes(path):\n",
    "#     hashes = {}\n",
    "#     files = os.listdir(path)\n",
    "#     for file_ in files:\n",
    "#         a = subprocess.check_output(\n",
    "#             'shasum -a 256 {0}'.format(path + '/' + file_), shell=True)\n",
    "#         hashes[file_] = a.split()[0]\n",
    "#     return hashes\n",
    "\n",
    "# def check_file_changes(csv_folders, just_dled_hashes):\n",
    "#     need_to_clean = False\n",
    "#     try:\n",
    "#         previous_dled_hashes = get_hashes(csv_folders[-2][1])\n",
    "\n",
    "#         # compare new download to previous download\n",
    "#         # check for added or deleted files\n",
    "#         dne_files = set(just_dled_hashes.keys()).intersection(\n",
    "#             set(previous_dled_hashes.keys()))\n",
    "#         add_files = set(previous_dled_hashes.keys()).intersection(\n",
    "#             set(just_dled_hashes.keys()))\n",
    "#         if len(just_dled_hashes) != len(previous_dled_hashes):\n",
    "#             need_to_clean = True\n",
    "#             print(\"Compared to the previous time new csv's were downloaded, the following files were deleted: \\n {0}\".format(\n",
    "#                 dne_files))\n",
    "#             print(\"Compared to the previous time new csv's were downloaded, the following files are new additions: \\n {0}\".format(\n",
    "#                 add_files))\n",
    "#         else:\n",
    "#             print('No files were added or deleted since previous downloading of csvs')\n",
    "\n",
    "#         # check for shasum256 changes\n",
    "#         changed_files = []\n",
    "#         for key in just_dled_hashes.keys() & previous_dled_hashes.keys():\n",
    "#             if previous_dled_hashes[key] != just_dled_hashes[key]:\n",
    "#                     changed_files.append(key)\n",
    "                \n",
    "#         if len(changed_files) == 0:\n",
    "#             print('There are no changes to previous downloaded lending club csvs (loan_info and pmt_hist) via shasum256 hashes')\n",
    "#         else:\n",
    "#             need_to_clean = True\n",
    "#             print('Compared to the previous data download, the shasum256 hashes changed for the following files: {0}'.format(\n",
    "#                 changed_files))\n",
    "\n",
    "#     except IndexError:\n",
    "#         need_to_clean = True\n",
    "#         print('Could not find previously download directory? This is probably your first time downloading the csvs or the first download to a new path.')\n",
    "\n",
    "#     return need_to_clean\n",
    "\n",
    "# def get_sorted_creationtime_dirs(ppath):\n",
    "#     csv_folders = [os.path.join(ppath, fn) for fn in os.listdir(\n",
    "#         ppath) if fn not in ['archived_csvs', 'working_csvs']]\n",
    "#     csv_folders = [(os.stat(path), path) for path in csv_folders]\n",
    "#     csv_folders = [(stat[ST_CTIME], path)\n",
    "#                    for stat, path in csv_folders if S_ISDIR(stat[ST_MODE])]\n",
    "#     return sorted(csv_folders)\n",
    "\n",
    "# def archiver(archive_flag, ppath, archiver_dir=None):\n",
    "#     archiver_dir = os.path.join(os.path.expanduser(\n",
    "#         '~'), 'projects', 'lendingclub', 'data', 'csvs', 'archived_csvs') if not archiver_dir else archiver_dir\n",
    "#     os.makedirs(archiver_dir, exist_ok=True)\n",
    "#     if archive_flag:\n",
    "#         just_dled = get_sorted_creationtime_dirs(ppath)[-1][1]\n",
    "        \n",
    "#         newest_folder = os.path.split(just_dled)[1]\n",
    "        \n",
    "#         copytree(just_dled, os.path.join(archiver_dir, newest_folder))\n",
    "        \n",
    "#         print('copied {0} to {1}'.format(newest_folder, archiver_dir))\n",
    "\n",
    "# def cleaner(ppath):\n",
    "#     just_dled = os.path.split(get_sorted_creationtime_dirs(ppath)[-1][1])[1]\n",
    "#     keep_dirs = ['archived_csvs', 'working_csvs', just_dled]\n",
    "#     for tree in os.listdir(ppath):\n",
    "#         if tree not in keep_dirs:\n",
    "#             rmtree(os.path.join(ppath, tree))\n",
    "#             print('removing old dirs {0}'.format(tree))\n",
    "#     return just_dled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T05:22:02.437044Z",
     "start_time": "2019-06-11T05:22:02.422071Z"
    }
   },
   "outputs": [],
   "source": [
    "# # setup\n",
    "# rel_path = '../../data/csvs'\n",
    "# now = time.strftime(\"%m_%d_%Hh_%Mm_%Ss_%Y\")\n",
    "# download_dir = 'csvs_' + now\n",
    "# os.mkdir(download_dir)\n",
    "\n",
    "# # download csvs\n",
    "# download_csvs(download_dir)\n",
    "\n",
    "# # calculate shasum256 hash on just downloaded csvs\n",
    "# just_dled_hashes = get_hashes(download_dir)\n",
    "\n",
    "# # copy the downloaded files to data location\n",
    "# copytree(download_dir, os.path.join(rel_path, download_dir))\n",
    "\n",
    "# # delete the original\n",
    "# rmtree(download_dir)\n",
    "\n",
    "# # get the dirs holding downloaded csvs by creation time (not archived_csvs dir)\n",
    "# csv_folders = get_sorted_creationtime_dirs(rel_path)\n",
    "\n",
    "# # check if compared to previous time, there are changes/additions/deletions in csvs\n",
    "# archive_flag = check_file_changes(csv_folders, just_dled_hashes)\n",
    "\n",
    "# # if something was different (archive_flag), then store a copy of just_downloaded to archives\n",
    "# archiver(archive_flag, rel_path)\n",
    "\n",
    "# # removes old downloads\n",
    "# cleaner(rel_path)\n",
    "\n",
    "# print('done downloading, checking, and archiving (when necessary) the csv files!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T05:26:18.086997Z",
     "start_time": "2019-06-11T05:26:18.066799Z"
    },
    "code_folding": [
     18,
     69,
     160,
     173,
     222,
     235
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../scripts/csv_dl_archiving/download_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../scripts/csv_dl_archiving/download_prep.py\n",
    "# driver download https://github.com/mozilla/geckodriver/releases\n",
    "# extracted geckodriver to /usr/local/bin in ubuntu\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "from stat import S_ISDIR, ST_CTIME, ST_MODE\n",
    "from shutil import copytree, rmtree\n",
    "import pause\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome import webdriver as chrome_webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "# relative import to grab user_creds\n",
    "sys.path.append('../../user_creds/')\n",
    "import account_info as acc_info\n",
    "\n",
    "class DriverBuilder():\n",
    "    # https://stackoverflow.com/questions/45631715/downloading-with-chrome-headless-and-selenium\n",
    "    def get_driver(self, download_location=None, headless=False):\n",
    "        driver = self._get_chrome_driver(download_location, headless)\n",
    "        driver.set_window_size(1400, 700)\n",
    "        return driver\n",
    "\n",
    "    def _get_chrome_driver(self, download_location, headless):\n",
    "        chrome_options = chrome_webdriver.Options()\n",
    "        if download_location:\n",
    "            prefs = {'download.default_directory': download_location,\n",
    "                     'download.prompt_for_download': False,\n",
    "                     'download.directory_upgrade': True,\n",
    "                     'safebrowsing.enabled': False,\n",
    "                     'safebrowsing.disable_download_protection': True}\n",
    "            chrome_options.add_experimental_option('prefs', prefs)\n",
    "            chrome_options.add_argument(\"--no-sandbox\")\n",
    "\n",
    "        if headless:\n",
    "            chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "        driver_path = '/usr/bin/chromedriver'\n",
    "\n",
    "        if sys.platform.startswith(\"win\"):\n",
    "            driver_path += \".exe\"\n",
    "\n",
    "        driver = Chrome(executable_path=driver_path,\n",
    "                        chrome_options=chrome_options)\n",
    "        if headless:\n",
    "            self.enable_download_in_headless_chrome(driver, download_location)\n",
    "        return driver\n",
    "\n",
    "    def enable_download_in_headless_chrome(self, driver, download_dir):\n",
    "        \"\"\"\n",
    "        there is currently a \"feature\" in chrome where\n",
    "        headless does not allow file download: https://bugs.chromium.org/p/chromium/issues/detail?id=696481\n",
    "        This method is a hacky work-around until the official chromedriver support for this.\n",
    "        Requires chrome version 62.0.3196.0 or above.\n",
    "        \"\"\"\n",
    "\n",
    "        # add missing support for chrome \"send_command\"  to selenium webdriver\n",
    "        driver.command_executor._commands[\"send_command\"] = (\n",
    "            \"POST\", '/session/$sessionId/chromium/send_command')\n",
    "\n",
    "        params = {'cmd': 'Page.setDownloadBehavior', 'params': {\n",
    "            'behavior': 'allow', 'downloadPath': download_dir}}\n",
    "        command_result = driver.execute(\"send_command\", params)\n",
    "        print(\"response from browser:\")\n",
    "        for key in command_result:\n",
    "            print(\"result:\" + key + \":\" + str(command_result[key]))\n",
    "\n",
    "def download_csvs(download_path):\n",
    "    '''\n",
    "    downloads all loan_info csvs and pmt_history csv\n",
    "    '''\n",
    "    print('downloading csvs to {0}'.format(os.path.abspath(download_path)))\n",
    "    \n",
    "    # setup constants\n",
    "    email = acc_info.email_throwaway\n",
    "    password = acc_info.password_throwaway\n",
    "    url_dl = \"https://www.lendingclub.com/info/download-data.action\"\n",
    "    url_signin = \"https://www.lendingclub.com/auth/login\"\n",
    "    url_pmt_hist = \"https://www.lendingclub.com/site/additional-statistics\"\n",
    "\n",
    "    d_builder = DriverBuilder()\n",
    "    driver = d_builder.get_driver(\n",
    "        download_location=download_path, headless=True)\n",
    "    \n",
    "    # sign in\n",
    "    driver.get(url_signin)\n",
    "    email_box = driver.find_element_by_xpath(\n",
    "        '/html/body/div[2]/div[1]/div[2]/form[1]/label[1]/input')\n",
    "    password_box = driver.find_element_by_xpath(\n",
    "        '/html/body/div[2]/div[1]/div[2]/form[1]/label[2]/input')\n",
    "\n",
    "    pause.milliseconds(1000)\n",
    "    email_box.send_keys(email)\n",
    "    password_box.send_keys(password)\n",
    "\n",
    "    button = driver.find_element_by_xpath(\n",
    "        '/html/body/div[2]/div[1]/div[2]/form[1]/button')\n",
    "    button.click()\n",
    "    pause.milliseconds(3000)\n",
    "\n",
    "    # download loan_info\n",
    "    driver.get(url_dl)\n",
    "    download_btn = driver.find_element_by_xpath(\n",
    "        '//*[@id=\"currentLoanStatsFileName\"]')\n",
    "\n",
    "    select = driver.find_element_by_xpath(\n",
    "        '//*[@id=\"loanStatsDropdown\"]')  # get the select element\n",
    "    options = select.find_elements_by_tag_name(\n",
    "        \"option\")  # get all the options into a list\n",
    "\n",
    "    options_dict = {}\n",
    "    for option in options:  # iterate over the options, place attribute value in list\n",
    "        options_dict[option.get_attribute(\"value\")] = option.text\n",
    "\n",
    "    for opt_val, text in options_dict.items():\n",
    "        print(\"starting download on option {0}, {1}\".format(opt_val, text))\n",
    "\n",
    "        select = driver.find_element_by_xpath(\n",
    "            '//*[@id=\"loanStatsDropdown\"]')\n",
    "        selection = Select(select)\n",
    "        selection.select_by_value(opt_val)\n",
    "        download_btn.click()\n",
    "        pause.milliseconds(2000)\n",
    "\n",
    "    # payment history downloads\n",
    "    driver.get(url_pmt_hist)\n",
    "\n",
    "    pmt_history = driver.find_element_by_xpath(\n",
    "        '/html/body/div[2]/section/div[2]/div/p[2]/a[2]')\n",
    "    pmt_history.click()\n",
    "\n",
    "    # wait for all downloads to finish\n",
    "    while True:\n",
    "        if len(os.listdir(download_path)) != (\n",
    "                len(options_dict) + 1):  # +1 for one pmt history file\n",
    "            time.sleep(5)\n",
    "            print('waiting for all csv downloads to start')\n",
    "            continue\n",
    "        else:\n",
    "            files = os.listdir(download_path)\n",
    "            k = 0\n",
    "            time.sleep(5)\n",
    "            print('checking/waiting for all csv downloads to finish')\n",
    "            for filename in files:\n",
    "                if 'crdownload' in filename:\n",
    "                    print('{0} is still downloading'.format(filename))\n",
    "                    time.sleep(30)\n",
    "                else:\n",
    "                    k += 1\n",
    "    #                 print(k)\n",
    "            if k == len(files):\n",
    "                time.sleep(2)\n",
    "                break\n",
    "\n",
    "    print('done downloading')\n",
    "    driver.close()\n",
    "    return True\n",
    "\n",
    "def get_hashes(path):\n",
    "    '''\n",
    "    gets shasum hashes for files to check for file changes\n",
    "    '''\n",
    "    print('computing shasum for files in {0}'.format(os.path.abspath(path)))\n",
    "    hashes = {}\n",
    "    files = os.listdir(path)\n",
    "    for file_ in files:\n",
    "        a = subprocess.check_output(\n",
    "            'shasum -a 256 {0}'.format(path + '/' + file_), shell=True)\n",
    "        hashes[file_] = a.split()[0]\n",
    "    return hashes\n",
    "\n",
    "def check_file_changes(csv_folders, just_dled_hashes):\n",
    "    need_to_clean = False\n",
    "    print('starting to check for file changes comparing what was just downloaded.')\n",
    "    try:\n",
    "        previous_dled_hashes = get_hashes(csv_folders[-2][1])\n",
    "\n",
    "        # compare new download to previous download\n",
    "        # check for added or deleted files\n",
    "        dne_files = set(just_dled_hashes.keys()).intersection(\n",
    "            set(previous_dled_hashes.keys()))\n",
    "        add_files = set(previous_dled_hashes.keys()).intersection(\n",
    "            set(just_dled_hashes.keys()))\n",
    "        if len(just_dled_hashes) != len(previous_dled_hashes):\n",
    "            need_to_clean = True\n",
    "            print(\"Compared to the previous time new csv's were downloaded, the following files were deleted: \\n {0}\".format(\n",
    "                dne_files))\n",
    "            print(\"Compared to the previous time new csv's were downloaded, the following files are new additions: \\n {0}\".format(\n",
    "                add_files))\n",
    "        else:\n",
    "            print('No files were added or deleted since previous downloading of csvs')\n",
    "\n",
    "        # check for shasum256 changes\n",
    "        changed_files = []\n",
    "        for key in just_dled_hashes.keys() & previous_dled_hashes.keys():\n",
    "            if previous_dled_hashes[key] != just_dled_hashes[key]:\n",
    "                    changed_files.append(key)\n",
    "                \n",
    "        if len(changed_files) == 0:\n",
    "            print('There are no changes to previous downloaded lending club csvs (loan_info and pmt_hist) via shasum256 hashes')\n",
    "        else:\n",
    "            need_to_clean = True\n",
    "            print('Compared to the previous data download, the shasum256 hashes changed for the following files: {0}'.format(\n",
    "                changed_files))\n",
    "\n",
    "    except IndexError:\n",
    "        need_to_clean = True\n",
    "        print('Could not find previously download directory? This is probably your first time downloading the csvs or the first download to a new path.')\n",
    "\n",
    "    return need_to_clean\n",
    "\n",
    "def get_sorted_creationtime_dirs(ppath):\n",
    "    print('getting folders sorted by creation time in {0}'.format(os.path.abspath(ppath)))\n",
    "    csv_folders = [os.path.join(ppath, fn) for fn in os.listdir(\n",
    "        ppath) if fn not in ['archived_csvs', 'working_csvs', 'latest_csvs']]\n",
    "    csv_folders = [(os.stat(path), path) for path in csv_folders]\n",
    "    csv_folders = [(stat[ST_CTIME], path)\n",
    "                   for stat, path in csv_folders if S_ISDIR(stat[ST_MODE])]\n",
    "    return sorted(csv_folders)\n",
    "\n",
    "def archiver(archive_flag, ppath, archiver_dir=None):\n",
    "    archiver_dir = os.path.join(os.path.expanduser(\n",
    "        '~'), 'projects', 'lendingclub', 'data', 'csvs', 'archived_csvs') if not archiver_dir else archiver_dir\n",
    "    os.makedirs(archiver_dir, exist_ok=True)\n",
    "    if archive_flag:\n",
    "        just_dled = get_sorted_creationtime_dirs(ppath)[-1][1]\n",
    "        \n",
    "        newest_folder = os.path.split(just_dled)[1]\n",
    "        \n",
    "        copytree(just_dled, os.path.join(archiver_dir, newest_folder))\n",
    "        \n",
    "        print('copied {0} to {1}'.format(newest_folder, os.path.abspath(archiver_dir)))\n",
    "\n",
    "def cleaner(ppath):\n",
    "    just_dled = os.path.split(get_sorted_creationtime_dirs(ppath)[-1][1])[1]\n",
    "    keep_dirs = ['archived_csvs', 'working_csvs', just_dled]\n",
    "    for tree in os.listdir(ppath):\n",
    "        if tree not in keep_dirs:\n",
    "            rmtree(os.path.join(ppath, tree))\n",
    "            print('removing old dirs {0}'.format(tree))\n",
    "    return just_dled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T05:26:23.104829Z",
     "start_time": "2019-06-11T05:26:23.085042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../scripts/csv_dl_archiving/download_and_check_csvs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../scripts/csv_dl_archiving/download_and_check_csvs.py\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from shutil import copytree, rmtree\n",
    "import download_prep as dp\n",
    "\n",
    "# setup\n",
    "rel_path = '../../data/csvs'\n",
    "now = time.strftime(\"%m_%d_%Hh_%Mm_%Ss_%Y\")\n",
    "download_dir = 'csvs_' + now\n",
    "os.mkdir(download_dir)\n",
    "\n",
    "# download csvs\n",
    "dp.download_csvs(download_dir)\n",
    "\n",
    "# calculate shasum256 hash on just downloaded csvs\n",
    "just_dled_hashes = dp.get_hashes(download_dir)\n",
    "\n",
    "# copy the downloaded files to data location\n",
    "copytree(download_dir, os.path.join(rel_path, download_dir))\n",
    "\n",
    "# delete the original\n",
    "rmtree(download_dir)\n",
    "\n",
    "# get the dirs holding downloaded csvs by creation time (not archived_csvs dir)\n",
    "csv_folders = dp.get_sorted_creationtime_dirs(rel_path)\n",
    "\n",
    "# check if compared to previous time, there are changes/additions/deletions in csvs\n",
    "archive_flag = dp.check_file_changes(csv_folders, just_dled_hashes)\n",
    "\n",
    "# if something was different (archive_flag), then store a copy of just_downloaded to archives\n",
    "dp.archiver(archive_flag, rel_path)\n",
    "\n",
    "# removes old downloads\n",
    "dp.cleaner(rel_path)\n",
    "\n",
    "print('done downloading, checking, and archiving (when necessary) the csv files!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Below was for storing in s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aws_access_key_id = \n",
    "aws_secret_access_key = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(ppath) if os.path.isdir(os.path.join(ppath,d))]\n",
    "dirs.sort()\n",
    "most_recent_dls = dirs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "files_to_store = os.listdir(ppath+'/'+most_recent_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ppath+'/'+most_recent_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bucket_name = ''\n",
    "for file_ in tqdm_notebook(files_to_store):\n",
    "    data = open('{0}'.format(ppath+'/'+most_recent_dls+'/'+file_), 'rb')\n",
    "    s3.Bucket(bucket_name).put_object(Key='{0}/{1}'.format(most_recent_dls, file_), Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
