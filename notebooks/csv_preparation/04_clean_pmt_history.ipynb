{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T01:44:55.620653Z",
     "start_time": "2019-06-18T01:44:55.603326Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHich is faster? Larger chunksize or smaller?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use chunks of about 25mill, which is 3 chunks as of 2019-09-29 10:59:48 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T01:26:53.414479Z",
     "start_time": "2019-11-30T01:26:53.407517Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../../lendingclub/csv_preparation/clean_pmt_history.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def find_dupe_dates(group):\n",
    "    '''finds duplicated dates in groupby group'''\n",
    "    return pd.to_datetime(group[group.duplicated('date')]['date'].values)\n",
    "\n",
    "def merge_dupe_dates(group, column_iloc_map):\n",
    "    '''\n",
    "    Merges the releveant numeric columns in loans that have 2 entries\n",
    "    for same month\n",
    "    '''\n",
    "    df_chunks = []\n",
    "    dupe_dates = find_dupe_dates(group)\n",
    "    df_chunks.append(group[~group['date'].isin(dupe_dates)])\n",
    "    for date in dupe_dates:\n",
    "        problem_rows = group[group['date'] == date]\n",
    "        ori_index = problem_rows.index\n",
    "        keep_row = problem_rows.iloc[-1].to_dict()\n",
    "        keep_row['outs_princp_beg'] = problem_rows.iloc[0,column_iloc_map['outs_princp_beg']]\n",
    "        summed = problem_rows.sum()\n",
    "        keep_row['princp_paid'] = summed['princp_paid']\n",
    "        keep_row['int_paid'] = summed['int_paid']\n",
    "        keep_row['fee_paid'] = summed['fee_paid']\n",
    "        # keep_row['amt_due'] = summed['amt_due']\n",
    "        keep_row['amt_paid'] = summed['amt_paid']\n",
    "        keep_row['charged_off_this_month'] = summed['charged_off_this_month']\n",
    "        keep_row['charged_off_amt'] = summed['charged_off_amt']\n",
    "        keep_row['recovs'] = summed['recovs']\n",
    "        keep_row['recov_fees'] = summed['recov_fees']\n",
    "        keep_row['all_cash_to_inv'] = summed['all_cash_to_inv']\n",
    "        to_append = pd.DataFrame(keep_row, index=[ori_index[-1]])\n",
    "        df_chunks.append(to_append)\n",
    "    return pd.concat(df_chunks)\n",
    "\n",
    "def insert_missing_dates(group, ids, verbose = False):\n",
    "    '''\n",
    "    redoes date so that there is one entry for each date\n",
    "    '''\n",
    "    # Copy Paste finished below\n",
    "    issue_d = group['issue_d'].min()\n",
    "    first_date = group['date'].min()\n",
    "    last_date = group['date'].max()\n",
    "    expected_months = set(pd.date_range(start=first_date, end=last_date, freq='MS'))\n",
    "    actual_months = set(group['date'])\n",
    "    to_make_months = list(expected_months.symmetric_difference(actual_months))\n",
    "    to_make_months.sort()\n",
    "    if len(to_make_months) > 0:\n",
    "        months_to_copy = []\n",
    "        for month in to_make_months:\n",
    "            months_to_copy.append(\n",
    "                find_closest_previous_record(\n",
    "                    ids, issue_d, first_date, actual_months, month))\n",
    "        copied = group[group['date'].isin(months_to_copy)].copy()\n",
    "        copied['amt_paid'] = 0.0\n",
    "        copied['date'] = to_make_months\n",
    "        copied['amt_due'] = np.where(copied['date'] < first_date, 0, copied['amt_due'])\n",
    "        return pd.concat([group, copied])\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('somehow there were no dates to add? id: {0}'.format(ids))\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_closest_previous_record(ids, issue_d, first_date, actual_months, month):\n",
    "    '''This function finds the closest previous month that is in the group.\n",
    "    It is here to handle cases where a record of one month is missing, but the\n",
    "    record before that missing month is also missing.'''\n",
    "    offset = pd.DateOffset(months=-1)\n",
    "    prev_month = month + offset\n",
    "    if month < issue_d:\n",
    "        print(ids)\n",
    "        return first_date\n",
    "    elif prev_month in actual_months:\n",
    "        return prev_month\n",
    "    return find_closest_previous_record(ids, issue_d, first_date, actual_months, prev_month)\n",
    "\n",
    "def detect_strange_pmt_hist(group, verbose=False):\n",
    "    '''\n",
    "    for each group in pmt_hist.groupby('LOAN_ID'), check that the \n",
    "    original due_amt is close to what is expected based on term, rate\n",
    "    '''\n",
    "    first_idx = group.index[0]\n",
    "    exp_pmt = np.pmt(group.at[first_idx,'InterestRate']/12., group.at[first_idx,'term'], -group.at[first_idx,'PBAL_BEG_PERIOD'])\n",
    "    rep_pmt = group.at[first_idx,'MONTHLYCONTRACTAMT']\n",
    "    if verbose:\n",
    "        print('expected pmt: {0}, reported pmt: {1}'.format(exp_pmt, rep_pmt))\n",
    "    if abs(exp_pmt - rep_pmt)/(exp_pmt) > .01:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def pmt_hist_fmt_date(df, col):\n",
    "    '''\n",
    "    Specifically reformats pmt_hist dates in the expected way\n",
    "    '''\n",
    "    month_dict = {\n",
    "        'jan': '1-',\n",
    "        'feb': '2-',\n",
    "        'mar': '3-',\n",
    "        'apr': '4-',\n",
    "        'may': '5-',\n",
    "        'jun': '6-',\n",
    "        'jul': '7-',\n",
    "        'aug': '8-',\n",
    "        'sep': '9-',\n",
    "        'oct': '10-',\n",
    "        'nov': '11-',\n",
    "        'dec': '12-'\n",
    "    }\n",
    "\n",
    "    df[col] = pd.to_datetime(\n",
    "        df[col].str[:3].str.lower().replace(month_dict) +\n",
    "        df[col].str[3:],\n",
    "        format='%m-%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T01:26:34.591972Z",
     "start_time": "2019-11-30T01:26:34.584767Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../../lendingclub/csv_preparation/04_clean_pmt_history.py\n",
    "'''\n",
    "Reads in payment history, does lots of cleaning\n",
    "'''\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import j_utils.munging as mg\n",
    "from lendingclub import config\n",
    "import lendingclub.csv_preparation.clean_pmt_history as cph\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # LOADING\n",
    "    csv_path = config.wrk_csv_dir\n",
    "    # for now its always been one csv. Will have to revisit if they break it out to multiple\n",
    "    pmt_hist_fnames = [f for f in os.listdir(csv_path) if 'PMTHIST' in f]\n",
    "    if len(pmt_hist_fnames) > 1:\n",
    "        sys.exit('more than one payment history file, need to change this code')\n",
    "\n",
    "    # load in dev_ids.pkl, pmt_hist_skiprows, dtypes\n",
    "    with open(os.path.join(config.data_dir, 'dev_ids.pkl'), \"rb\") as f:\n",
    "        dev_ids = pickle.load(f)\n",
    "    with open(os.path.join(config.data_dir, 'pmt_hist_skiprows.pkl'), \"rb\") as f:\n",
    "        pmt_hist_skiprows = pickle.load(f)\n",
    "    with open(os.path.join(config.data_dir, 'pmt_hist_dtypes.pkl'), 'rb') as f:\n",
    "        dtypes = pickle.load(f)\n",
    "        \n",
    "    print('loading pmt_hist; skipping {0} rows'.format(len(pmt_hist_skiprows)))\n",
    "    pmt_hist = pd.read_csv(os.path.join(csv_path, pmt_hist_fnames[0]),\n",
    "                           skiprows=pmt_hist_skiprows,\n",
    "                           na_values=['*'],\n",
    "                           dtype=dtypes)\n",
    "    print(\"{:,}\".format(len(pmt_hist)) + \" rows of pmt_hist loaded\")\n",
    "\n",
    "\n",
    "    \n",
    "    # COMPRESS MEMORY\n",
    "    changed_type_cols, pmt_hist = mg.reduce_memory(pmt_hist)\n",
    "    \n",
    "    # DATA INTEGRITY PART 1\n",
    "    id_grouped = pmt_hist.groupby('LOAN_ID')\n",
    "    strange_pmt_hist_ids = []\n",
    "    for ids, group in tqdm(id_grouped):\n",
    "        if cph.detect_strange_pmt_hist(group):\n",
    "            strange_pmt_hist_ids.append(ids)\n",
    "    with open(os.path.join(config.data_dir, 'strange_pmt_hist_ids.pkl'), \"wb\") as f:\n",
    "        pickle.dump(strange_pmt_hist_ids, f)\n",
    "    \n",
    "    # DATA PROCESSING\n",
    "    # Set loan ids as int _____________________________________________________\n",
    "    pmt_hist['LOAN_ID'] = pmt_hist['LOAN_ID'].astype(int)\n",
    "    print('payment history for', len(pmt_hist['LOAN_ID'].unique()), 'different loan ids')\n",
    "\n",
    "    # Round values to 3 decimal places ____________________________________________\n",
    "    pmt_hist = pmt_hist.round(3)\n",
    "\n",
    "    # renaming columns ____________________________________________________________\n",
    "    rename_col_dict = {\n",
    "        'LOAN_ID': 'loan_id',\n",
    "        'PBAL_BEG_PERIOD': 'outs_princp_beg',\n",
    "        'PRNCP_PAID': 'princp_paid',\n",
    "        'INT_PAID': 'int_paid',\n",
    "        'FEE_PAID': 'fee_paid',\n",
    "        'DUE_AMT': 'amt_due',\n",
    "        'RECEIVED_AMT': 'amt_paid',\n",
    "        'RECEIVED_D': 'pmt_date',\n",
    "        'PERIOD_END_LSTAT': 'status_period_end',\n",
    "        'MONTH': 'date',\n",
    "        'PBAL_END_PERIOD': 'outs_princp_end',\n",
    "        'MOB': 'm_on_books',\n",
    "        'CO': 'charged_off_this_month',\n",
    "        'COAMT': 'charged_off_amt',\n",
    "        'InterestRate': 'int_rate',\n",
    "        'IssuedDate': 'issue_d',\n",
    "        'MONTHLYCONTRACTAMT': 'monthly_pmt',\n",
    "        'dti': 'dti',\n",
    "        'State': 'addr_state',\n",
    "        'HomeOwnership': 'home_ownership',\n",
    "        'MonthlyIncome': 'm_income',\n",
    "        'EarliestCREDITLine': 'first_credit_line',\n",
    "        'OpenCREDITLines': 'open_credit_lines',\n",
    "        'TotalCREDITLines': 'total_credit_lines',\n",
    "        'RevolvingCREDITBalance': 'revol_credit_bal',\n",
    "        'RevolvingLineUtilization': 'revol_line_util',\n",
    "        'Inquiries6M': 'inq_6m',\n",
    "        'DQ2yrs': 'dq_24m',\n",
    "        'MonthsSinceDQ': 'm_since_dq',\n",
    "        'PublicRec': 'public_recs',\n",
    "        'MonthsSinceLastRec': 'm_since_rec',\n",
    "        'EmploymentLength': 'emp_len',\n",
    "        'currentpolicy': 'current_policy',\n",
    "        'grade': 'grade',\n",
    "        'term': 'term',\n",
    "        'APPL_FICO_BAND': 'fico_apply',\n",
    "        'Last_FICO_BAND': 'fico_last',\n",
    "        'VINTAGE': 'vintage',\n",
    "        'PCO_RECOVERY': 'recovs',\n",
    "        'PCO_COLLECTION_FEE': 'recov_fees',\n",
    "    }\n",
    "\n",
    "    pmt_hist.rename(columns=rename_col_dict, inplace=True)\n",
    "\n",
    "#     # There is a problem with the inquiries 6m column. Some are nan values and some\n",
    "#     # are marked '*' with no explanation. inq6m should be in loan info so dropping\n",
    "#     pmt_hist.drop('inq_6m', axis=1, inplace=True)\n",
    "\n",
    "    # There are 5 columns dealing with money: princp_paid, int_paid, fee_paid,\n",
    "    # recovs, and recovs_fee. princp_paid + int_paid + fee_paid is sometimes short\n",
    "    # of amt_paid. Be conservative and rewrite amt_paid to be sum of said 3.\n",
    "    # Also make all_cash_to_inv = amt_paid + recovs - recov_fees\n",
    "    # Fee paid is always positive, and by inspection it is money borrower pays out\n",
    "    pmt_hist[\n",
    "        'amt_paid'] = pmt_hist['princp_paid'] + pmt_hist['int_paid'] + pmt_hist['fee_paid']\n",
    "    pmt_hist['recovs'].fillna(0, inplace=True)\n",
    "    pmt_hist['recov_fees'].fillna(0, inplace=True)\n",
    "    pmt_hist[\n",
    "        'all_cash_to_inv'] = pmt_hist['amt_paid'] + pmt_hist['recovs'] - pmt_hist['recov_fees']\n",
    "\n",
    "    # turn all date columns into pandas timestamp _________________________________\n",
    "    for col in ['pmt_date', 'date', 'issue_d', 'first_credit_line']:\n",
    "        cph.pmt_hist_fmt_date(pmt_hist, col)\n",
    "\n",
    "\n",
    "    # status_period_end ____________________________________________________________\n",
    "    status_fix = {\n",
    "        'Current': 'current',\n",
    "        'Late (31-120 days)': 'late_120',\n",
    "        'Fully Paid': 'paid',\n",
    "        'Charged Off': 'charged_off',\n",
    "        'Default': 'defaulted',\n",
    "        'Late (16-30 days)': 'late_30',\n",
    "        'In Grace Period': 'grace_15',\n",
    "        'Issued': 'current'\n",
    "    }\n",
    "    pmt_hist['status_period_end'] = pmt_hist['status_period_end'].replace(\n",
    "        status_fix)\n",
    "\n",
    "    # home_ownership _______________________________________________________________\n",
    "    home_ownership_fix = {\n",
    "        'admin_us': 'other',\n",
    "        'mortgage': 'mortgage',\n",
    "        'rent': 'rent',\n",
    "        'own': 'own',\n",
    "        'other': 'other',\n",
    "        'none': 'none',\n",
    "        'any': 'none'\n",
    "    }\n",
    "    pmt_hist['home_ownership'] = pmt_hist['home_ownership'].str.lower().replace(\n",
    "        home_ownership_fix)\n",
    "\n",
    "    # fico_apply __________________________________________________________________\n",
    "    fico_apply_fix = {'850': '850-850'}\n",
    "    pmt_hist['fico_apply'] = pmt_hist['fico_apply'].replace(fico_apply_fix)\n",
    "    pmt_hist['fico_apply'] = (pmt_hist['fico_apply'].str[:3].astype(int) +\n",
    "                              pmt_hist['fico_apply'].str[4:].astype(int)) / 2\n",
    "    pmt_hist['fico_apply'] = pmt_hist['fico_apply'].astype(int)\n",
    "\n",
    "    # fico_last ___________________________________________________________________\n",
    "    fico_last_fix = {'845-HIGH': '845-849', 'LOW-499': '495-499'}\n",
    "    pmt_hist['fico_last'] = pmt_hist['fico_last'].replace(fico_last_fix)\n",
    "    pmt_hist.loc[pmt_hist['fico_last'] != 'MISSING', 'fico_last'] = (\n",
    "        pmt_hist.loc[pmt_hist['fico_last'] != 'MISSING', 'fico_last'].str[:3]\n",
    "        .astype(int) + pmt_hist.loc[pmt_hist['fico_last'] != 'MISSING',\n",
    "                                    'fico_last'].str[4:].astype(int)) / 2\n",
    "    pmt_hist.loc[pmt_hist['fico_last'] == 'MISSING', 'fico_last'] = pmt_hist.loc[\n",
    "        pmt_hist['fico_last'] == 'MISSING', 'fico_apply']\n",
    "    pmt_hist['fico_last'] = pmt_hist['fico_last'].astype(int)\n",
    "\n",
    "    # revol_credit_bal ____________________________________________________________\n",
    "    pmt_hist['revol_credit_bal'] = pmt_hist['revol_credit_bal'].astype(\n",
    "        float)\n",
    "\n",
    "    # fix on a few bad rows where I think there is a mistaken amt_paid ____________\n",
    "    pmt_hist.loc[(pmt_hist['pmt_date'].isnull() & pmt_hist['amt_paid'] > 0),\n",
    "                 'amt_paid'] = 0\n",
    "\n",
    "    # compress memory\n",
    "    changed_type_cols, pmt_hist = mg.reduce_memory(pmt_hist)\n",
    "\n",
    "\n",
    "    # map position to column\n",
    "    column_iloc_map = {\n",
    "        col_name: pmt_hist.iloc[-1].index.get_loc(col_name)\n",
    "        for col_name in pmt_hist.columns.values\n",
    "    }\n",
    "\n",
    "    # split into portions needing fixing and not needing fixing\n",
    "    dup_date_ids = pmt_hist[pmt_hist.duplicated(\n",
    "        ['loan_id', 'date'])]['loan_id'].unique()\n",
    "    already_good = pmt_hist[~pmt_hist['loan_id'].isin(dup_date_ids)]\n",
    "    needs_fixing = pmt_hist[pmt_hist['loan_id'].isin(dup_date_ids)]\n",
    "    del pmt_hist\n",
    "\n",
    "    # fix dfs with duplicate dates to be one per month\n",
    "    fixed_dfs = []\n",
    "    id_grouped = needs_fixing.groupby('loan_id')\n",
    "    for ids, group in tqdm(id_grouped):\n",
    "        if ids in dup_date_ids:\n",
    "            fixed_dfs.append(cph.merge_dupe_dates(group, column_iloc_map))\n",
    "\n",
    "    # combine dfs\n",
    "    fixed_df = pd.concat(fixed_dfs)\n",
    "    pmt_hist = pd.concat([already_good, fixed_df])\n",
    "    del already_good, fixed_df\n",
    "\n",
    "    # want one entry for every month for every loan until \"loan end\".\n",
    "    # clean_pmt_history_2 ensured that there were not duplicate entries per month\n",
    "    # now we ensure that there's an entry for each month\n",
    "    id_grouped = pmt_hist.groupby('loan_id')\n",
    "\n",
    "    fixed_dfs = []\n",
    "    fixed_ids = []\n",
    "    for ids, group in tqdm(id_grouped):\n",
    "        fix_df = cph.insert_missing_dates(group, ids)\n",
    "        if fix_df is not None:\n",
    "            fixed_dfs.append(fix_df)\n",
    "            fixed_ids.append(ids)\n",
    "\n",
    "    # combine the fixed entries with ones that don't need fixing\n",
    "    already_good = pmt_hist[~pmt_hist['loan_id'].isin(fixed_ids)]\n",
    "    fixed_df = pd.concat(fixed_dfs)\n",
    "    del pmt_hist\n",
    "    pmt_hist = pd.concat([already_good, fixed_df])\n",
    "    del already_good, fixed_df\n",
    "\n",
    "    # compress memory\n",
    "    changed_type_cols, pmt_hist = mg.reduce_memory(pmt_hist)\n",
    "\n",
    "    # resort to keep relevant rows together, reset index, save\n",
    "    pmt_hist.sort_values(by=['loan_id', 'date'], inplace=True)\n",
    "    pmt_hist.reset_index(inplace=True, drop=True)\n",
    "    pmt_hist.to_feather(os.path.join(config.data_dir, 'clean_pmt_history.fth'))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part  1 of cleaning lending club payment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T18:03:05.310689Z",
     "start_time": "2019-06-14T18:03:05.289186Z"
    }
   },
   "outputs": [],
   "source": [
    "import dir_constants as dc\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T18:12:52.056249Z",
     "start_time": "2019-06-14T18:12:52.036311Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = os.path.join(os.path.expanduser('~'), 'projects', 'lendingclub', 'data', 'csvs', 'lastest_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T18:12:56.634439Z",
     "start_time": "2019-06-14T18:12:56.615246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/justin/projects/lendingclub/data/csvs/lastest_csvs'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T21:09:02.930825Z",
     "start_time": "2018-08-23T21:06:05.795853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,327,674 rows of pmt_hist loaded\n",
      "payment history for 2003523 different loan ids\n"
     ]
    }
   ],
   "source": [
    "# Set some constants __________________________________________________________\n",
    "platform = 'lendingclub'\n",
    "\n",
    "# Set data_path _______________________________________________________________\n",
    "data_path = dc.home_path + '/rsync_dl_rig/unzipped_lc_csvs/'\n",
    "\n",
    "# Load in pmt_hist_file _______________________________________________________\n",
    "files = os.listdir(data_path)\n",
    "# loan_hist_filename = [file_ for file_ in files if file_.startswith('PMTHIST')][0]\n",
    "# pmt_hist = pd.read_csv(data_path + '{0}'.format(loan_hist_filename), low_memory=False)\n",
    "pmt_hist = pd.read_csv(PATH, low_memory=False)\n",
    "print(\"{:,}\".format(len(pmt_hist)) + \" rows of pmt_hist loaded\")\n",
    "\n",
    "# Set loan ids as strings _____________________________________________________\n",
    "pmt_hist['LOAN_ID'] = pmt_hist['LOAN_ID'].astype(int)\n",
    "print('payment history for', len(pmt_hist['LOAN_ID'].unique()), 'different loan ids')\n",
    "\n",
    "# Round values to 3 decimal places ____________________________________________\n",
    "pmt_hist = pmt_hist.round(3)\n",
    "\n",
    "# renaming columns ____________________________________________________________\n",
    "rename_col_dict = {\n",
    "    'LOAN_ID': 'loan_id',\n",
    "    'PBAL_BEG_PERIOD': 'outs_princp_beg',\n",
    "    'PRNCP_PAID': 'princp_paid',\n",
    "    'INT_PAID': 'int_paid',\n",
    "    'FEE_PAID': 'fee_paid',\n",
    "    'DUE_AMT': 'amt_due',\n",
    "    'RECEIVED_AMT': 'amt_paid',\n",
    "    'RECEIVED_D': 'pmt_date',\n",
    "    'PERIOD_END_LSTAT': 'status_period_end',\n",
    "    'MONTH': 'date',\n",
    "    'PBAL_END_PERIOD': 'outs_princp_end',\n",
    "    'MOB': 'm_on_books',\n",
    "    'CO': 'charged_off_this_month',\n",
    "    'COAMT': 'charged_off_amt',\n",
    "    'InterestRate': 'int_rate',\n",
    "    'IssuedDate': 'issue_d',\n",
    "    'MONTHLYCONTRACTAMT': 'monthly_pmt',\n",
    "    'dti': 'dti',\n",
    "    'State': 'addr_state',\n",
    "    'HomeOwnership': 'home_ownership',\n",
    "    'MonthlyIncome': 'm_income',\n",
    "    'EarliestCREDITLine': 'first_credit_line',\n",
    "    'OpenCREDITLines': 'open_credit_lines',\n",
    "    'TotalCREDITLines': 'total_credit_lines',\n",
    "    'RevolvingCREDITBalance': 'revol_credit_bal',\n",
    "    'RevolvingLineUtilization': 'revol_line_util',\n",
    "    'Inquiries6M': 'inq_6m',\n",
    "    'DQ2yrs': 'dq_24m',\n",
    "    'MonthsSinceDQ': 'm_since_dq',\n",
    "    'PublicRec': 'public_recs',\n",
    "    'MonthsSinceLastRec': 'm_since_rec',\n",
    "    'EmploymentLength': 'emp_len',\n",
    "    'currentpolicy': 'current_policy',\n",
    "    'grade': 'grade',\n",
    "    'term': 'term',\n",
    "    'APPL_FICO_BAND': 'fico_apply',\n",
    "    'Last_FICO_BAND': 'fico_last',\n",
    "    'VINTAGE': 'vintage',\n",
    "    'PCO_RECOVERY': 'recovs',\n",
    "    'PCO_COLLECTION_FEE': 'recov_fees',\n",
    "}\n",
    "\n",
    "pmt_hist.rename(columns=rename_col_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try and reduces memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T21:09:02.951672Z",
     "start_time": "2018-08-23T21:09:02.932456Z"
    }
   },
   "outputs": [],
   "source": [
    "import j_utils.munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T21:10:00.327854Z",
     "start_time": "2018-08-23T21:09:02.953191Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:13<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed dtypes of 26 cols\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37327674 entries, 0 to 37327673\n",
      "Data columns (total 40 columns):\n",
      "pmt_date                  object\n",
      "status_period_end         object\n",
      "date                      object\n",
      "issue_d                   object\n",
      "addr_state                object\n",
      "home_ownership            object\n",
      "first_credit_line         object\n",
      "inq_6m                    object\n",
      "public_recs               object\n",
      "emp_len                   object\n",
      "grade                     object\n",
      "fico_apply                object\n",
      "fico_last                 object\n",
      "vintage                   object\n",
      "amt_due                   float32\n",
      "amt_paid                  float32\n",
      "charged_off_amt           float32\n",
      "charged_off_this_month    int8\n",
      "current_policy            int8\n",
      "dq_24m                    float32\n",
      "dti                       float32\n",
      "fee_paid                  float32\n",
      "int_paid                  float32\n",
      "int_rate                  float32\n",
      "loan_id                   int32\n",
      "m_income                  float32\n",
      "m_on_books                int8\n",
      "m_since_dq                float32\n",
      "m_since_rec               float32\n",
      "monthly_pmt               float32\n",
      "open_credit_lines         float32\n",
      "outs_princp_beg           float32\n",
      "outs_princp_end           float32\n",
      "princp_paid               float32\n",
      "recov_fees                float32\n",
      "recovs                    float32\n",
      "revol_credit_bal          int32\n",
      "revol_line_util           float32\n",
      "term                      int8\n",
      "total_credit_lines        float32\n",
      "dtypes: float32(20), int32(2), int8(4), object(14)\n",
      "memory usage: 34.2 GB\n"
     ]
    }
   ],
   "source": [
    "changed_cols, pmt_hist = j_utils.munging.compress_memory(pmt_hist)\n",
    "pmt_hist.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T21:10:01.330885Z",
     "start_time": "2018-08-23T21:10:00.329488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T21:18:55.283433Z",
     "start_time": "2018-08-23T21:10:05.355478Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:98: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# There are 5 columns dealing with money: princp_paid, int_paid, fee_paid,\n",
    "# recovs, and recovs_fee. princp_paid + int_paid + fee_paid is sometimes short\n",
    "# of amt_paid. Be conservative and rewrite amt_paid to be sum of said 3.\n",
    "# Also make all_cash_to_inv = amt_paid + recovs - recov_fees\n",
    "# Fee paid is always positive, and by inspection it is money borrower pays out\n",
    "pmt_hist[\n",
    "    'amt_paid'] = pmt_hist['princp_paid'] + pmt_hist['int_paid'] + pmt_hist['fee_paid']\n",
    "pmt_hist['recovs'].fillna(0, inplace=True)\n",
    "pmt_hist['recov_fees'].fillna(0, inplace=True)\n",
    "pmt_hist[\n",
    "    'all_cash_to_inv'] = pmt_hist['amt_paid'] + pmt_hist['recovs'] - pmt_hist['recov_fees']\n",
    "\n",
    "# turn all date columns into pandas timestamp _________________________________\n",
    "month_dict = {\n",
    "    'jan': '1-',\n",
    "    'feb': '2-',\n",
    "    'mar': '3-',\n",
    "    'apr': '4-',\n",
    "    'may': '5-',\n",
    "    'jun': '6-',\n",
    "    'jul': '7-',\n",
    "    'aug': '8-',\n",
    "    'sep': '9-',\n",
    "    'oct': '10-',\n",
    "    'nov': '11-',\n",
    "    'dec': '12-'\n",
    "}\n",
    "\n",
    "# pmt_date ____________________________________________________________________\n",
    "pmt_hist['pmt_date'] = pd.to_datetime(\n",
    "    pmt_hist['pmt_date'].str[:3].str.lower().replace(month_dict) +\n",
    "    pmt_hist['pmt_date'].str[3:],\n",
    "    format='%m-%Y')\n",
    "\n",
    "# date ________________________________________________________________________\n",
    "pmt_hist['date'] = pd.to_datetime(\n",
    "    pmt_hist['date'].str[:3].str.lower().replace(month_dict) +\n",
    "    pmt_hist['date'].str[3:],\n",
    "    format='%m-%Y')\n",
    "\n",
    "# issue_d _____________________________________________________________________\n",
    "pmt_hist['issue_d'] = pd.to_datetime(\n",
    "    pmt_hist['issue_d'].str[:3].str.lower().replace(month_dict) +\n",
    "    pmt_hist['issue_d'].str[3:],\n",
    "    format='%m-%Y')\n",
    "\n",
    "# first_credit_line ____________________________________________________________\n",
    "pmt_hist['first_credit_line'] = pd.to_datetime(\n",
    "    pmt_hist['first_credit_line'].str[:3].str.lower().replace(month_dict) +\n",
    "    pmt_hist['first_credit_line'].str[3:],\n",
    "    format='%m-%Y')\n",
    "\n",
    "# status_period_end ____________________________________________________________\n",
    "status_fix = {\n",
    "    'Current': 'current',\n",
    "    'Late (31-120 days)': 'late_120',\n",
    "    'Fully Paid': 'paid',\n",
    "    'Charged Off': 'charged_off',\n",
    "    'Default': 'defaulted',\n",
    "    'Late (16-30 days)': 'late_30',\n",
    "    'In Grace Period': 'grace_15',\n",
    "    'Issued': 'current'\n",
    "}\n",
    "pmt_hist['status_period_end'] = pmt_hist['status_period_end'].replace(\n",
    "    status_fix)\n",
    "\n",
    "# home_ownership _______________________________________________________________\n",
    "home_ownership_fix = {\n",
    "    'admin_us': 'other',\n",
    "    'mortgage': 'mortgage',\n",
    "    'rent': 'rent',\n",
    "    'own': 'own',\n",
    "    'other': 'other',\n",
    "    'none': 'none',\n",
    "    'any': 'none'\n",
    "}\n",
    "pmt_hist['home_ownership'] = pmt_hist['home_ownership'].str.lower().replace(\n",
    "    home_ownership_fix)\n",
    "\n",
    "# public_recs __________________________________________________________________\n",
    "records_fix = {\n",
    "    '*': 1\n",
    "}  #leave nan as nan, but * had at least 1 from m_since_record\n",
    "pmt_hist['public_recs'] = pmt_hist['public_recs'].replace(records_fix).astype(\n",
    "    float)\n",
    "\n",
    "# fico_apply __________________________________________________________________\n",
    "fico_apply_fix = {'850': '850-850'}\n",
    "pmt_hist['fico_apply'] = pmt_hist['fico_apply'].replace(fico_apply_fix)\n",
    "pmt_hist['fico_apply'] = (pmt_hist['fico_apply'].str[:3].astype(int) +\n",
    "                          pmt_hist['fico_apply'].str[4:].astype(int)) / 2\n",
    "pmt_hist['fico_apply'] = pmt_hist['fico_apply'].astype(int)\n",
    "\n",
    "# fico_last ___________________________________________________________________\n",
    "fico_last_fix = {'845-HIGH': '845-849', 'LOW-499': '495-499'}\n",
    "pmt_hist['fico_last'] = pmt_hist['fico_last'].replace(fico_last_fix)\n",
    "pmt_hist.ix[pmt_hist['fico_last'] != 'MISSING', 'fico_last'] = (\n",
    "    pmt_hist.ix[pmt_hist['fico_last'] != 'MISSING', 'fico_last'].str[:3]\n",
    "    .astype(int) + pmt_hist.ix[pmt_hist['fico_last'] != 'MISSING',\n",
    "                               'fico_last'].str[4:].astype(int)) / 2\n",
    "pmt_hist.ix[pmt_hist['fico_last'] == 'MISSING', 'fico_last'] = pmt_hist.ix[\n",
    "    pmt_hist['fico_last'] == 'MISSING', 'fico_apply']\n",
    "pmt_hist['fico_last'] = pmt_hist['fico_last'].astype(int)\n",
    "\n",
    "# revol_credit_bal ____________________________________________________________\n",
    "pmt_hist['revol_credit_bal'] = pmt_hist['revol_credit_bal'].astype(\n",
    "    float)\n",
    "\n",
    "# fix on a few bad rows where I think there is a mistaken amt_paid ____________\n",
    "pmt_hist.ix[(pmt_hist['pmt_date'].isnull() & pmt_hist['amt_paid'] > 0),\n",
    "            'amt_paid'] = 0\n",
    "\n",
    "# There is a problem with the inquiries 6m column. Some are nan values and some\n",
    "# are marked '*' with no explanation. inq6m should be in loan info so dropping\n",
    "pmt_hist.drop('inq_6m', axis=1, inplace=True)\n",
    "\n",
    "# add a column which is numerical of loan_id for later reading from hdfstore\n",
    "pmt_hist['loan_id_num'] = pmt_hist['loan_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-23T21:19:19.198269Z",
     "start_time": "2018-08-23T21:18:55.649694Z"
    }
   },
   "outputs": [],
   "source": [
    "# save as feather format\n",
    "PATH = '/home/justin/all_data/lendingclub/'\n",
    "pmt_hist.to_feather(f'{PATH}pmt_hist_c1.fth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store part 1 of cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-24T20:30:46.160809Z",
     "start_time": "2018-08-24T20:30:46.135274Z"
    }
   },
   "outputs": [],
   "source": [
    "# # store pmt_history in hdfstore _______________________________________________\n",
    "# store = pd.HDFStore(\n",
    "#     dc.home_path+'/justin_tinkering/data_science/lendingclub/{0}_store.h5'.\n",
    "#     format(platform),\n",
    "#     append=True)\n",
    "\n",
    "# # Create min_itemsize_dict for allocating size when storing ___________________\n",
    "# min_itemsize_dict = {}\n",
    "# for col in pmt_hist.columns:\n",
    "#     if pmt_hist[col].dtype == np.object:\n",
    "#         print(col, pmt_hist[col].str.len().max())\n",
    "#         if col in ['State', 'VINTAGE', 'grade']:\n",
    "#             pass\n",
    "#         else:\n",
    "#             min_itemsize_dict[col] = 15\n",
    "\n",
    "# total_len = len(pmt_hist)\n",
    "# chunk_size = 120000 # 120k rows at a time\n",
    "# chunks = np.ceil(total_len/chunk_size)\n",
    "# df_chunks = np.array_split(pmt_hist, chunks)\n",
    "\n",
    "     \n",
    "# k = 0\n",
    "# for chunk in tqdm_notebook(df_chunks):\n",
    "#     if k == 0:\n",
    "#         store.append(\n",
    "#             'pmt_hist_intermediary_1',\n",
    "#             chunk,\n",
    "#             data_columns=True,\n",
    "#             index=True,\n",
    "#             append=False,\n",
    "#             min_itemsize=min_itemsize_dict)\n",
    "#         k += 1\n",
    "#     else:\n",
    "#         store.append(\n",
    "#             'pmt_hist_intermediary_1',\n",
    "#             chunk,\n",
    "#             data_columns=True,\n",
    "#             index=True,\n",
    "#             append=True)            \n",
    "        \n",
    "# # store pmt_hist ids        \n",
    "# pmt_hist_ids = pd.Series(pmt_hist['loan_id'].unique())\n",
    "# pmt_hist_ids.to_hdf(store, 'pmt_hist_ids', mode='w')        \n",
    "# print(store.keys())\n",
    "# print(store)        \n",
    "# store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below was investigating to base my choices above on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmt_hist['unaccounted_rec_pmt_money'] = pmt_hist['amt_paid'] - (\n",
    "#     pmt_hist['princp_paid'] + pmt_hist['int_paid'] + pmt_hist['fee_paid'])\n",
    "\n",
    "# # Don't care about differences less than a cent _______________________________\n",
    "# pmt_hist['unaccounted_rec_pmt_money'] = np.where(\n",
    "#     pmt_hist['unaccounted_rec_pmt_money'] < 0.01, 0,\n",
    "#     pmt_hist['unaccounted_rec_pmt_money'])\n",
    "\n",
    "# # These should probably be Received_amt 0 because there is no received_d\n",
    "# pmt_hist[(pmt_hist['unaccounted_rec_pmt_money'] > 0) & (pmt_hist['PERIOD_END_LSTAT'] != 'Fully Paid')]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:lendingclub]",
   "language": "python",
   "name": "conda-env-lendingclub-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
