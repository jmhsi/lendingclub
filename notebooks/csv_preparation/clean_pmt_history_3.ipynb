{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T00:38:32.417368Z",
     "start_time": "2019-06-19T00:38:32.373078Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile ../../scripts/csv_preparation/clean_pmt_history_3.py\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import os\n",
    "\n",
    "def find_closest_previous_record(ids, issue_d, first_date, actual_months, month):\n",
    "    '''This function finds the closest previous month that is in the group. \n",
    "    It is here to handle cases where a record of one month is missing, but the\n",
    "    record before that missing month is also missing.'''\n",
    "    offset = pd.DateOffset(months=-1)\n",
    "    prev_month = month + offset\n",
    "    if month < issue_d:\n",
    "        print(ids)\n",
    "        return first_date\n",
    "    elif prev_month in actual_months:\n",
    "        return prev_month\n",
    "    else:\n",
    "        find_closest_previous_record(ids, issue_d, first_date, actual_months, prev_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T00:38:37.318754Z",
     "start_time": "2019-06-19T00:38:32.569483Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "dpath = os.path.join(os.path.expanduser('~'), 'projects', 'lendingclub', 'data')\n",
    "pmt_hist = pd.read_feather(os.path.join(dpath, 'clean_pmt_history_2.fth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T01:27:21.983365Z",
     "start_time": "2019-06-19T00:42:59.003358Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/justin/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/justin/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 109, in run\n",
      "    if instance.miniters > 1 and \\\n",
      "AttributeError: 'tqdm' object has no attribute 'miniters'\n",
      "\n",
      "  0%|          | 0/2375574 [00:00<?, ?it/s]/home/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n",
      "  \n",
      "100%|██████████| 2375574/2375574 [42:47<00:00, 925.10it/s] \n"
     ]
    }
   ],
   "source": [
    "# want one entry for every month for every loan until \"loan end\".\n",
    "# clean_pmt_history_2 ensured that there were not duplicate entries per month\n",
    "# now we ensure that there's an entry for each month\n",
    "id_grouped = pmt_hist.groupby('loan_id')\n",
    "\n",
    "fixed_dfs = []\n",
    "fixed_ids = []\n",
    "for ids, group in tqdm(id_grouped):\n",
    "        # Copy Paste finished below\n",
    "        issue_d = group['issue_d'].min()\n",
    "        first_date = group['date'].min()\n",
    "        last_date = group['date'].max()\n",
    "        expected_months = set(pd.DatetimeIndex(start=first_date, end=last_date, freq='MS'))\n",
    "        actual_months = set(group['date'])\n",
    "        to_make_months = list(expected_months.symmetric_difference(actual_months))\n",
    "        to_make_months.sort()\n",
    "        if len(to_make_months) > 1:\n",
    "            months_to_copy = []\n",
    "            for month in to_make_months:\n",
    "                months_to_copy.append(find_closest_previous_record(ids, issue_d, first_date, actual_months, month))\n",
    "            copied = group[group['date'].isin(months_to_copy)].copy()\n",
    "            copied['amt_paid'] = 0.0\n",
    "            copied['date'] = to_make_months\n",
    "            copied['amt_due'] = np.where(copied['date'] < first_date, 0, copied['amt_due'])\n",
    "            fixed_dfs.append(pd.concat([group, copied]))\n",
    "            fixed_ids.append(ids)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T01:27:45.089924Z",
     "start_time": "2019-06-19T01:27:21.986244Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine the fixed entries with ones that don't need fixing\n",
    "already_good = pmt_hist[~pmt_hist['loan_id'].isin(fixed_ids)]\n",
    "fixed_df = pd.concat(fixed_dfs)\n",
    "del pmt_hist\n",
    "pmt_hist = pd.concat([already_good, fixed_df])\n",
    "del already_good, fixed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T01:29:03.574804Z",
     "start_time": "2019-06-19T01:27:45.094793Z"
    }
   },
   "outputs": [],
   "source": [
    "# resort to keep relevant rows together, reset index, save\n",
    "pmt_hist.sort_values(by=['loan_id', 'date'], inplace=True)\n",
    "pmt_hist.reset_index(inplace=True, drop=True)\n",
    "pmt_hist.to_feather(os.path.join(dpath, 'clean_pmt_history_3.fth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 of cleaning lending club payment history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T18:56:11.944821Z",
     "start_time": "2018-08-25T18:56:11.925324Z"
    }
   },
   "outputs": [],
   "source": [
    "import dir_constants as dc\n",
    "from tqdm import tqdm_notebook, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T18:49:38.145625Z",
     "start_time": "2018-08-25T18:49:38.124946Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_closest_previous_record(ids, issue_d, first_date, actual_months, month):\n",
    "    '''This function finds the closest previous month that is in the group. \n",
    "    It is here to handle cases where a record of one month is missing, but the\n",
    "    record before that missing month is also missing.'''\n",
    "    offset = pd.DateOffset(months=-1)\n",
    "    prev_month = month + offset\n",
    "    if month < issue_d:\n",
    "        print(ids)\n",
    "        return first_date\n",
    "    elif prev_month in actual_months:\n",
    "        return prev_month\n",
    "    else:\n",
    "        find_closest_previous_record(ids, issue_d, first_date, actual_months, prev_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T18:50:02.527310Z",
     "start_time": "2018-08-25T18:49:39.138684Z"
    }
   },
   "outputs": [],
   "source": [
    "project = 'lendingclub'\n",
    "# !ls {dc.data_path+project}\n",
    "path = dc.data_path+project\n",
    "\n",
    "pmt_hist = pd.read_feather(path+'/pmt_hist_c2.fth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are loans that have multiple row entries per month (as in multiple pmts in same month) and there are also loans that don't have any entry for a month. Make an entry for the missing month showing 0 payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T19:44:26.294420Z",
     "start_time": "2018-08-25T18:56:13.307151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/justin/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/justin/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 109, in run\n",
      "    if instance.miniters > 1 and \\\n",
      "AttributeError: 'tqdm' object has no attribute 'miniters'\n",
      "\n",
      "100%|██████████| 2003523/2003523 [47:57<00:00, 696.20it/s] \n"
     ]
    }
   ],
   "source": [
    "id_grouped = pmt_hist.groupby('loan_id')\n",
    "\n",
    "fixed_dfs = []\n",
    "fixed_ids = []\n",
    "for ids, group in tqdm(id_grouped):\n",
    "        # Copy Paste finished below\n",
    "        issue_d = group['issue_d'].min()\n",
    "        first_date = group['date'].min()\n",
    "        last_date = group['date'].max()\n",
    "        expected_months = set(pd.DatetimeIndex(start=first_date, end=last_date, freq='MS'))\n",
    "        actual_months = set(group['date'])\n",
    "        to_make_months = list(expected_months.symmetric_difference(actual_months))\n",
    "        to_make_months.sort()\n",
    "        if len(to_make_months) > 1:\n",
    "            months_to_copy = []\n",
    "            for month in to_make_months:\n",
    "                months_to_copy.append(find_closest_previous_record(ids, issue_d, first_date, actual_months, month))\n",
    "            copied = group[group['date'].isin(months_to_copy)].copy()\n",
    "            copied['amt_paid'] = 0.0\n",
    "            copied['date'] = to_make_months\n",
    "            copied['amt_due'] = np.where(copied['date'] < first_date, 0, copied['amt_due'])\n",
    "            fixed_dfs.append(pd.concat([group, copied]))\n",
    "            fixed_ids.append(ids)\n",
    "        else:\n",
    "            pass\n",
    "#             already_good_dfs.append(group)\n",
    "#             if len(already_good_dfs) == chunksize:\n",
    "#                 better_sized_already_good_dfs.append(pd.concat(already_good_dfs))\n",
    "#                 already_good_dfs = []\n",
    "#             if n+1 == n_chunks: # if on the last chunk\n",
    "#                 better_sized_already_good_dfs.append(pd.concat(already_good_dfs))\n",
    "#                 already_good_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T19:47:23.204484Z",
     "start_time": "2018-08-25T19:47:15.088546Z"
    }
   },
   "outputs": [],
   "source": [
    "already_good = pmt_hist[~pmt_hist['loan_id'].isin(fixed_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T19:47:43.516175Z",
     "start_time": "2018-08-25T19:47:42.249261Z"
    }
   },
   "outputs": [],
   "source": [
    "fixed_df = pd.concat(fixed_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T19:48:47.906192Z",
     "start_time": "2018-08-25T19:48:28.038302Z"
    }
   },
   "outputs": [],
   "source": [
    "del pmt_hist\n",
    "pmt_hist = pd.concat([already_good, fixed_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T20:01:19.390857Z",
     "start_time": "2018-08-25T20:01:13.059036Z"
    }
   },
   "outputs": [],
   "source": [
    "del already_good, fixed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T20:01:37.182860Z",
     "start_time": "2018-08-25T20:01:37.133510Z"
    }
   },
   "outputs": [],
   "source": [
    "pmt_hist.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T20:03:40.193008Z",
     "start_time": "2018-08-25T20:02:59.888122Z"
    }
   },
   "outputs": [],
   "source": [
    "pmt_hist.to_feather(path+'/pmt_hist_clean.fth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T19:45:01.554841Z",
     "start_time": "2018-08-25T19:45:01.527615Z"
    }
   },
   "outputs": [],
   "source": [
    "# # fix loans with no record at all for a specific month ________________________\n",
    "# pmt_hist_ids = store['pmt_hist_ids'].astype(int)\n",
    "# max_id = pmt_hist_ids.max()\n",
    "# chunksize = 800\n",
    "# n_chunks = len(pmt_hist_ids)//chunksize + 1\n",
    "\n",
    "# already_good_dfs = []\n",
    "# better_sized_already_good_dfs = []\n",
    "# fixed_dfs = []\n",
    "# # k = 0\n",
    "# for n in tqdm_notebook(np.arange(n_chunks)):\n",
    "#     if n == 0:\n",
    "#         left_bound = 0\n",
    "#     else:\n",
    "#         left_bound = pmt_hist_ids[n*chunksize]\n",
    "#     if n == (n_chunks - 1):\n",
    "#         right_bound = max_id\n",
    "#     else:\n",
    "#         right_bound = pmt_hist_ids[(n+1)*chunksize]\n",
    "    \n",
    "#     chunk = pd.read_hdf(\n",
    "#         store,\n",
    "#         'pmt_hist_intermediary_2',\n",
    "#         where='(loan_id_num > left_bound) & (loan_id_num <= right_bound)')\n",
    "    \n",
    "#     id_grouped = chunk.groupby('loan_id')\n",
    "#     for ids, group in id_grouped:\n",
    "#         # Copy Paste finished below\n",
    "#         issue_d = group['issue_d'].min()\n",
    "#         first_date = group['date'].min()\n",
    "#         last_date = group['date'].max()\n",
    "#         expected_months = set(pd.DatetimeIndex(start=first_date, end=last_date, freq='MS'))\n",
    "#         actual_months = set(group['date'])\n",
    "#         to_make_months = list(expected_months.symmetric_difference(actual_months))\n",
    "#         to_make_months.sort()\n",
    "#         if len(to_make_months) > 1:\n",
    "#             months_to_copy = []\n",
    "#             for month in to_make_months:\n",
    "#                 months_to_copy.append(find_closest_previous_record(ids, issue_d, first_date, actual_months, month))\n",
    "#             copied = group[group['date'].isin(months_to_copy)].copy()\n",
    "#             copied['amt_paid'] = 0.0\n",
    "#             copied['date'] = to_make_months\n",
    "#             copied['amt_due'] = np.where(copied['date'] < first_date, 0, copied['amt_due'])\n",
    "#             fixed_dfs.append(pd.concat([group, copied]))\n",
    "#         else:\n",
    "#             already_good_dfs.append(group)\n",
    "#             if len(already_good_dfs) == chunksize:\n",
    "#                 better_sized_already_good_dfs.append(pd.concat(already_good_dfs))\n",
    "#                 already_good_dfs = []\n",
    "#             if n+1 == n_chunks: # if on the last chunk\n",
    "#                 better_sized_already_good_dfs.append(pd.concat(already_good_dfs))\n",
    "#                 already_good_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T20:01:47.864057Z",
     "start_time": "2018-08-25T20:01:47.844849Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # Create min_itemsize_dict for allocating size when storing ___________________\n",
    "# min_itemsize_dict = {}\n",
    "# #arbitrarily take last 10000 to hopefully be long enough for min item size\n",
    "# example = pd.concat(better_sized_already_good_dfs[-20:]) \n",
    "# for col in example.columns:\n",
    "#     if example[col].dtype == np.object:\n",
    "#         print(col, example[col].str.len().max())\n",
    "#         if col in ['State', 'VINTAGE', 'grade']:\n",
    "#             pass\n",
    "#         else:\n",
    "#             min_itemsize_dict[col] = 15\n",
    "\n",
    "# col_dtype_map = better_sized_already_good_dfs[0].dtypes.to_dict()\n",
    "# all_fixed_dfs = pd.concat(fixed_dfs)\n",
    "# for col, dtype in col_dtype_map.items():\n",
    "#     all_fixed_dfs[col] = all_fixed_dfs[col].astype(dtype)\n",
    "# k = 0\n",
    "# for chunk in tqdm_notebook([all_fixed_dfs] + better_sized_already_good_dfs):\n",
    "#     sorted_chunk = chunk.sort_values(['loan_id', 'date'])\n",
    "#     if k == 0:\n",
    "#         store.append(\n",
    "#             'pmt_hist_clean',\n",
    "#             sorted_chunk,\n",
    "#             data_columns=True,\n",
    "#             index=True,\n",
    "#             append=False,\n",
    "#             min_itemsize=min_itemsize_dict)\n",
    "#         k += 1\n",
    "#     else:\n",
    "#         store.append(\n",
    "#             'pmt_hist_clean',\n",
    "#             sorted_chunk,\n",
    "#             data_columns=True,\n",
    "#             index=True,\n",
    "#             append=True)       \n",
    "        \n",
    "# store.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "598px",
    "left": "361px",
    "right": "279px",
    "top": "11px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
