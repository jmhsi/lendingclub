{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So 1.0.0 doesn't actually convincingly perform better than 0.2.1 (RF) so I'm seeing if more hidden layers changes anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_science.lendingclub.dataprep_and_modeling.modeling_utils.data_prep_new as data_prep\n",
    "import dir_constants as dc\n",
    "from sklearn.externals import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# HTML('''<script>\n",
    "# code_show_err=false; \n",
    "# function code_toggle_err() {\n",
    "#  if (code_show_err){\n",
    "#  $('div.output_stderr').hide();\n",
    "#  } else {\n",
    "#  $('div.output_stderr').show();\n",
    "#  }\n",
    "#  code_show_err = !code_show_err\n",
    "# } \n",
    "# $( document ).ready(code_toggle_err);\n",
    "# </script>\n",
    "# To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT FORGET TO DROP ISSUE_D AFTER PREPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'lendingclub'\n",
    "use_cuda = True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "save_path = \"model_dump/nn_1_0_1/\"\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "store = pd.HDFStore(\n",
    "    dc.home_path+'/justin_tinkering/data_science/lendingclub/{0}_store.h5'.\n",
    "    format(platform),\n",
    "    append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_info = store['train_filtered_columns']\n",
    "columns = loan_info.columns.values\n",
    "# checking dtypes to see which columns need one hotting, and which need null or not\n",
    "to_one_hot = []\n",
    "to_null_or_not = []\n",
    "do_nothing = []\n",
    "for col in columns:\n",
    "    if loan_info[col].dtypes == np.dtype('O'):\n",
    "#         print(col, loan_info[col].isnull().value_counts(dropna=False).to_dict())\n",
    "        to_one_hot.append(col)\n",
    "    elif len(loan_info[col].isnull().value_counts(dropna=False)) > 1:\n",
    "#         print(col, loan_info[col].isnull().value_counts(dropna=False).to_dict())\n",
    "        to_null_or_not.append(col)\n",
    "    else:\n",
    "#         print(col, loan_info[col].isnull().value_counts(dropna=False).to_dict())\n",
    "        do_nothing.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Until I figure out a good imputation method (e.g. bayes PCA), just drop columns with null still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, mean_series, std_dev_series = data_prep.process_data_train(\n",
    "    loan_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx,:], self.targets[idx,:]\n",
    "    \n",
    "def get_loader(dataset, use_cuda, batch_size=6400, shuffle=True):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=use_cuda) \n",
    "\n",
    "train_dataset = TrainDataset(train_X.values, train_y.values)\n",
    "train_loader = get_loader(train_dataset, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instantiate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile model_dump/nn_1_0_1/net_class.py\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.autograd import Variable\n",
    "# import numpy as np\n",
    "\n",
    "# dtype = torch.FloatTensor\n",
    "\n",
    "# nn_input_dim = 223\n",
    "# hly1_n = 300\n",
    "# hly2_n = 400\n",
    "# hly3_n = 300\n",
    "# hly4_n = 200\n",
    "# hly5_n = 100\n",
    "# hly6_n = 100\n",
    "# hly7_n = 100\n",
    "# # hly8_n = 100\n",
    "# nn_output_dim = 1\n",
    "\n",
    "# class Net(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.hl1 = nn.Linear(nn_input_dim, hly1_n)\n",
    "#         self.hl2 = nn.Linear(hly1_n, hly2_n)\n",
    "#         self.hl3 = nn.Linear(hly2_n, hly3_n)\n",
    "#         self.hl4 = nn.Linear(hly3_n, hly4_n)\n",
    "#         self.hl5 = nn.Linear(hly4_n, hly5_n)\n",
    "#         self.hl6 = nn.Linear(hly5_n, hly6_n)\n",
    "#         self.hl7 = nn.Linear(hly6_n, hly7_n)\n",
    "# #         self.hl8 = nn.Linear(hly7_n, hly8_n)        \n",
    "#         self.out = nn.Linear(hly7_n, nn_output_dim)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = F.leaky_relu(self.hl1(x))\n",
    "#         x = F.leaky_relu(self.hl2(x))\n",
    "#         x = F.leaky_relu(self.hl3(x))\n",
    "#         x = F.leaky_relu(self.hl4(x))\n",
    "#         x = F.leaky_relu(self.hl5(x))\n",
    "#         x = F.leaky_relu(self.hl6(x))        \n",
    "#         x = F.leaky_relu(self.hl7(x))        \n",
    "# #         x = F.leaky_relu(self.hl8(x))\n",
    "#         x = self.out(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "    \n",
    "# def torch_version(df_inputs, net):\n",
    "#     input = Variable(torch.from_numpy(df_inputs.values)).type(dtype)\n",
    "#     return np.round(net(input).data.cpu().numpy(),5).ravel()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_input_dim = 223\n",
    "hly1_n = 300\n",
    "hly2_n = 400\n",
    "hly3_n = 300\n",
    "hly4_n = 200\n",
    "hly5_n = 100\n",
    "hly6_n = 100\n",
    "hly7_n = 100\n",
    "# hly8_n = 100\n",
    "nn_output_dim = 1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hl1 = nn.Linear(nn_input_dim, hly1_n)\n",
    "        self.hl2 = nn.Linear(hly1_n, hly2_n)\n",
    "        self.hl3 = nn.Linear(hly2_n, hly3_n)\n",
    "        self.hl4 = nn.Linear(hly3_n, hly4_n)\n",
    "        self.hl5 = nn.Linear(hly4_n, hly5_n)\n",
    "        self.hl6 = nn.Linear(hly5_n, hly6_n)\n",
    "        self.hl7 = nn.Linear(hly6_n, hly7_n)\n",
    "#         self.hl8 = nn.Linear(hly7_n, hly8_n)        \n",
    "        self.out = nn.Linear(hly7_n, nn_output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.hl1(x))\n",
    "        x = F.leaky_relu(self.hl2(x))\n",
    "        x = F.leaky_relu(self.hl3(x))\n",
    "        x = F.leaky_relu(self.hl4(x))\n",
    "        x = F.leaky_relu(self.hl5(x))\n",
    "        x = F.leaky_relu(self.hl6(x))        \n",
    "        x = F.leaky_relu(self.hl7(x))        \n",
    "#         x = F.leaky_relu(self.hl8(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001, weight_decay=0.00135)\n",
    "# scheduler = torch.optim.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 600\n",
    "epoch_list = []\n",
    "loss_list = []\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, targets = data\n",
    "        # wrap in Variable\n",
    "        inputs, targets = Variable(inputs.cuda()).type(dtype), Variable(targets.cuda()).type(dtype)\n",
    "\n",
    "        # in your training loop:\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        \n",
    "        output = net(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data[0]\n",
    "    \n",
    "    try:\n",
    "        last_loss = loss_list[-1]\n",
    "    except:\n",
    "        last_loss = 9999999999999\n",
    "    if running_loss > (2*last_loss):\n",
    "        pass\n",
    "    else:\n",
    "        epoch_list.append(epoch)\n",
    "        loss_list.append(running_loss)\n",
    "    if epoch+1 % 100 == 0:\n",
    "        # drop learning rate at 250 epoch\n",
    "        optimizer.param_groups[0]['lr'] *= .97\n",
    "    if epoch % 1 == 0:\n",
    "        plt.plot(epoch_list, loss_list)\n",
    "        plt.title(\"Epoch: {0}\".format(epoch))\n",
    "        fig.canvas.draw()\n",
    "    if (epoch >= 99) & ((epoch+1) % 20 == 0):\n",
    "        torch.save(net.state_dict(), save_path+'1.0.1_e{0}'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the weights and biases of the nn into np since at this size np is faster (correction, pytorch was faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_hl1_weight = net.hl1.weight.data.numpy()\n",
    "# np_hl1_bias = net.hl1.bias.data.numpy()\n",
    "# np_hl2_weight = net.hl2.weight.data.numpy()\n",
    "# np_hl2_bias = net.hl2.bias.data.numpy()\n",
    "# np_out_weight = net.out.weight.data.numpy()\n",
    "# np_out_bias = net.out.bias.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check that they output the same and speedtest (pytorch was faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def np_version(df_inputs):\n",
    "#     np_hl1_z = df_inputs.dot(np_hl1_weight.T) + np_hl1_bias\n",
    "#     np_hl1_a = np.maximum(.01*np_hl1_z, np_hl1_z)\n",
    "#     np_hl2_z = np_hl1_a.dot(np_hl2_weight.T) + np_hl2_bias\n",
    "#     np_hl2_a = np.maximum(.01*np_hl2_z, np_hl2_z)\n",
    "#     np_out = np_hl2_a.dot(np_out_weight.T) + np_out_bias\n",
    "#     return np_out\n",
    "\n",
    "class FeedDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx,:].values\n",
    "\n",
    "def torch_version(df_inputs, net):\n",
    "    feed_dataset = FeedDataset(df_inputs)\n",
    "    feed_loader = get_loader(feed_dataset, batch_size=6400, shuffle=False, use_cuda = True)\n",
    "    all_results = []\n",
    "    for i, data in enumerate(feed_loader):\n",
    "        # wrap in Variable\n",
    "        inputs = data\n",
    "        inputs = Variable(inputs.cuda()).type(dtype)\n",
    "#         inputs = Variable(inputs.cuda()).type(dtype)\n",
    "        outputs = np.round(net(inputs).data.cpu().numpy(),5).ravel().tolist()\n",
    "        all_results += outputs\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit np_version(standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit torch_version(train_X, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "test = store['test_filtered_columns']\n",
    "train = store['train_filtered_columns']\n",
    "loan_npv_rois = store['loan_npv_rois']\n",
    "default_series = test['target_strict']\n",
    "results = store['results']\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = data_prep.process_data_test(train)\n",
    "train_y = train_y['npv_roi_10'].values\n",
    "test_X, test_y = data_prep.process_data_test(test)\n",
    "test_y = test_y['npv_roi_10'].values\n",
    "# regr = joblib.load('model_dump/model_0.2.1.pkl')\n",
    "regr_version = '1.0.1'\n",
    "test_yhat = torch_version(test_X, net)\n",
    "train_yhat = torch_version(train_X, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = mean_squared_error(test_yhat,test_y)\n",
    "train_mse = mean_squared_error(train_yhat,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models_net(trials, port_size, available_loans, net, regr_version, test, loan_npv_rois,\n",
    "                default_series):\n",
    "    results = {}\n",
    "    pct_default = {}\n",
    "    test_copy = test.copy()\n",
    "    for trial in tqdm_notebook(np.arange(trials)):\n",
    "        loan_ids = np.random.choice(\n",
    "            test_copy.index.values, available_loans, replace=False)\n",
    "        loans_to_pick_from = test_copy.loc[loan_ids, :]\n",
    "        scores = torch_version(loans_to_pick_from, net)\n",
    "        scores_series = pd.Series(dict(zip(loan_ids, scores)))\n",
    "        scores_series.sort_values(ascending=False, inplace=True)\n",
    "        picks = scores_series[:900].index.values\n",
    "        results[trial] = loan_npv_rois.loc[picks, :].mean().to_dict()\n",
    "        pct_default[trial] = (default_series.loc[picks].sum()) / port_size\n",
    "    pct_default_series = pd.Series(pct_default)\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df['pct_def'] = pct_default_series\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as per done with baseline models, say 3000 loans available\n",
    "# , pick 900 of them\n",
    "trials = 20000\n",
    "port_size = 900\n",
    "available_loans = 3000\n",
    "model_results = eval_models_net(trials, port_size, available_loans, net, regr_version, test_X, loan_npv_rois, default_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index = []\n",
    "for col in model_results.columns.values:\n",
    "    multi_index.append((str(col),regr_version))\n",
    "append_results = model_results.copy()\n",
    "append_results.columns = pd.MultiIndex.from_tuples(multi_index, names = ['discount_rate', 'model'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index_results = []\n",
    "for col in results.columns.values:\n",
    "    multi_index_results.append((str(col[0]), col[1]))\n",
    "results.columns = pd.MultiIndex.from_tuples(multi_index_results, names = ['discount_rate', 'model'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results = results.join(append_results)\n",
    "full_results.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "store['results'] = full_results\n",
    "model_info = store['model_info']\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making model info and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the model\n",
    "# joblib.dump(regr, 'model_dump/model_0.2.1.pkl')\n",
    "joblib.dump((mean_series, std_dev_series), 'model_dump/mean_stddev.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.strftime(\"%Y_%m_%d_%Hh_%Mm_%Ss\")\n",
    "# info to stick in detailed dataframe describing each model\n",
    "model_info_dict = {'model_version': regr_version,\n",
    "              'target': 'npv_roi_10',\n",
    "              'weights': 'None',\n",
    "              'algo_model': 'feedforward NN',\n",
    "              'hyperparams': \"nn_input_dim = 223, hly1_n = 300, hly2_n = 400, hly3_n = 300, hly4_n = 200, hly5_n = 100, hly6_n = 100, hly7_n = 100, nn_output_dim = 1, criterion = nn.MSELoss(),optimizer = optim.Adam(net.parameters(), lr=0.0001, weight_decay=0.00135),     if epoch+1 % 100 == 0: optimizer.param_groups[0]['lr'] *= .97\",\n",
    "              'cost_func': 'criterion = nn.MSELoss(),',\n",
    "              'useful_notes': 'test_mse: 0.0642635, train_mse: 0.061784, epoch_600',\n",
    "              'date': now}\n",
    "\n",
    "model_info_df = pd.DataFrame(model_info_dict, index = [regr_version])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.ix[regr_version,:] = model_info_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "store.append(\n",
    "            'model_info',\n",
    "            model_info,\n",
    "            data_columns=True,\n",
    "            index=True,\n",
    "            append=False,\n",
    ")\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine scores distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pd.Series(train_yhat)\n",
    "test_preds = pd.Series(test_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     results = results.join(append_results)\n",
    "# except ValueError:\n",
    "#     results.loc[:, (slice(None), slice('1.0.0','1.0.0'))] = append_results\n",
    "# results.sort_index(axis=1, inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "711px",
    "left": "200px",
    "right": "440px",
    "top": "-12px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
