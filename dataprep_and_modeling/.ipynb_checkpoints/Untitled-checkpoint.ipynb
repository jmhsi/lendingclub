{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-11T03:18:44.810646Z",
     "start_time": "2018-03-11T03:18:44.795429Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ~/justin_tinkering/data_science/lendingclub/dataprep_and_modeling/fastai/column_data.py\n",
    "from .imports import *\n",
    "from .torch_imports import *\n",
    "from .dataset import *\n",
    "from .learner import *\n",
    "\n",
    "\n",
    "class PassthruDataset(Dataset):\n",
    "    def __init__(self,*args):\n",
    "        *xs,y=args\n",
    "        self.xs,self.y = xs,y\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return [o[idx] for o in self.xs] + [self.y[idx]]\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(self, df, cols_x, col_y):\n",
    "        cols = [df[o] for o in cols_x+[col_y]]\n",
    "        return self(*cols)\n",
    "\n",
    "\n",
    "class ColumnarDataset(Dataset):\n",
    "    def __init__(self, cats, conts, y):\n",
    "        n = len(cats[0]) if cats else len(conts[0])\n",
    "        self.cats = np.stack(cats, 1).astype(np.int64) if cats else np.zeros((n,1))\n",
    "        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n",
    "        self.y = np.zeros((n,1)) if y is None else y[:,None]\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.cats[idx], self.conts[idx], self.y[idx]]\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls, df_cat, df_cont, y=None):\n",
    "        cat_cols = [c.values for n,c in df_cat.items()]\n",
    "        cont_cols = [c.values for n,c in df_cont.items()]\n",
    "        return cls(cat_cols, cont_cols, y)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, df, cat_flds, y=None):\n",
    "        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y)\n",
    "\n",
    "\n",
    "class ColumnarModelData(ModelData):\n",
    "    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n",
    "        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n",
    "        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n",
    "            DataLoader(val_ds, bs*2, shuffle=False, num_workers=1), test_dl)\n",
    "\n",
    "    @classmethod\n",
    "    def from_arrays(cls, path, val_idxs, xs, y, bs=64, test_xs=None, shuffle=True):\n",
    "        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n",
    "        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs)) if test_xs is not None else None\n",
    "        return cls(path, PassthruDataset(*(trn_xs.T), trn_y), PassthruDataset(*(val_xs.T), val_y),\n",
    "                   bs=bs, shuffle=shuffle, test_ds=test_ds)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, test_df=None):\n",
    "        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds) if test_df is not None else None\n",
    "        return cls(path, ColumnarDataset.from_data_frame(trn_df, cat_flds, trn_y),\n",
    "                    ColumnarDataset.from_data_frame(val_df, cat_flds, val_y), bs, test_ds=test_ds)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, test_df=None):\n",
    "        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n",
    "        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, test_df=test_df)\n",
    "\n",
    "    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n",
    "                    y_range=None, use_bn=False, **kwargs):\n",
    "        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn)\n",
    "        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n",
    "\n",
    "\n",
    "def emb_init(x):\n",
    "    x = x.weight.data\n",
    "    sc = 2/(x.size(1)+1)\n",
    "    x.uniform_(-sc,sc)\n",
    "\n",
    "\n",
    "class MixedInputModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n",
    "                 y_range=None, use_bn=False):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
    "        for emb in self.embs: emb_init(emb)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs)\n",
    "        self.n_emb, self.n_cont=n_emb, n_cont\n",
    "        \n",
    "        szs = [n_emb+n_cont] + szs\n",
    "        self.lins = nn.ModuleList([\n",
    "            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n",
    "        self.bns = nn.ModuleList([\n",
    "            nn.BatchNorm1d(sz) for sz in szs[1:]])\n",
    "        for o in self.lins: kaiming_normal(o.weight.data)\n",
    "        self.outp = nn.Linear(szs[-1], out_sz)\n",
    "        kaiming_normal(self.outp.weight.data)\n",
    "\n",
    "        self.emb_drop = nn.Dropout(emb_drop)\n",
    "        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n",
    "        self.bn = nn.BatchNorm1d(n_cont)\n",
    "        self.use_bn,self.y_range = use_bn,y_range\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x2 = self.bn(x_cont)\n",
    "            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n",
    "        for l,d,b in zip(self.lins, self.drops, self.bns):\n",
    "            x = F.relu(l(x))\n",
    "            if self.use_bn: x = b(x)\n",
    "            x = d(x)\n",
    "        x = self.outp(x)\n",
    "        if self.y_range:\n",
    "            x = F.sigmoid(x)\n",
    "            x = x*(self.y_range[1] - self.y_range[0])\n",
    "            x = x+self.y_range[0]\n",
    "        return x\n",
    "\n",
    "\n",
    "class StructuredLearner(Learner):\n",
    "    def __init__(self, data, models, **kwargs):\n",
    "        super().__init__(data, models, **kwargs)\n",
    "        self.crit = F.mse_loss\n",
    "\n",
    "class StructuredModel(BasicModel):\n",
    "    def get_layer_groups(self):\n",
    "        m=self.model\n",
    "        return [m.embs, children(m.lins)+children(m.bns), m.outp]\n",
    "\n",
    "\n",
    "class CollabFilterDataset(Dataset):\n",
    "    def __init__(self, path, user_col, item_col, ratings):\n",
    "        self.ratings,self.path = ratings.values.astype(np.float32),path\n",
    "        self.n = len(ratings)\n",
    "        (self.users,self.user2idx,self.user_col,self.n_users) = self.proc_col(user_col)\n",
    "        (self.items,self.item2idx,self.item_col,self.n_items) = self.proc_col(item_col)\n",
    "        self.min_score,self.max_score = min(ratings),max(ratings)\n",
    "        self.cols = [self.user_col,self.item_col,self.ratings]\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, path, df, user_name, item_name, rating_name):\n",
    "        return cls(path, df[user_name], df[item_name], df[rating_name])\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(cls, path, csv, user_name, item_name, rating_name):\n",
    "        df = pd.read_csv(os.path.join(path,csv))\n",
    "        return cls.from_data_frame(path, df, user_name, item_name, rating_name)\n",
    "\n",
    "    def proc_col(self,col):\n",
    "        uniq = col.unique()\n",
    "        name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "        return (uniq, name2idx, np.array([name2idx[x] for x in col]), len(uniq))\n",
    "\n",
    "    def __len__(self): return self.n\n",
    "    def __getitem__(self, idx): return [o[idx] for o in self.cols]\n",
    "\n",
    "    def get_data(self, val_idxs, bs):\n",
    "        val, trn = zip(*split_by_idx(val_idxs, *self.cols))\n",
    "        return ColumnarModelData(self.path, PassthruDataset(*trn), PassthruDataset(*val), bs)\n",
    "\n",
    "    def get_model(self, n_factors):\n",
    "        model = EmbeddingDotBias(n_factors, self.n_users, self.n_items, self.min_score, self.max_score)\n",
    "        return CollabFilterModel(to_gpu(model))\n",
    "\n",
    "    def get_learner(self, n_factors, val_idxs, bs, **kwargs):\n",
    "        return CollabFilterLearner(self.get_data(val_idxs, bs), self.get_model(n_factors), **kwargs)\n",
    "\n",
    "\n",
    "def get_emb(ni,nf):\n",
    "    e = nn.Embedding(ni, nf)\n",
    "    e.weight.data.uniform_(-0.05,0.05)\n",
    "    return e\n",
    "\n",
    "class EmbeddingDotBias(nn.Module):\n",
    "    def __init__(self, n_factors, n_users, n_items, min_score, max_score):\n",
    "        super().__init__()\n",
    "        self.min_score,self.max_score = min_score,max_score\n",
    "        (self.u, self.i, self.ub, self.ib) = [get_emb(*o) for o in [\n",
    "            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n",
    "        ]]\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        um = self.u(users)* self.i(items)\n",
    "        res = um.sum(1) + self.ub(users).squeeze() + self.ib(items).squeeze()\n",
    "        return F.sigmoid(res) * (self.max_score-self.min_score) + self.min_score\n",
    "\n",
    "class CollabFilterLearner(Learner):\n",
    "    def __init__(self, data, models, **kwargs):\n",
    "        super().__init__(data, models, **kwargs)\n",
    "        self.crit = F.mse_loss\n",
    "\n",
    "class CollabFilterModel(BasicModel):\n",
    "    def get_layer_groups(self): return self.model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
