{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:04:49.361274Z",
     "start_time": "2018-01-17T11:04:49.331435Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:04:50.240021Z",
     "start_time": "2018-01-17T11:04:49.786351Z"
    }
   },
   "outputs": [],
   "source": [
    "import data_science.lendingclub.dataprep_and_modeling.modeling_utils.data_prep_new as data_prep\n",
    "import dir_constants as dc\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:04:50.774954Z",
     "start_time": "2018-01-17T11:04:50.763667Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 100): \n",
    "        with pd.option_context(\"display.max_columns\", 1000): \n",
    "            display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT FORGET TO DROP ISSUE_D AFTER PREPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:35:39.716171Z",
     "start_time": "2018-01-17T10:35:33.731209Z"
    }
   },
   "outputs": [],
   "source": [
    "platform = 'lendingclub'\n",
    "\n",
    "store = pd.HDFStore(\n",
    "    dc.home_path+'/justin_tinkering/data_science/lendingclub/{0}_store.h5'.\n",
    "    format(platform),\n",
    "    append=True)\n",
    "loan_info = store['loan_info_clean']\n",
    "filtered_col_example = store['base_dataset_filtered_columns']\n",
    "base_cols = filtered_col_example.columns\n",
    "del filtered_col_example\n",
    "npv_rois = store['loan_npv_rois']\n",
    "loan_info['npv_roi_10'] = npv_rois[0.1]\n",
    "del npv_rois\n",
    "# loan_info = loan_info[base_cols]\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:35:57.967553Z",
     "start_time": "2018-01-17T10:35:55.704955Z"
    }
   },
   "outputs": [],
   "source": [
    "# figure out how to split dataset into train and validation. Split validation in half for valid and test\n",
    "sbd = loan_info[loan_info['maturity_time'] >= .98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:36:10.225293Z",
     "start_time": "2018-01-17T10:36:10.126775Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-09-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print((sbd['issue_d'].value_counts(dropna=False).index.max()))\n",
    "# last date is 2014-10-01\n",
    "# for 36 month, lets say 2014 july/aug/sep/oct are valid/test, everything before is train for normal loans\n",
    "# assume 4 month to charge off for defaulting loans, so july aug sep oct still valid/test, but\n",
    "# last pmt date for defaulting should be Feb.\n",
    "# for 60 month, same as above but 2012 dates\n",
    "\n",
    "    \n",
    "#     (sbd['last_pymnt_d'] <= '2014-06-01') & (sbd['loan_status'].isin(['paid', 'current']))) |((sbd['last_pymnt_d'] <= '2014-02-01') & (~sbd['loan_status'].isin(['paid', 'current'])))))\n",
    "\n",
    "train_mask_36 = ((sbd['term'] == 36) & ( ((sbd['last_pymnt_d'] <= '2014-06-01') & (sbd['loan_status'].isin(['paid', 'current'])))  | ((sbd['last_pymnt_d'] <= '2014-02-01') & (~sbd['loan_status'].isin(['paid', 'current']))) ))\n",
    "\n",
    "train_mask_60 = ((sbd['term'] == 60) & ( ((sbd['last_pymnt_d'] <= '2012-06-01') & (sbd['loan_status'].isin(['paid', 'current'])))  | ((sbd['last_pymnt_d'] <= '2012-02-01') & (~sbd['loan_status'].isin(['paid', 'current']))) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:36:23.091302Z",
     "start_time": "2018-01-17T10:36:22.522912Z"
    }
   },
   "outputs": [],
   "source": [
    "train_idx = np.array(pd.concat([sbd[train_mask_36], sbd[train_mask_60]])['id'])\n",
    "# all_idx = np.array(sbd.index)\n",
    "test_idx = np.array(sbd[~sbd['id'].isin(train_idx)].index)\n",
    "assert (len(train_idx) + len(test_idx)) == len(sbd)\n",
    "valid_idx = np.random.choice(test_idx, len(test_idx)//2, replace=False)\n",
    "va_set = set(valid_idx)\n",
    "te_set = set(test_idx).difference(va_set)\n",
    "tr_set = set(train_idx)\n",
    "assert len(te_set.intersection(va_set)) == 0\n",
    "test_idx = np.array(list(te_set))\n",
    "assert (len(train_idx)+ len(test_idx)+ len(valid_idx)) == len(sbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:36:37.455898Z",
     "start_time": "2018-01-17T10:36:36.926093Z"
    }
   },
   "outputs": [],
   "source": [
    "sbd = sbd[base_cols]\n",
    "cols_to_drop = ['hardship_type', 'hardship_reason', 'hardship_status', 'deferral_term', 'hardship_amount',\n",
    "                'hardship_start_date', 'hardship_end_date', 'payment_plan_start_date', 'hardship_length',\n",
    "                'hardship_dpd', 'hardship_loan_status', 'orig_projected_additional_accrued_interest',\n",
    "                'hardship_payoff_balance_amount', 'hardship_last_payment_amount', 'maturity_time', 'maturity_paid',\n",
    "                'target_loose','installment_amount', 'npv_roi_10', 'orig_amt_due',]\n",
    "\n",
    "sbd.drop(cols_to_drop, axis=1, inplace=True)\n",
    "sbd.rename({'issue_d': 'issue_date'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:36:51.613640Z",
     "start_time": "2018-01-17T10:36:50.371863Z"
    }
   },
   "outputs": [],
   "source": [
    "add_datepart(sbd, 'issue_date')\n",
    "train_cats(sbd)\n",
    "df, y, nas = proc_df(sbd, 'target_strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:37:05.305232Z",
     "start_time": "2018-01-17T10:37:05.293086Z"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y, index=df.index, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:04:54.753019Z",
     "start_time": "2018-01-17T11:04:54.581991Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d9a59e1259b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save in temp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/X_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/X_valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/X_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# save in temp\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "X_train = df.ix[train_idx,:].fillna(0).reset_index(drop=True).to_feather('tmp/X_train')\n",
    "X_valid = df.ix[valid_idx,:].fillna(0).reset_index(drop=True).to_feather('tmp/X_valid')\n",
    "X_test = df.ix[test_idx,:].fillna(0).reset_index(drop=True).to_feather('tmp/X_test')\n",
    "y_train = y.ix[train_idx].reset_index(drop=True).to_feather('tmp/y_train')\n",
    "y_valid = y.ix[valid_idx].reset_index(drop=True).to_feather('tmp/y_valid')\n",
    "y_test = y.ix[test_idx].reset_index(drop=True).to_feather('tmp/y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:04:58.168037Z",
     "start_time": "2018-01-17T11:04:57.658713Z"
    }
   },
   "outputs": [],
   "source": [
    "# load in\n",
    "os.makedirs('tmp', exist_ok=True)\n",
    "X_train = pd.read_feather('tmp/X_train')\n",
    "X_valid = pd.read_feather('tmp/X_valid')\n",
    "X_test = pd.read_feather('tmp/X_test')\n",
    "y_train = pd.read_feather('tmp/y_train')\n",
    "y_valid = pd.read_feather('tmp/y_valid')\n",
    "y_test = pd.read_feather('tmp/y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:05:03.503765Z",
     "start_time": "2018-01-17T11:05:02.033152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9785526872619551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = RandomForestClassifier(n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "m.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:48:45.705607Z",
     "start_time": "2018-01-17T10:48:45.694840Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(x,y): return mean_squared_error(x, y)\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:49:06.778278Z",
     "start_time": "2018-01-17T10:49:02.793055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 76 ms, total: 2.43 s\n",
      "Wall time: 807 ms\n",
      "[0.021599661447312738, 0.16963072043497962, 0.97840033855268727, 0.83036927956502038]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestClassifier(n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:49:10.434095Z",
     "start_time": "2018-01-17T10:49:10.417809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380073143892809"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "103571/len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:44:31.189907Z",
     "start_time": "2018-01-17T10:44:31.155208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    103571\n",
       "1     20021\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid['target'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T10:44:47.639112Z",
     "start_time": "2018-01-17T10:44:47.625628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:06:16.020980Z",
     "start_time": "2018-01-17T11:06:16.004989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-17 11:06:16.019234\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:06:20.186859Z",
     "start_time": "2018-01-17T11:06:20.166133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-17 11:06:20.184828\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T11:06:24.099056Z",
     "start_time": "2018-01-17T11:06:24.086376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-17 11:06:24.097581\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T05:36:56.869967Z",
     "start_time": "2018-01-17T05:36:53.582705Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.059732917073720165, 0.04208146144427001, 0.040107782786927837, -0.37598011900242989]\n"
     ]
    }
   ],
   "source": [
    "# change depth\n",
    "m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T05:38:55.292696Z",
     "start_time": "2018-01-17T05:38:35.678008Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0088245236926061746, 0.045153428009101076, 0.85819223255594679, -0.4764273177064402, -0.0030401048978054845]\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random search RF hyperparams, and build with best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_dict = {'n_estimators': np.arange(1,201),\n",
    "                   'criterion': ['mse'],#, 'mae'\n",
    "                   'max_features': [3,10, 50, 70, 100, 150, 200],\n",
    "                   'min_samples_split': [20, 200, 2000],\n",
    "                   'min_samples_leaf': [10, 100, 1000],\n",
    "                   'bootstrap': [True],\n",
    "                   'oob_score': [True],\n",
    "                   'n_jobs': [-1],\n",
    "                   'verbose': [10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 20\n",
    "random_search = RandomizedSearchCV(\n",
    "    regr, param_distributions=fit_params_dict, n_iter=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "random_search.fit(standardized, eval_cols)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(random_search.cv_results_)\n",
    "# Model with rank: 1\n",
    "# Mean validation score: 0.078 (std: 0.001)\n",
    "# Parameters: {'verbose': 10, 'oob_score': True, 'n_jobs': -1, 'n_estimators': 175, 'min_samples_split': 200, 'min_samples_leaf': 10, 'max_features': 70, 'criterion': 'mse', 'bootstrap': True}\n",
    "\n",
    "# Model with rank: 2\n",
    "# Mean validation score: 0.078 (std: 0.001)\n",
    "# Parameters: {'verbose': 10, 'oob_score': True, 'n_jobs': -1, 'n_estimators': 185, 'min_samples_split': 200, 'min_samples_leaf': 10, 'max_features': 100, 'criterion': 'mse', 'bootstrap': True}\n",
    "\n",
    "# Model with rank: 3\n",
    "# Mean validation score: 0.077 (std: 0.002)\n",
    "# Parameters: {'verbose': 10, 'oob_score': True, 'n_jobs': -1, 'n_estimators': 139, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 100, 'criterion': 'mse', 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# take best hyperparams from report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(\n",
    "    n_estimators=175,\n",
    "    random_state=0,\n",
    "    max_features=70,\n",
    "    min_samples_split=200,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1,\n",
    "    oob_score=True,\n",
    "    bootstrap=True,\n",
    "    criterion='mse',\n",
    ")\n",
    "regr.fit(standardized, eval_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.score(standardized, eval_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the model\n",
    "joblib.dump(regr, 'model_dump/model_0.2.1.pkl')\n",
    "joblib.dump((mean_series, std_dev_series), 'model_dump/mean_stddev.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.strftime(\"%Y_%m_%d_%Hh_%Mm_%Ss\")\n",
    "# info to stick in detailed dataframe describing each model\n",
    "model_info = {'model_version': '0.2.1',\n",
    "              'target': 'npv_roi_10',\n",
    "              'weights': 'None',\n",
    "              'algo_model': 'RF_regr',\n",
    "              'hyperparams': \"bootstrap=True, criterion='mse', max_depth=None, max_features=70, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=10, min_samples_split=200, min_weight_fraction_leaf=0.0, n_estimators=175, n_jobs=-1, oob_score=True, random_state=0, verbose=0, warm_start=False\",\n",
    "              'cost_func': 'sklearn default, which I think is mse',\n",
    "              'useful_notes': 'R2 score of .3830649 (regr.score())',\n",
    "              'date': now}\n",
    "\n",
    "model_info_df = pd.DataFrame(model_info, index = ['0.2.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "model_info = store['model_info']\n",
    "model_info.ix['0.2.1',:] = model_info_df.values\n",
    "model_info.sort_index(inplace=True)\n",
    "store.append(\n",
    "            'model_info',\n",
    "            model_info_df,\n",
    "            data_columns=True,\n",
    "            index=True,\n",
    "            append=False,\n",
    ")\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "test = store['test_filtered_columns']\n",
    "train = store['train_filtered_columns']\n",
    "loan_npv_rois = store['loan_npv_rois']\n",
    "default_series = test['target_strict']\n",
    "results = store['results']\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = data_prep.process_data_test(train)\n",
    "train_y = train_y['npv_roi_10'].values\n",
    "test_X, test_y = data_prep.process_data_test(test)\n",
    "test_y = test_y['npv_roi_10'].values\n",
    "regr = joblib.load('model_dump/model_0.2.1.pkl')\n",
    "regr_version = '0.2.1'\n",
    "test_yhat = regr.predict(test_X)\n",
    "train_yhat = regr.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = np.sum((test_yhat - test_y)**2)/len(test_y)\n",
    "train_mse = np.sum((train_yhat - train_y)**2)/len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(trials, port_size, available_loans, regr, regr_version, test, loan_npv_rois,\n",
    "                default_series):\n",
    "    results = {}\n",
    "    pct_default = {}\n",
    "    test_copy = test.copy()\n",
    "    for trial in tqdm_notebook(np.arange(trials)):\n",
    "        loan_ids = np.random.choice(\n",
    "            test_copy.index.values, available_loans, replace=False)\n",
    "        loans_to_pick_from = test_copy.loc[loan_ids, :]\n",
    "        scores = regr.predict(loans_to_pick_from)\n",
    "        scores_series = pd.Series(dict(zip(loan_ids, scores)))\n",
    "        scores_series.sort_values(ascending=False, inplace=True)\n",
    "        picks = scores_series[:900].index.values\n",
    "        results[trial] = loan_npv_rois.loc[picks, :].mean().to_dict()\n",
    "        pct_default[trial] = (default_series.loc[picks].sum()) / port_size\n",
    "    pct_default_series = pd.Series(pct_default)\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df['pct_def'] = pct_default_series\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as per done with baseline models, say 3000 loans available\n",
    "# , pick 900 of them\n",
    "trials = 20000\n",
    "port_size = 900\n",
    "available_loans = 3000\n",
    "model_results = eval_models(trials, port_size, available_loans, regr, regr_version, test_X, loan_npv_rois, default_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index = []\n",
    "for col in model_results.columns.values:\n",
    "    multi_index.append((str(col),regr_version))\n",
    "append_results = model_results.copy()\n",
    "append_results.columns = pd.MultiIndex.from_tuples(multi_index, names = ['discount_rate', 'model'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index_results = []\n",
    "for col in results.columns.values:\n",
    "    multi_index_results.append((str(col[0]), col[1]))\n",
    "results.columns = pd.MultiIndex.from_tuples(multi_index_results, names = ['discount_rate', 'model'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results = results.join(append_results)\n",
    "except ValueError:\n",
    "    results.loc[:, (slice(None), slice('0.2.1','0.2.1'))] = append_results\n",
    "results.sort_index(axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "store['results'] = full_results\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
