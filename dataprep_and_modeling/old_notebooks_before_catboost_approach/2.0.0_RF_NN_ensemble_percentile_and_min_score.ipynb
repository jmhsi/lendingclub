{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seeing the performance of 1.0.1 NN and 0.2.1 RF used together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_science.lendingclub.dataprep_and_modeling.modeling_utils.data_prep_new as data_prep\n",
    "import dir_constants as dc\n",
    "from sklearn.externals import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from  lendingclub.dataprep_and_modeling.model_dump.nn_1_0_1 import net_class\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_this(summaries):\n",
    "    plt.figure(figsize=(9,6))\n",
    "    plt.plot(summaries.columns.values, summaries.loc['mean',:], 'o', label='mean')\n",
    "    plt.plot(summaries.columns.values, summaries.loc['25%',:], 'ro', label='25%')\n",
    "    # plt.plot(summaries.columns.values, summaries.loc['50%',:], '-.')\n",
    "    plt.plot(summaries.columns.values, summaries.loc['75%',:], 'ko', label='75%')\n",
    "    plt.title('return per percentile over batches')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('percentile of 1.0.1_score')\n",
    "    plt.ylabel('npv_roi_10')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'lendingclub'\n",
    "nn_path = '/home/justin/justin_tinkering/data_science/lendingclub/dataprep_and_modeling/model_dump/nn_1_0_1/1.0.1_e600'\n",
    "rf_path = '/home/justin/justin_tinkering/data_science/lendingclub/dataprep_and_modeling/model_dump/model_0.2.1.pkl'\n",
    "regr_version = '2.0.0'\n",
    "\n",
    "store = pd.HDFStore(\n",
    "    dc.home_path+'/justin_tinkering/data_science/lendingclub/{0}_store.h5'.\n",
    "    format(platform),\n",
    "    append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure no loan in test set was in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "train = store['train_filtered_columns']\n",
    "test = store['test_filtered_columns']\n",
    "loan_npv_rois = store['loan_npv_rois']\n",
    "default_series = test['target_strict']\n",
    "results = store['results']\n",
    "store.close()\n",
    "\n",
    "train_ids = set(train.index.values)\n",
    "test_ids = set(test.index.values)\n",
    "assert len(train_ids.intersection(test_ids)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = data_prep.process_data_test(test)\n",
    "test_y = test_y['npv_roi_10'].values\n",
    "# NN score\n",
    "net = net_class.Net()\n",
    "net.load_state_dict(torch.load(nn_path))\n",
    "test_yhat_NN = net_class.torch_version(test_X,net)\n",
    "# RF score\n",
    "regr = joblib.load('model_dump/model_0.2.1.pkl')\n",
    "test_yhat_RF = regr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that there was no null columns in test_X just to verify\n",
    "# that data_prep.process_data_test was working properly\n",
    "for col in test_X.columns:\n",
    "    if len(test_X[test_X[col].isnull()]) > 0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_yhat = (test_yhat_RF + test_yhat_NN)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short digression on examining feature importances (N/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[regr_version+'_scores'] = test_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['2.0.0_scores'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test[test['2.0.0_scores'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['agg.path.chunksize'] = 10000\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(test[regr_version+'_scores'], test['npv_roi_10'], 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# at scores above 0, check the pctage of positive returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cutoff = -.02\n",
    "pos_scores = test[test[regr_version+'_scores'] >= score_cutoff]\n",
    "ps_pos_returns = pos_scores[pos_scores['npv_roi_10'] > score_cutoff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ps_pos_returns)/len(pos_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking return per percentile below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = np.arange(0,100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(trials, port_size, available_loans, test, percentiles):\n",
    "    results = {}\n",
    "    pct_default = {}\n",
    "    test_copy = test.copy()\n",
    "    for trial in tqdm_notebook(np.arange(trials)):\n",
    "        loan_ids = np.random.choice(\n",
    "            test_copy.index.values, available_loans, replace=False)\n",
    "        loans_to_pick_from = test_copy.loc[loan_ids, :]\n",
    "        loans_to_pick_from.sort_values(regr_version+'_scores', ascending=True, inplace = True)\n",
    "        chunksize = int(len(loans_to_pick_from)/100)\n",
    "        results_dict = {}\n",
    "        for k,perc in enumerate(percentiles):\n",
    "            subset = loans_to_pick_from[k*chunksize:(k+1)*chunksize]\n",
    "            results_dict[perc] = subset['npv_roi_10'].mean()\n",
    "\n",
    "        results[trial] = pd.Series(results_dict)\n",
    "        \n",
    "    return pd.DataFrame.from_dict(results).T\n",
    "\n",
    "\n",
    "#         picks = scores_series[:900].index.values\n",
    "#         results[trial] = loan_npv_rois.loc[picks, :].mean().to_dict()\n",
    "#         pct_default[trial] = (default_series.loc[picks].sum()) / port_size\n",
    "#     pct_default_series = pd.Series(pct_default)\n",
    "#     results_df = pd.DataFrame(results).T\n",
    "#     results_df['pct_def'] = pct_default_series\n",
    "#     return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as per done with baseline models, say 3000 loans available\n",
    "# , pick 900 of them\n",
    "trials = 20000\n",
    "port_size = 900\n",
    "available_loans = 3000\n",
    "results = eval_models(trials, port_size, available_loans, test, percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "store['percentiles_for_2.0.0'] = results\n",
    "# store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = store['percentiles_for_0.2.1']\n",
    "nn_results = store['percentiles_for_1.0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_summaries = rf_results.describe()\n",
    "nn_summaries = nn_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index = []\n",
    "for col in summaries.columns.values:\n",
    "    multi_index.append((str(col),'2.0.0'))\n",
    "append_results = summaries.copy()\n",
    "append_results.columns = pd.MultiIndex.from_tuples(multi_index, names = ['percentile', 'model'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_multi_index = []\n",
    "for col in rf_summaries.columns.values:\n",
    "    rf_multi_index.append((str(col),'0.2.1'))\n",
    "rf_append_results = rf_summaries.copy()\n",
    "rf_append_results.columns = pd.MultiIndex.from_tuples(rf_multi_index, names = ['percentile', 'model'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_multi_index = []\n",
    "for col in nn_summaries.columns.values:\n",
    "    nn_multi_index.append((str(col),'1.0.1'))\n",
    "nn_append_results = nn_summaries.copy()\n",
    "nn_append_results.columns = pd.MultiIndex.from_tuples(nn_multi_index, names = ['percentile', 'model'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([append_results,rf_append_results,nn_append_results], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
