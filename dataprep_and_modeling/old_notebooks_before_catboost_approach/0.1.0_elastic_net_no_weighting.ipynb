{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modeling_utils.data_prep as data_prep\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.externals import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT FORGET TO DROP ISSUE_D AFTER PREPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'lendingclub'\n",
    "\n",
    "store = pd.HDFStore(\n",
    "    '/Users/justinhsi/justin_tinkering/data_science/lendingclub/{0}_store.h5'.\n",
    "    format(platform),\n",
    "    append=True)\n",
    "\n",
    "loan_info = store['train_filtered_columns']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Until I figure out a good imputation method (e.g. bayes PCA), just drop columns with null still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized, eval_cols, mean_series, std_dev_series = data_prep.process_data_train(\n",
    "    loan_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# straight up out of box elastic net with slightly tweaked alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = ElasticNet(alpha = .004, random_state=0, max_iter = 1500)\n",
    "regr.fit(standardized, eval_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the model\n",
    "joblib.dump(regr, 'model_dump/model_0.1.0.pkl')\n",
    "joblib.dump((mean_series, std_dev_series), 'model_dump/mean_stddev.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict = {}\n",
    "for index, coef in enumerate(regr.coef_):\n",
    "    coef_dict[index] = coef\n",
    "pd.Series(coef_dict).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.score(standardized, eval_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.strftime(\"%Y_%m_%d_%Hh_%Mm_%Ss\")\n",
    "# info to stick in detailed dataframe describing each model\n",
    "model_info = {'model_version': '0.1.0',\n",
    "              'target': 'npv_roi_10',\n",
    "              'weights': 'None',\n",
    "              'algo_model': 'elastic_net',\n",
    "              'hyperparams': \"alpha:.004, random_state: 0, max_iter: 1500\",\n",
    "              'cost_func': 'sklearn default, which I think is mse',\n",
    "              'useful_notes': 'R2 score of .0604167 (regr.score())',\n",
    "              'date': now}\n",
    "\n",
    "model_info_df = pd.DataFrame(model_info, index = ['0.1.0'])\n",
    "store.open()\n",
    "store.append(\n",
    "            'model_info',\n",
    "            model_info_df,\n",
    "            data_columns=True,\n",
    "            index=True,\n",
    "            append=True,\n",
    "            min_itemsize={'model_version': 20,\n",
    "                  'target': 20,\n",
    "                  'weights': 200,\n",
    "                  'algo_model': 20,\n",
    "                  'hyperparams': 500,\n",
    "                  'cost_func': 300,\n",
    "                  'useful_notes': 1000,\n",
    "                  'date': 30}\n",
    ")\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "test = store['test_filtered_columns']\n",
    "train = store['train_filtered_columns']\n",
    "loan_npv_rois = store['loan_npv_rois']\n",
    "default_series = test['target_strict']\n",
    "results = store['results']\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = data_prep.process_data_test(train)\n",
    "train_y = train_y['npv_roi_10'].values\n",
    "test_X, test_y = data_prep.process_data_test(test)\n",
    "test_y = test_y['npv_roi_10'].values\n",
    "regr = joblib.load('model_dump/model_0.1.0.pkl')\n",
    "regr_version = '0.1.0'\n",
    "test_yhat = regr.predict(test_X)\n",
    "train_yhat = regr.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse = np.sum((test_yhat - test_y)**2)/len(test_y)\n",
    "train_mse = np.sum((train_yhat - train_y)**2)/len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(trials, port_size, available_loans, regr, regr_version, test, loan_npv_rois,\n",
    "                default_series):\n",
    "    results = {}\n",
    "    pct_default = {}\n",
    "    test_copy = test.copy()\n",
    "    for trial in tqdm_notebook(np.arange(trials)):\n",
    "        loan_ids = np.random.choice(\n",
    "            test_copy.index.values, available_loans, replace=False)\n",
    "        loans_to_pick_from = test_copy.loc[loan_ids, :]\n",
    "        scores = regr.predict(loans_to_pick_from)\n",
    "        scores_series = pd.Series(dict(zip(loan_ids, scores)))\n",
    "        scores_series.sort_values(ascending=False, inplace=True)\n",
    "        picks = scores_series[:900].index.values\n",
    "        results[trial] = loan_npv_rois.loc[picks, :].mean().to_dict()\n",
    "        pct_default[trial] = (default_series.loc[picks].sum()) / port_size\n",
    "    pct_default_series = pd.Series(pct_default)\n",
    "    results_df = pd.DataFrame(results).T\n",
    "    results_df['pct_def'] = pct_default_series\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as per done with baseline models, say 3000 loans available\n",
    "# , pick 900 of them\n",
    "trials = 20000\n",
    "port_size = 900\n",
    "available_loans = 3000\n",
    "model_results = eval_models(trials, port_size, available_loans, regr, regr_version, test_X, loan_npv_rois, default_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_index = []\n",
    "for col in model_results.columns.values:\n",
    "    multi_index.append((col,regr_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_results = model_results\n",
    "append_results.columns = pd.MultiIndex.from_tuples(multi_index, names = ['discount_rate', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results = results.join(append_results)\n",
    "except ValueError:\n",
    "    results.loc[:, (slice(None), slice('0.1.0','0.1.0'))] = append_results\n",
    "results.sort_index(axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "store['results'] = results\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
