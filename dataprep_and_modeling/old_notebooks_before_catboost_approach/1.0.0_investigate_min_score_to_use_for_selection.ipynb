{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If I plan to run the scorer every batch to select loans, I should have a minimum score that a loan must receive to even be considered for investing in, and the remaining loans can be selected from in descending score order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dir_constants as dir_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_con.home_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model_dump.nn_1_0_0 import net_class\n",
    "\n",
    "import modeling_utils.data_prep_new as data_prep\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = 'lendingclub'\n",
    "\n",
    "\n",
    "store = pd.HDFStore(\n",
    "    os.path.join(home,'justin_tinkering/data_science/lendingclub/{0}_store.h5'.format(platform)),\n",
    "    append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure no loan in test set was in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.open()\n",
    "train = store['train_filtered_columns']\n",
    "test = store['test_filtered_columns']\n",
    "loan_npv_rois = store['loan_npv_rois']\n",
    "default_series = test['target_strict']\n",
    "results = store['results']\n",
    "store.close()\n",
    "\n",
    "train_ids = set(train.index.values)\n",
    "test_ids = set(test.index.values)\n",
    "assert len(train_ids.intersection(test_ids)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add scores and npv_roi_5 to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'model_dump/nn_1_0_0/1.0.0_e500'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net_class.Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = data_prep.process_data_test(train)\n",
    "test_X, test_y = data_prep.process_data_test(test)\n",
    "train_y = train_y['npv_roi_10'].values\n",
    "test_y = test_y['npv_roi_10'].values\n",
    "regr_version = '1.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yhat = net_class.torch_version(train_X, net)\n",
    "test_yhat = net_class.torch_version(test_X, net)\n",
    "test['1.0.0_scores'] = test_yhat\n",
    "train['1.0.0_scores'] = train_yhat\n",
    "test['npv_roi_5'] = loan_npv_rois[.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See what the range of predictions is, to tell if we predict outliers later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['1.0.0_scores'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['1.0.0_scores'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['1.0.0_scores'] > 0]['grade'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['1.0.0_scores'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find what is a good percentile to cutoff at, and what the distribution for scores is at that percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_percentiles = np.arange(71,101,1)\n",
    "good_percentiles = good_percentiles[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_score_models(trials, available_loans, test, percentiles):\n",
    "    # looks at loans that scored in top 30%, computes avg npv_roi_5 in each of those\n",
    "    # top percentiles\n",
    "    results = {}\n",
    "    results_scores = {}\n",
    "    pct_default = {}\n",
    "    test_copy = test.copy()\n",
    "    for trial in tqdm_notebook(np.arange(trials)):\n",
    "        loan_ids = np.random.choice(\n",
    "            test_copy.index.values, available_loans, replace=False)\n",
    "        loans_to_pick_from = test_copy.loc[loan_ids, :]\n",
    "        loans_to_pick_from.sort_values('1.0.0_scores', ascending=False, inplace = True)\n",
    "        chunksize = int(len(loans_to_pick_from)/100)\n",
    "        results_dict = {}\n",
    "        results_scores_dict = {}\n",
    "        for k,perc in enumerate(percentiles):\n",
    "            subset = loans_to_pick_from[k*chunksize:(k+1)*chunksize]\n",
    "            results_dict[perc] = subset['npv_roi_5'].mean()\n",
    "            results_scores_dict[perc] = subset['1.0.0_scores'].mean()\n",
    "\n",
    "        results[trial] = pd.Series(results_dict)\n",
    "        results_scores[trial] = pd.Series(results_scores_dict)\n",
    "\n",
    "    return pd.DataFrame.from_dict(results).T, pd.DataFrame.from_dict(results_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume there's 200 loans per batch\n",
    "trials = 20000\n",
    "available_loans = 200\n",
    "results, results_scores = find_min_score_models(trials, available_loans, test, good_percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = results.describe()\n",
    "summaries_scores = results_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(summaries.columns.values, summaries.loc['mean',:], 'o', label='mean')\n",
    "plt.plot(summaries.columns.values, summaries.loc['25%',:], 'ro', label='25%')\n",
    "# plt.plot(summaries.columns.values, summaries.loc['50%',:], '-.')\n",
    "plt.plot(summaries.columns.values, summaries.loc['75%',:], 'ko', label='75%')\n",
    "plt.title('return per percentile over batches')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('percentile of 1.0.0_score')\n",
    "plt.ylabel('npv_roi_5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(summaries_scores.columns.values, summaries_scores.loc['mean',:], 'o', label='mean')\n",
    "plt.plot(summaries_scores.columns.values, summaries_scores.loc['25%',:], 'ro', label='25%')\n",
    "# plt.plot(summaries_scores.columns.values, summaries_scores.loc['50%',:], '-.')\n",
    "plt.plot(summaries_scores.columns.values, summaries_scores.loc['75%',:], 'ko', label='75%')\n",
    "plt.title('scores per percentile over batches')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('percentile of 1.0.0_score')\n",
    "plt.ylabel('npv_roi_5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_scores.loc['mean', 75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take one sided 99% cofidence interval at score is greater than mean -3 std_dev at 90th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = summaries_scores.loc['mean', 90] - 3*summaries_scores.loc['std', 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Say I wanted the 75pctile of the 80th percentile (-0.36289), what grade distribution of loans are those?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = test[test['1.0.0_scores'] >= -0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade distribution of picks\n",
    "picks['grade'].value_counts(dropna=False)/len(picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared to grade distribution of all test loans\n",
    "test['grade'].value_counts(dropna=False)/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd dataprep_and_modeling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
